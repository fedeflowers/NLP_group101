{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e77650b3",
      "metadata": {
        "id": "e77650b3"
      },
      "source": [
        "# 1st task, dataset exploration and binary calssification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "PDSMR0DGx0U_"
      },
      "id": "PDSMR0DGx0U_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Y4MdoKK4x2gU"
      },
      "id": "Y4MdoKK4x2gU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "zsCyujQZx2k1"
      },
      "id": "zsCyujQZx2k1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "1jPeMfjcx2nd"
      },
      "id": "1jPeMfjcx2nd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IvjKm4l7x2pv"
      },
      "id": "IvjKm4l7x2pv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebc72f41",
      "metadata": {
        "id": "ebc72f41"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
        "train_set = dataset[\"train\"]\n",
        "validation_set = dataset[\"validation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79842d99",
      "metadata": {
        "id": "79842d99"
      },
      "outputs": [],
      "source": [
        "dataset['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4236bce3",
      "metadata": {
        "id": "4236bce3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(train_set)#.sample(frac=1) #RESHUFFLING\n",
        "vs = pd.DataFrame(validation_set)#.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166d770d",
      "metadata": {
        "scrolled": false,
        "id": "166d770d"
      },
      "outputs": [],
      "source": [
        "df.head() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c561824d",
      "metadata": {
        "id": "c561824d"
      },
      "outputs": [],
      "source": [
        "new_df = []\n",
        "new_vs = []\n",
        "for i in range(len(df)):\n",
        "    if df.iloc[i,2] == 'japanese' or df.iloc[i,2] == 'finnish' or df.iloc[i,2] == 'english':\n",
        "        new_df.append(df.iloc[i, :])\n",
        "for i in range(len(vs)):\n",
        "    if vs.iloc[i,2] == 'japanese' or vs.iloc[i,2] == 'finnish' or vs.iloc[i,2] == 'english':\n",
        "        new_vs.append(vs.iloc[i, :])\n",
        "df = pd.DataFrame(new_df) #only with english, japanese or finnish text\n",
        "vs = pd.DataFrame(new_vs) #only with english, japanese or finnish text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5595f93",
      "metadata": {
        "id": "f5595f93"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install janome"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5M-mfkOyZjP",
        "outputId": "aa653f20-4cd1-48a2-9a36-6cc153d09e3a"
      },
      "id": "K5M-mfkOyZjP",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting janome\n",
            "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 106.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "288ee902",
      "metadata": {
        "id": "288ee902"
      },
      "outputs": [],
      "source": [
        "from janome.tokenizer import Tokenizer as tok_jap #japanese tokenizer\n",
        "tok_jap = tok_jap()\n",
        "from nltk.tokenize import word_tokenize #english tokenizer\n",
        "#[token for token in t.tokenize(df.iloc[1,4], wakati=True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "54d9b906",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54d9b906",
        "outputId": "b924c2c3-14a4-4814-df6d-1e7c94ece587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29868/29868 [03:40<00:00, 135.66it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "tokenized_answers = {} #dictionary, key = number of iteration in the dataframe, value = answer_text, or '' if it's not answerable\n",
        "tokenized_questions = {} #same as before but with questions\n",
        "tokenized_documents = {} #same but with documents\n",
        "\n",
        "for i in tqdm(range(len(df))):\n",
        "    if df.iloc[i,2] == 'japanese': #check the language\n",
        "        tokenized_answers[i] = [token for token in tok_jap.tokenize(df.iloc[i,3]['answer_text'][0], wakati=True)]\n",
        "        tokenized_questions[i] = [token for token in tok_jap.tokenize(df.iloc[i,0], wakati=True)]\n",
        "        tokenized_documents[i] = [token for token in tok_jap.tokenize(df.iloc[i,4], wakati=True)]\n",
        "    if df.iloc[i,2] == 'english':\n",
        "        tokenized_answers[i] = word_tokenize(df.iloc[i,3]['answer_text'][0])\n",
        "        tokenized_questions[i] = word_tokenize(df.iloc[i,0])\n",
        "        tokenized_documents[i] = word_tokenize(df.iloc[i,4])\n",
        "    if df.iloc[i,2] == 'finnish': #I used the same tokenizer, maybe we can find another one that is better for finnish\n",
        "        tokenized_answers[i] = word_tokenize(df.iloc[i,3]['answer_text'][0])\n",
        "        tokenized_questions[i] = word_tokenize(df.iloc[i,0])\n",
        "        tokenized_documents[i] = word_tokenize(df.iloc[i,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c9ef9381",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9ef9381",
        "outputId": "0adf34cd-fbe5-4474-9138-3ace3c2b98af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3712/3712 [00:58<00:00, 62.94it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "tokenized_answers_validation = {} #dictionary, key = number of iteration in the dataframe, value = answer_text, or '' if it's not answerable\n",
        "tokenized_questions_validation = {} #same as before but with questions\n",
        "tokenized_documents_validation = {} #same but with documents\n",
        "\n",
        "for i in tqdm(range(len(vs))):\n",
        "    if vs.iloc[i,2] == 'japanese': #check the language\n",
        "        tokenized_answers_validation[i] = [token for token in tok_jap.tokenize(vs.iloc[i,3]['answer_text'][0], wakati=True)]\n",
        "        tokenized_questions_validation[i] = [token for token in tok_jap.tokenize(vs.iloc[i,0], wakati=True)]\n",
        "        tokenized_documents_validation[i] = [token for token in tok_jap.tokenize(vs.iloc[i,4], wakati=True)]\n",
        "    if vs.iloc[i,2] == 'english':\n",
        "        tokenized_answers_validation[i] = word_tokenize(vs.iloc[i,3]['answer_text'][0])\n",
        "        tokenized_questions_validation[i] = word_tokenize(vs.iloc[i,0])\n",
        "        tokenized_documents_validation[i] = word_tokenize(vs.iloc[i,4])\n",
        "    if vs.iloc[i,2] == 'finnish': #I used the same tokenizer, maybe we can find another one that is better for finnish\n",
        "        tokenized_answers_validation[i] = word_tokenize(vs.iloc[i,3]['answer_text'][0])\n",
        "        tokenized_questions_validation[i] = word_tokenize(vs.iloc[i,0])\n",
        "        tokenized_documents_validation[i] = word_tokenize(vs.iloc[i,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "14a9203a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "14a9203a",
        "outputId": "b8fe4ace-bcde-4466-8425-6e7cefc363f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           question_text  \\\n",
              "3                                     化学兵器禁止条約はどこで採択された？   \n",
              "9                                オリヴィア・デ・ハヴィランドが生まれたのはいつ   \n",
              "11                         Kauanko lasia on valmistettu?   \n",
              "14                                Mikä on Ponzi-huijaus?   \n",
              "20                Mikä oli Napoleonin sotien lopputulos?   \n",
              "...                                                  ...   \n",
              "13305      What is the most common first word by babies?   \n",
              "13307                  Kuinka kauan valtiopäivät kestää?   \n",
              "13315                                アイスランド共和国の首都はどこですか？   \n",
              "13317                Milloin käytiin Persianlahden sota?   \n",
              "13319  When did the Bundaberg Central State School be...   \n",
              "\n",
              "                       document_title  language  \\\n",
              "3                            化学兵器禁止条約  japanese   \n",
              "9                      オリヴィア・デ・ハヴィランド  japanese   \n",
              "11                               Lasi   finnish   \n",
              "14                      Ponzi-huijaus   finnish   \n",
              "20                   Napoleonin sodat   finnish   \n",
              "...                               ...       ...   \n",
              "13305          Vocabulary development   english   \n",
              "13307             Suomen valtiopäivät   finnish   \n",
              "13315                          アイスランド  japanese   \n",
              "13317              Persianlahden sota   finnish   \n",
              "13319  Bundaberg Central State School   english   \n",
              "\n",
              "                                             annotations  \\\n",
              "3          {'answer_start': [11], 'answer_text': ['パリ']}   \n",
              "9      {'answer_start': [46], 'answer_text': ['1916年7...   \n",
              "11     {'answer_start': [160], 'answer_text': ['noin ...   \n",
              "14     {'answer_start': [39], 'answer_text': ['pyrami...   \n",
              "20     {'answer_start': [15], 'answer_text': ['Ranska...   \n",
              "...                                                  ...   \n",
              "13305        {'answer_start': [-1], 'answer_text': ['']}   \n",
              "13307        {'answer_start': [-1], 'answer_text': ['']}   \n",
              "13315        {'answer_start': [-1], 'answer_text': ['']}   \n",
              "13317        {'answer_start': [-1], 'answer_text': ['']}   \n",
              "13319        {'answer_start': [-1], 'answer_text': ['']}   \n",
              "\n",
              "                                      document_plaintext  \\\n",
              "3      1993年1月13日にパリにおいて署名がなされ、1997年4月29日に発効した[1]。実効的...   \n",
              "9      \\nオリヴィア・デ・ハヴィランド（Dame Olivia De Havilland, DBE...   \n",
              "11     Vanhin tunnettu lasilaatu on alkali­kalkki­las...   \n",
              "14     Ponzi-huijaus eli Ponzi-järjestelmä on pyramid...   \n",
              "20     Sotien jälkeen Ranska alistettiin kovilla rauh...   \n",
              "...                                                  ...   \n",
              "13305  Social pragmatic theories, also in contrast to...   \n",
              "13307  \\nEnnen vuotta 1906 kokoontuivat säätyvaltiopä...   \n",
              "13315  こうした危機を乗り切るため、アイスランド中央銀行は8日にロシアから40億ユーロの緊急融資を受...   \n",
              "13317  Ilmaiskuilla oli erityisen tuhoisa vaikutus Ir...   \n",
              "13319  By the 1880s the school site had become valuab...   \n",
              "\n",
              "                                            document_url  \n",
              "3      https://ja.wikipedia.org/wiki/%E5%8C%96%E5%AD%...  \n",
              "9      https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%...  \n",
              "11                    https://fi.wikipedia.org/wiki/Lasi  \n",
              "14           https://fi.wikipedia.org/wiki/Ponzi-huijaus  \n",
              "20      https://fi.wikipedia.org/wiki/Napoleonin%20sodat  \n",
              "...                                                  ...  \n",
              "13305  https://en.wikipedia.org/wiki/Vocabulary%20dev...  \n",
              "13307  https://fi.wikipedia.org/wiki/Suomen%20valtiop...  \n",
              "13315  https://ja.wikipedia.org/wiki/%E3%82%A2%E3%82%...  \n",
              "13317  https://fi.wikipedia.org/wiki/Persianlahden%20...  \n",
              "13319  https://en.wikipedia.org/wiki/Bundaberg%20Cent...  \n",
              "\n",
              "[3712 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-248131d1-a4c2-4171-b3a6-4e0b523bfc20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_text</th>\n",
              "      <th>document_title</th>\n",
              "      <th>language</th>\n",
              "      <th>annotations</th>\n",
              "      <th>document_plaintext</th>\n",
              "      <th>document_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>化学兵器禁止条約はどこで採択された？</td>\n",
              "      <td>化学兵器禁止条約</td>\n",
              "      <td>japanese</td>\n",
              "      <td>{'answer_start': [11], 'answer_text': ['パリ']}</td>\n",
              "      <td>1993年1月13日にパリにおいて署名がなされ、1997年4月29日に発効した[1]。実効的...</td>\n",
              "      <td>https://ja.wikipedia.org/wiki/%E5%8C%96%E5%AD%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>オリヴィア・デ・ハヴィランドが生まれたのはいつ</td>\n",
              "      <td>オリヴィア・デ・ハヴィランド</td>\n",
              "      <td>japanese</td>\n",
              "      <td>{'answer_start': [46], 'answer_text': ['1916年7...</td>\n",
              "      <td>\\nオリヴィア・デ・ハヴィランド（Dame Olivia De Havilland, DBE...</td>\n",
              "      <td>https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Kauanko lasia on valmistettu?</td>\n",
              "      <td>Lasi</td>\n",
              "      <td>finnish</td>\n",
              "      <td>{'answer_start': [160], 'answer_text': ['noin ...</td>\n",
              "      <td>Vanhin tunnettu lasilaatu on alkali­kalkki­las...</td>\n",
              "      <td>https://fi.wikipedia.org/wiki/Lasi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Mikä on Ponzi-huijaus?</td>\n",
              "      <td>Ponzi-huijaus</td>\n",
              "      <td>finnish</td>\n",
              "      <td>{'answer_start': [39], 'answer_text': ['pyrami...</td>\n",
              "      <td>Ponzi-huijaus eli Ponzi-järjestelmä on pyramid...</td>\n",
              "      <td>https://fi.wikipedia.org/wiki/Ponzi-huijaus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Mikä oli Napoleonin sotien lopputulos?</td>\n",
              "      <td>Napoleonin sodat</td>\n",
              "      <td>finnish</td>\n",
              "      <td>{'answer_start': [15], 'answer_text': ['Ranska...</td>\n",
              "      <td>Sotien jälkeen Ranska alistettiin kovilla rauh...</td>\n",
              "      <td>https://fi.wikipedia.org/wiki/Napoleonin%20sodat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13305</th>\n",
              "      <td>What is the most common first word by babies?</td>\n",
              "      <td>Vocabulary development</td>\n",
              "      <td>english</td>\n",
              "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
              "      <td>Social pragmatic theories, also in contrast to...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Vocabulary%20dev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13307</th>\n",
              "      <td>Kuinka kauan valtiopäivät kestää?</td>\n",
              "      <td>Suomen valtiopäivät</td>\n",
              "      <td>finnish</td>\n",
              "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
              "      <td>\\nEnnen vuotta 1906 kokoontuivat säätyvaltiopä...</td>\n",
              "      <td>https://fi.wikipedia.org/wiki/Suomen%20valtiop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13315</th>\n",
              "      <td>アイスランド共和国の首都はどこですか？</td>\n",
              "      <td>アイスランド</td>\n",
              "      <td>japanese</td>\n",
              "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
              "      <td>こうした危機を乗り切るため、アイスランド中央銀行は8日にロシアから40億ユーロの緊急融資を受...</td>\n",
              "      <td>https://ja.wikipedia.org/wiki/%E3%82%A2%E3%82%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13317</th>\n",
              "      <td>Milloin käytiin Persianlahden sota?</td>\n",
              "      <td>Persianlahden sota</td>\n",
              "      <td>finnish</td>\n",
              "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
              "      <td>Ilmaiskuilla oli erityisen tuhoisa vaikutus Ir...</td>\n",
              "      <td>https://fi.wikipedia.org/wiki/Persianlahden%20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13319</th>\n",
              "      <td>When did the Bundaberg Central State School be...</td>\n",
              "      <td>Bundaberg Central State School</td>\n",
              "      <td>english</td>\n",
              "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
              "      <td>By the 1880s the school site had become valuab...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Bundaberg%20Cent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3712 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-248131d1-a4c2-4171-b3a6-4e0b523bfc20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-248131d1-a4c2-4171-b3a6-4e0b523bfc20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-248131d1-a4c2-4171-b3a6-4e0b523bfc20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "vs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e194d9f8",
      "metadata": {
        "id": "e194d9f8"
      },
      "source": [
        "# Creating trainset and validation set for the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8b554f65",
      "metadata": {
        "id": "8b554f65"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#need only question and document, I don't really need the tokenization done before:\n",
        "jap_training = {} \n",
        "finn_training = {}\n",
        "eng_training = {}\n",
        "\n",
        "\n",
        "\n",
        "j = 0\n",
        "f = 0\n",
        "e = 0\n",
        "\n",
        "\n",
        "for i in range(len(df)):\n",
        "    sample_dict = {}\n",
        "    #sample_dict['answer_start'] = df.iloc[i,:]['annotations']['answer_start']\n",
        "    sample_dict['answer'] = tokenized_answers[i]\n",
        "    sample_dict['question'] = tokenized_questions[i]\n",
        "    sample_dict['context'] = tokenized_documents[i]\n",
        "   \n",
        "    #sample_dict['question'] = df.iloc[i,0]\n",
        "    #sample_dict['document'] = df.iloc[i,4]\n",
        "    \n",
        "    if tokenized_answers[i] == [] :\n",
        "        sample_dict['label'] = 0 #not answerable question\n",
        "    else:\n",
        "        sample_dict['label'] = 1\n",
        "        \n",
        "    if df.iloc[i,2] == 'japanese':\n",
        "        jap_training[j] = sample_dict\n",
        "        j += 1\n",
        "        continue\n",
        "    elif df.iloc[i,2] == 'english':\n",
        "        eng_training[e] = sample_dict\n",
        "        e += 1\n",
        "        continue\n",
        "    elif df.iloc[i,2] == 'finnish':\n",
        "        finn_training[f] = sample_dict\n",
        "        f += 1\n",
        "        continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7562423e",
      "metadata": {
        "id": "7562423e"
      },
      "outputs": [],
      "source": [
        "#validation set\n",
        "import nltk\n",
        "\n",
        "jap_val = {} \n",
        "finn_val = {}\n",
        "eng_val = {}\n",
        "\n",
        "j = 0\n",
        "f = 0\n",
        "e = 0\n",
        "\n",
        "\n",
        "for i in range(len(vs)):\n",
        "    sample_dict = {}\n",
        "    #sample_dict['answer_start'] = vs.iloc[i,:]['annotations']['answer_start']\n",
        "    sample_dict['answer'] = tokenized_answers_validation[i]\n",
        "    sample_dict['question'] = tokenized_questions_validation[i]\n",
        "    sample_dict['context'] = tokenized_documents_validation[i]\n",
        "    \n",
        "    if tokenized_answers_validation[i] == [] :\n",
        "        sample_dict['label'] = 0 #not answerable question\n",
        "    else:\n",
        "        sample_dict['label'] = 1\n",
        "        \n",
        "    if vs.iloc[i,2] == 'japanese':\n",
        "        jap_val[j] = sample_dict\n",
        "        j += 1\n",
        "        continue\n",
        "    elif vs.iloc[i,2] == 'english':\n",
        "        eng_val[e] = sample_dict\n",
        "        e += 1\n",
        "        continue\n",
        "    elif vs.iloc[i,2] == 'finnish':\n",
        "        finn_val[f] = sample_dict\n",
        "        f += 1\n",
        "        continue\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fca3583e",
      "metadata": {
        "id": "fca3583e"
      },
      "source": [
        "## Create corpus for tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da71b2c",
      "metadata": {
        "id": "0da71b2c"
      },
      "outputs": [],
      "source": [
        "#corpus to create a vocabulary with all possible words\n",
        "\n",
        "corpus_questions_eng = []\n",
        "corpus_questions_finn = []\n",
        "corpus_questions_jap = []\n",
        "corpus_context_eng = []\n",
        "corpus_context_finn = []\n",
        "corpus_context_jap = []\n",
        "\n",
        "for x in eng_training:\n",
        "    corpus_questions_eng.append(eng_training[x]['question'])\n",
        "    corpus_context_eng.append(eng_training[x]['context'])\n",
        "for x in finn_training:\n",
        "    corpus_questions_finn.append(finn_training[x]['question'])\n",
        "    corpus_context_finn.append(finn_training[x]['context'])\n",
        "for x in jap_training:\n",
        "    corpus_questions_jap.append(jap_training[x]['question'])\n",
        "    corpus_context_jap.append(jap_training[x]['context'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b8ac13d",
      "metadata": {
        "id": "0b8ac13d"
      },
      "outputs": [],
      "source": [
        "corpus_questions_VAL_eng = []\n",
        "corpus_context_VAL_eng = []\n",
        "corpus_questions_VAL_finn = []\n",
        "corpus_context_VAL_finn = []\n",
        "corpus_questions_VAL_jap = []\n",
        "corpus_context_VAL_jap = []\n",
        "\n",
        "for x in eng_val:\n",
        "    corpus_questions_VAL_eng.append(eng_val[x]['question'])  \n",
        "    corpus_context_VAL_eng.append(eng_val[x]['context']) \n",
        "for x in finn_val:\n",
        "    corpus_questions_VAL_finn.append(finn_val[x]['question'])  \n",
        "    corpus_context_VAL_finn.append(finn_val[x]['context']) \n",
        "for x in jap_val:\n",
        "    corpus_questions_VAL_jap.append(jap_val[x]['question'])  \n",
        "    corpus_context_VAL_jap.append(jap_val[x]['context']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec0d4fed",
      "metadata": {
        "id": "ec0d4fed"
      },
      "outputs": [],
      "source": [
        "bag_of_words_dict_eng = {}\n",
        "bag_of_words_dict_finn = {}\n",
        "bag_of_words_dict_jap = {}\n",
        "\n",
        "for sent in corpus_questions_eng:\n",
        "    for word in sent:\n",
        "        if word not in bag_of_words_dict_eng:\n",
        "            bag_of_words_dict_eng[word] = 1\n",
        "        else:\n",
        "            bag_of_words_dict_eng[word] +=1\n",
        "            \n",
        "for question in corpus_questions_finn:\n",
        "    for word in question:\n",
        "        if word not in bag_of_words_dict_finn:\n",
        "            bag_of_words_dict_finn[word] = 1\n",
        "        else:\n",
        "            bag_of_words_dict_finn[word] +=1\n",
        "            \n",
        "for question in corpus_questions_jap:\n",
        "    for word in question:\n",
        "        if word not in bag_of_words_dict_jap:\n",
        "            bag_of_words_dict_jap[word] = 1\n",
        "        else:\n",
        "            bag_of_words_dict_jap[word] +=1\n",
        "            \n",
        "#list_words = bag_of_words_dict_eng.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed1de7d3",
      "metadata": {
        "id": "ed1de7d3",
        "outputId": "d802dc6e-890e-45a6-8ddf-980f3389dde0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nbag_of_words_dict_eng = {}\\nfor question in corpus_questions:\\n    for word in question:\\n        if word not in bag_of_words_dict_eng:\\n            bag_of_words_dict_eng[word] = 1\\n        else:\\n            bag_of_words_dict_eng[word] +=1\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#VALIDATIO SET, the vocabulary should be the same as the training set\n",
        "#I have to use the same vocabulary as the training, even for the validation set, that's why the commented part of code it's not useful\n",
        "'''\n",
        "bag_of_words_dict_eng = {}\n",
        "for question in corpus_questions:\n",
        "    for word in question:\n",
        "        if word not in bag_of_words_dict_eng:\n",
        "            bag_of_words_dict_eng[word] = 1\n",
        "        else:\n",
        "            bag_of_words_dict_eng[word] +=1\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b566f53",
      "metadata": {
        "id": "8b566f53"
      },
      "source": [
        "### Top 10 words in english"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af81be00",
      "metadata": {
        "id": "af81be00",
        "outputId": "1deb27c1-d447-484e-a81b-bae4683b1553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['?', 'the', 'When', 'was', 'What', 'is', 'of', 'How', 'in', 'did']\n"
          ]
        }
      ],
      "source": [
        "sorted_words_question = dict(sorted(bag_of_words_dict_eng.items(), key=lambda item:item[1], \n",
        "reverse=True))\n",
        "print(list(sorted_words_question)[:10]) #top 10 words in english questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f1c924c",
      "metadata": {
        "id": "4f1c924c",
        "outputId": "c67daf1c-97d0-4870-be45-a8f97e18a6c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "peninsula\n"
          ]
        }
      ],
      "source": [
        "print(list(sorted_words_question)[-1]) #least common"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "308fbfe2",
      "metadata": {
        "id": "308fbfe2"
      },
      "source": [
        "### Top 10 words in finnish questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f76aa8d",
      "metadata": {
        "id": "7f76aa8d",
        "outputId": "21758d91-e7e8-42cb-c2a5-1e6206898187"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['?', 'on', 'Milloin', 'Mikä', 'Missä', 'Kuka', 'oli', 'Mitä', 'syntyi', 'kuoli']\n"
          ]
        }
      ],
      "source": [
        "sorted_words_question = dict(sorted(bag_of_words_dict_finn.items(), key=lambda item:item[1], \n",
        "reverse=True))\n",
        "print(list(sorted_words_question)[:10]) #top 10 words in english questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b83e6a1",
      "metadata": {
        "id": "6b83e6a1",
        "outputId": "67c72b4e-3042-4936-a7d4-d4a466dc23bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "väestölaskennan\n"
          ]
        }
      ],
      "source": [
        "print(list(sorted_words_question)[-1]) #least common"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86b7f9b2",
      "metadata": {
        "id": "86b7f9b2"
      },
      "source": [
        "### Top 10 words in japanese questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fde165",
      "metadata": {
        "id": "58fde165",
        "outputId": "62bafe73-87a5-4b6f-dce3-7601b7cd4c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['は', 'の', '？', 'た', 'い', 'つ', '何', 'し', 'どこ', 'が']\n"
          ]
        }
      ],
      "source": [
        "sorted_words_question = dict(sorted(bag_of_words_dict_jap.items(), key=lambda item:item[1], \n",
        "reverse=True))\n",
        "print(list(sorted_words_question)[:10]) #top 10 words in english questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d660310a",
      "metadata": {
        "id": "d660310a",
        "outputId": "9cc109e6-906c-482e-9aa1-1213f730f3d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ウサギ\n"
          ]
        }
      ],
      "source": [
        "print(list(sorted_words_question)[-1]) #least common"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fa41cd2",
      "metadata": {
        "id": "4fa41cd2"
      },
      "source": [
        "# TfIdf vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd589a20",
      "metadata": {
        "id": "cd589a20"
      },
      "source": [
        "# English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90d14ca8",
      "metadata": {
        "id": "90d14ca8"
      },
      "outputs": [],
      "source": [
        "corpus_questions_eng_not_tokenized = [\" \".join(x) for x in corpus_questions_eng]\n",
        "corpus_context_eng_not_tokenized = [\" \".join(x) for x in corpus_context_eng]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee2184ff",
      "metadata": {
        "id": "ee2184ff"
      },
      "source": [
        "##### use tfidf for questions and then for context, concatenate the 2 and try to predict, for validation set use the same model of tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e549d070",
      "metadata": {
        "id": "e549d070",
        "outputId": "67239f5a-83d9-475e-ed84-1de3d1a742fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<7389x4603 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 50118 stored elements in Compressed Sparse Row format>,\n",
              " <7389x50037 sparse matrix of type '<class 'numpy.float64'>'\n",
              " \twith 455794 stored elements in Compressed Sparse Row format>)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer_questions = TfidfVectorizer()\n",
        "q = tfidf_vectorizer_questions.fit_transform(corpus_questions_eng_not_tokenized)\n",
        "\n",
        "tfidf_vectorizer_context = TfidfVectorizer() #new model\n",
        "c = tfidf_vectorizer_context.fit_transform(corpus_context_eng_not_tokenized) \n",
        "q,c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be05b3b2",
      "metadata": {
        "id": "be05b3b2"
      },
      "outputs": [],
      "source": [
        "#concatenate sparse matrices\n",
        "from scipy.sparse import hstack\n",
        "X = hstack([q,c]) #questions and contexts tfidfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "006e950c",
      "metadata": {
        "id": "006e950c",
        "outputId": "9f6e8e8a-cd55-40ac-9bda-55153f069758"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<7389x54640 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 505912 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1baaa9cc",
      "metadata": {
        "id": "1baaa9cc"
      },
      "outputs": [],
      "source": [
        "#why not use fit_transform also on validation set:\n",
        "#https://stats.stackexchange.com/questions/154660/tfidfvectorizer-should-it-be-used-on-train-only-or-traintest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aac13d2",
      "metadata": {
        "id": "4aac13d2"
      },
      "outputs": [],
      "source": [
        "#repeat process for validation set:\n",
        "corpus_questions_VAL_eng_not_t = [\" \".join(x) for x in corpus_questions_VAL_eng] # not tokenized\n",
        "corpus_context_VAL_eng_not_t = [\" \".join(x) for x in corpus_context_VAL_eng]\n",
        "q = tfidf_vectorizer_questions.transform(corpus_questions_VAL_eng_not_t) #ignores unknown words\n",
        "c = tfidf_vectorizer_context.transform(corpus_context_VAL_eng_not_t) #ignores unknown words\n",
        "\n",
        "X_VAL = hstack([q,c])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9de2389",
      "metadata": {
        "id": "c9de2389",
        "outputId": "f1fd737b-d93c-40a4-b74e-198cbbe829f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<990x54640 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 63594 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_VAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "367f0c99",
      "metadata": {
        "id": "367f0c99"
      },
      "outputs": [],
      "source": [
        "y = [] #-1 not answ, 1 is answ.\n",
        "Y_VAL = []\n",
        "for i in eng_training:\n",
        "    y.append(eng_training[i]['label'])\n",
        "    \n",
        "for i in eng_val:\n",
        "    Y_VAL.append(eng_val[i]['label'])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "741fe620",
      "metadata": {
        "id": "741fe620",
        "outputId": "b0eccadc-9d48-4cb5-f4d0-18f7122b52c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "89.21369603464609\n",
            "vald_set accuracy\n",
            "72.42424242424242\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(X, y)\n",
        "y_pred = LR.predict(X)\n",
        "#training accuracy score\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(Y_VAL, y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59329d38",
      "metadata": {
        "id": "59329d38"
      },
      "outputs": [],
      "source": [
        "features_eng = X\n",
        "features_val_eng = X_VAL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb45dc31",
      "metadata": {
        "id": "fb45dc31"
      },
      "source": [
        "# Finnish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17406dc",
      "metadata": {
        "id": "c17406dc",
        "outputId": "14ed55a6-adec-4ccf-8250-c64b256dc729"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "91.69403693161084\n",
            "vald_set accuracy\n",
            "71.23368920521945\n"
          ]
        }
      ],
      "source": [
        "#same as english\n",
        "corpus_questions_finn_not_tokenized = [\" \".join(x) for x in corpus_questions_finn]\n",
        "corpus_context_finn_not_tokenized = [\" \".join(x) for x in corpus_context_finn]\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer_questions = TfidfVectorizer()\n",
        "q = tfidf_vectorizer_questions.fit_transform(corpus_questions_finn_not_tokenized)\n",
        "\n",
        "tfidf_vectorizer_context = TfidfVectorizer() #new model\n",
        "c = tfidf_vectorizer_context.fit_transform(corpus_context_finn_not_tokenized) \n",
        "\n",
        "#concatenate sparse matrices\n",
        "from scipy.sparse import hstack\n",
        "X = hstack([q,c]) #questions and contexts tfidfs\n",
        "\n",
        "corpus_questions_VAL_finn_not_t = [\" \".join(x) for x in corpus_questions_VAL_finn] # not tokenized\n",
        "corpus_context_VAL_finn_not_t = [\" \".join(x) for x in corpus_context_VAL_finn]\n",
        "q = tfidf_vectorizer_questions.transform(corpus_questions_VAL_finn_not_t) #ignores unknown words\n",
        "c = tfidf_vectorizer_context.transform(corpus_context_VAL_finn_not_t) #ignores unknown words\n",
        "\n",
        "X_VAL = hstack([q,c])\n",
        "\n",
        "y = [] #-1 not answ, 1 is answ.\n",
        "Y_VAL = []\n",
        "for i in finn_training:\n",
        "    y.append(finn_training[i]['label'])\n",
        "    \n",
        "for i in finn_val:\n",
        "    Y_VAL.append(finn_val[i]['label'])\n",
        "    \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(X, y)\n",
        "y_pred = LR.predict(X)\n",
        "#training accuracy score\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(Y_VAL, y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ab4d7fe",
      "metadata": {
        "id": "4ab4d7fe"
      },
      "outputs": [],
      "source": [
        "features_finn = X\n",
        "features_val_finn = X_VAL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e61f8e79",
      "metadata": {
        "id": "e61f8e79"
      },
      "source": [
        "# Japanese\n",
        "##### overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bef4230",
      "metadata": {
        "id": "4bef4230",
        "outputId": "759ee844-e1e7-429b-9ed7-30a82e53e7f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "98.32535885167464\n",
            "vald_set accuracy\n",
            "57.91505791505791\n"
          ]
        }
      ],
      "source": [
        "#same as english\n",
        "corpus_questions_jap_not_tokenized = [\"\".join(x) for x in corpus_questions_jap] # no space in japanese\n",
        "corpus_context_jap_not_tokenized = [\"\".join(x) for x in corpus_context_jap]\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer_questions = TfidfVectorizer()\n",
        "q = tfidf_vectorizer_questions.fit_transform(corpus_questions_jap_not_tokenized)\n",
        "\n",
        "tfidf_vectorizer_context = TfidfVectorizer()\n",
        "c = tfidf_vectorizer_context.fit_transform(corpus_context_jap_not_tokenized) \n",
        "\n",
        "#concatenate sparse matrices\n",
        "from scipy.sparse import hstack\n",
        "X = hstack([q,c]) #questions and contexts tfidfs\n",
        "\n",
        "corpus_questions_VAL_jap_not_t = [\" \".join(x) for x in corpus_questions_VAL_jap] # not tokenized\n",
        "corpus_context_VAL_jap_not_t = [\" \".join(x) for x in corpus_context_VAL_jap]\n",
        "q = tfidf_vectorizer_questions.transform(corpus_questions_VAL_jap_not_t) #ignores unknown words\n",
        "c = tfidf_vectorizer_context.transform(corpus_context_VAL_jap_not_t) #ignores unknown words\n",
        "\n",
        "X_VAL = hstack([q,c])\n",
        "\n",
        "y = [] #-1 not answ, 1 is answ.\n",
        "Y_VAL = []\n",
        "for i in jap_training:\n",
        "    y.append(jap_training[i]['label'])\n",
        "    \n",
        "for i in jap_val:\n",
        "    Y_VAL.append(jap_val[i]['label'])\n",
        "    \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(X, y)\n",
        "y_pred = LR.predict(X)\n",
        "#training accuracy score\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(Y_VAL, y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9342e747",
      "metadata": {
        "id": "9342e747"
      },
      "outputs": [],
      "source": [
        "features_jap = X\n",
        "features_val_jap = X_VAL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80262d96",
      "metadata": {
        "id": "80262d96"
      },
      "source": [
        "#### maybe the problem is due to the tokenizer used in tfidf model, but I wasn't able to use janome..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7288cdc",
      "metadata": {
        "id": "e7288cdc"
      },
      "source": [
        "### --------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6c2ace1",
      "metadata": {
        "id": "a6c2ace1"
      },
      "source": [
        "# 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff873240",
      "metadata": {
        "id": "ff873240"
      },
      "source": [
        "##### CBOW (Continuous Bag of Words): CBOW model predicts the current word given context words within a specific window. The input layer contains the context words and the output layer contains the current word. The hidden layer contains the number of dimensions in which we want to represent the current word present at the output layer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfbbe307",
      "metadata": {
        "id": "cfbbe307"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8b29397",
      "metadata": {
        "id": "b8b29397"
      },
      "source": [
        "#### The model is trained on single words but I will get an avg of all the words rep for each sentence in order to obtain a sentence representation and not a single word one."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65fe9f7c",
      "metadata": {
        "id": "65fe9f7c"
      },
      "source": [
        "# English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d884de40",
      "metadata": {
        "id": "d884de40"
      },
      "outputs": [],
      "source": [
        "#min_count= ignore words with less than min_count value\n",
        "#window = window used for CBOW model\n",
        "import gensim\n",
        "vector_size = 500\n",
        "continous_rep_eng_questions = gensim.models.Word2Vec(corpus_questions_eng, min_count = 1,\n",
        "                              vector_size = vector_size, window = 5, epochs=5) \n",
        "continous_rep_eng_context = gensim.models.Word2Vec(corpus_context_eng, min_count = 1,\n",
        "                              vector_size = vector_size, window = 5, epochs=5) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d1b7cc9",
      "metadata": {
        "id": "8d1b7cc9"
      },
      "outputs": [],
      "source": [
        "#combination of representations of input level\n",
        "for i in eng_training:\n",
        "    sent = eng_training[i]['question']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        average_vector += continous_rep_eng_questions.wv[word]\n",
        "    average_vector = average_vector / n\n",
        "    eng_training[i]['CBOW_question'] = average_vector\n",
        "\n",
        "for i in eng_training:\n",
        "    sent = eng_training[i]['context']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        average_vector += continous_rep_eng_context.wv[word]\n",
        "    average_vector = average_vector / n\n",
        "    eng_training[i]['CBOW_context'] = average_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783716b5",
      "metadata": {
        "id": "783716b5"
      },
      "outputs": [],
      "source": [
        "for i in eng_val:\n",
        "    count_not_in_vocab = 0\n",
        "    sent = eng_val[i]['question']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        try:\n",
        "            average_vector += continous_rep_eng_questions.wv[word]\n",
        "        except:\n",
        "            count_not_in_vocab += 1\n",
        "            #print(\"word not in vocabulary\")\n",
        "    average_vector = average_vector / (n - count_not_in_vocab)\n",
        "    eng_val[i]['CBOW_question'] = average_vector\n",
        "    \n",
        "for i in eng_val:\n",
        "    count_not_in_vocab = 0\n",
        "    sent = eng_val[i]['context']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        try:\n",
        "            average_vector += continous_rep_eng_context.wv[word]\n",
        "        except:\n",
        "            count_not_in_vocab += 1\n",
        "            #print(\"word not in vocabulary\")\n",
        "    if n - count_not_in_vocab >0:\n",
        "        average_vector = average_vector / (n - count_not_in_vocab)\n",
        "    else:\n",
        "        average_vector = average_vector/1\n",
        "    eng_val[i]['CBOW_context'] = average_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a658f254",
      "metadata": {
        "id": "a658f254"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = [] #0 not answ, 1 is answ.\n",
        "X_VAL = []\n",
        "Y_VAL = []\n",
        "for i in eng_training:\n",
        "    X.append(list(np.concatenate((eng_training[i]['CBOW_question'],eng_training[i]['CBOW_context']),axis = None)))\n",
        "    y.append(eng_training[i]['label'])\n",
        "    \n",
        "for i in eng_val:\n",
        "    X_VAL.append(list(np.concatenate((eng_val[i]['CBOW_question'],eng_val[i]['CBOW_context']),axis = None)))\n",
        "    Y_VAL.append(eng_val[i]['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84de6469",
      "metadata": {
        "id": "84de6469",
        "outputId": "52102cb9-091f-465a-c2d3-e3b896ac82b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<7389x54640 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 505912 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_eng"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fbc2864",
      "metadata": {
        "id": "6fbc2864"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "CBOW_rep = csr_matrix(np.array(X))\n",
        "#lots of elements because it's not sparse... but in this way I can stack it to the previous rep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e8023b4",
      "metadata": {
        "id": "9e8023b4"
      },
      "outputs": [],
      "source": [
        "X = hstack([features_eng,CBOW_rep]) #features_eng = features of prev. representations, CBOW_rep current rep."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2db18453",
      "metadata": {
        "id": "2db18453",
        "outputId": "85a5e68f-2ee1-4156-d2c8-76caa9fd19ea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<7389x55640 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 7894912 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X # +200 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a38e55f",
      "metadata": {
        "id": "5a38e55f"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "CBOW_rep_val = csr_matrix(np.array(X_VAL))\n",
        "X_VAL = hstack([features_val_eng,CBOW_rep_val]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc90e727",
      "metadata": {
        "id": "dc90e727",
        "outputId": "5aaa2515-8422-4c30-b598-dcf893293cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "86.41223440249018\n",
            "vald_set accuracy\n",
            "72.02020202020202\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "\n",
        "LR.fit(X, y)\n",
        "y_pred = LR.predict(X)\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(Y_VAL, y_pred)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fc0d360",
      "metadata": {
        "id": "8fc0d360"
      },
      "source": [
        "## just CBOW:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51ab549e",
      "metadata": {
        "id": "51ab549e"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = [] #0 not answ, 1 is answ.\n",
        "X_VAL = []\n",
        "Y_VAL = []\n",
        "for i in eng_training:\n",
        "    X.append(list(np.concatenate((eng_training[i]['CBOW_question'],eng_training[i]['CBOW_context']),axis = None)))\n",
        "    y.append(eng_training[i]['label'])\n",
        "    \n",
        "for i in eng_val:\n",
        "    X_VAL.append(list(np.concatenate((eng_val[i]['CBOW_question'],eng_val[i]['CBOW_context']),axis = None)))\n",
        "    Y_VAL.append(eng_val[i]['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33cc67d2",
      "metadata": {
        "id": "33cc67d2",
        "outputId": "7a341ed1-f6e0-4f08-9cd2-760eaeb2d910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "69.69820002706726\n",
            "vald_set accuracy\n",
            "65.35353535353535\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "LR = LogisticRegression(random_state=0, max_iter=1000)\n",
        "#training decision tree\n",
        "LR.fit(X, y)\n",
        "y_pred = LR.predict(X)\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(Y_VAL, y_pred)*100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc950665",
      "metadata": {
        "id": "bc950665"
      },
      "source": [
        "# FINN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e467f178",
      "metadata": {
        "id": "e467f178",
        "outputId": "338dce23-433c-4660-8c1a-083f7f116970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "89.0299978103788\n",
            "vald_set accuracy\n",
            "70.22538552787663\n"
          ]
        }
      ],
      "source": [
        "#min_count= ignore words with less than min_count value\n",
        "#window = window used for CBOW model\n",
        "import gensim\n",
        "vector_size = 500\n",
        "continous_rep_finn_questions = gensim.models.Word2Vec(corpus_questions_finn, min_count = 1,\n",
        "                              vector_size = vector_size, window = 5, epochs=5) \n",
        "continous_rep_finn_context = gensim.models.Word2Vec(corpus_context_finn, min_count = 1,\n",
        "                              vector_size = vector_size, window = 5, epochs=5) \n",
        "#combination of representations of input level\n",
        "for i in finn_training:\n",
        "    sent = finn_training[i]['question']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        average_vector += continous_rep_finn_questions.wv[word]\n",
        "    average_vector = average_vector / n\n",
        "    finn_training[i]['CBOW_question'] = average_vector\n",
        "\n",
        "for i in finn_training:\n",
        "    sent =finn_training[i]['context']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        average_vector += continous_rep_finn_context.wv[word]\n",
        "    average_vector = average_vector / n\n",
        "    finn_training[i]['CBOW_context'] = average_vector\n",
        "    \n",
        "for i in finn_val:\n",
        "    count_not_in_vocab = 0\n",
        "    sent = finn_val[i]['question']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        try:\n",
        "            average_vector += continous_rep_finn_questions.wv[word]\n",
        "        except:\n",
        "            count_not_in_vocab += 1\n",
        "            #print(\"word not in vocabulary\")\n",
        "    average_vector = average_vector / (n - count_not_in_vocab)\n",
        "    finn_val[i]['CBOW_question'] = average_vector\n",
        "    \n",
        "for i in finn_val:\n",
        "    count_not_in_vocab = 0\n",
        "    sent = finn_val[i]['context']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        try:\n",
        "            average_vector += continous_rep_finn_context.wv[word]\n",
        "        except:\n",
        "            count_not_in_vocab += 1\n",
        "            #print(\"word not in vocabulary\")\n",
        "    if n - count_not_in_vocab >0:\n",
        "        average_vector = average_vector / (n - count_not_in_vocab)\n",
        "    else:\n",
        "        average_vector = average_vector/1\n",
        "    finn_val[i]['CBOW_context'] = average_vector\n",
        "    \n",
        "X = []\n",
        "y = [] #0 not answ, 1 is answ.\n",
        "X_VAL = []\n",
        "Y_VAL = []\n",
        "for i in finn_training:\n",
        "    X.append(list(np.concatenate((finn_training[i]['CBOW_question'],finn_training[i]['CBOW_context']),axis = None)))\n",
        "    y.append(finn_training[i]['label'])\n",
        "    \n",
        "for i in finn_val:\n",
        "    X_VAL.append(list(np.concatenate((finn_val[i]['CBOW_question'],finn_val[i]['CBOW_context']),axis = None)))\n",
        "    Y_VAL.append(finn_val[i]['label'])\n",
        "\n",
        "CBOW_rep = csr_matrix(np.array(X))\n",
        "\n",
        "X = hstack([features_finn,CBOW_rep]) #features_eng = features of prev. representations, CBOW_rep current rep.\n",
        "\n",
        "CBOW_rep_val = csr_matrix(np.array(X_VAL))\n",
        "X_VAL = hstack([features_val_finn,CBOW_rep_val])\n",
        "                \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "\n",
        "LR.fit(X, y)\n",
        "y_pred = LR.predict(X)\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(Y_VAL, y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed6a343d",
      "metadata": {
        "id": "ed6a343d",
        "outputId": "8038a9dd-2424-4f32-95fc-df51089ca8f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "69.60805780599955\n",
            "vald_set accuracy\n",
            "64.70937129300118\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "y = [] #0 not answ, 1 is answ.\n",
        "X_VAL = []\n",
        "Y_VAL = []\n",
        "for i in finn_training:\n",
        "    X.append(list(np.concatenate((finn_training[i]['CBOW_question'],finn_training[i]['CBOW_context']),axis = None)))\n",
        "    y.append(finn_training[i]['label'])\n",
        "    \n",
        "for i in finn_val:\n",
        "    X_VAL.append(list(np.concatenate((finn_val[i]['CBOW_question'],finn_val[i]['CBOW_context']),axis = None)))\n",
        "    Y_VAL.append(finn_val[i]['label'])\n",
        "    \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "LR = LogisticRegression(random_state=0, max_iter=1000)\n",
        "#training decision tree\n",
        "LR.fit(X, y)\n",
        "y_pred = LR.predict(X)\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(Y_VAL, y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2a928d8",
      "metadata": {
        "id": "c2a928d8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b043ecb1",
      "metadata": {
        "id": "b043ecb1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "76123b01",
      "metadata": {
        "id": "76123b01"
      },
      "source": [
        "# JAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77ad4fc",
      "metadata": {
        "id": "e77ad4fc",
        "outputId": "c5bd61be-4482-4c90-cd9e-e643610c3364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "88.50535429482798\n",
            "vald_set accuracy\n",
            "64.1891891891892\n"
          ]
        }
      ],
      "source": [
        "#min_count= ignore words with less than min_count value\n",
        "#window = window used for CBOW model\n",
        "import gensim\n",
        "vector_size = 500\n",
        "continous_rep_jap_questions = gensim.models.Word2Vec(corpus_questions_jap, min_count = 1,\n",
        "                              vector_size = vector_size, window = 5, epochs=5) \n",
        "continous_rep_jap_context = gensim.models.Word2Vec(corpus_context_jap, min_count = 1,\n",
        "                              vector_size = vector_size, window = 5, epochs=5) \n",
        "#combination of representations of input level\n",
        "for i in jap_training:\n",
        "    sent = jap_training[i]['question']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        average_vector += continous_rep_jap_questions.wv[word]\n",
        "    average_vector = average_vector / n\n",
        "    jap_training[i]['CBOW_question'] = average_vector\n",
        "\n",
        "for i in jap_training:\n",
        "    sent =jap_training[i]['context']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        average_vector += continous_rep_jap_context.wv[word]\n",
        "    average_vector = average_vector / n\n",
        "    jap_training[i]['CBOW_context'] = average_vector\n",
        "    \n",
        "for i in jap_val:\n",
        "    count_not_in_vocab = 0\n",
        "    sent = jap_val[i]['question']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        try:\n",
        "            average_vector += continous_rep_jap_questions.wv[word]\n",
        "        except:\n",
        "            count_not_in_vocab += 1\n",
        "            #print(\"word not in vocabulary\")\n",
        "    average_vector = average_vector / (n - count_not_in_vocab)\n",
        "    jap_val[i]['CBOW_question'] = average_vector\n",
        "    \n",
        "for i in jap_val:\n",
        "    count_not_in_vocab = 0\n",
        "    sent = jap_val[i]['context']\n",
        "    n = len(sent)\n",
        "    average_vector = np.zeros(vector_size)\n",
        "    for word in sent:\n",
        "        try:\n",
        "            average_vector += continous_rep_jap_context.wv[word]\n",
        "        except:\n",
        "            count_not_in_vocab += 1\n",
        "            #print(\"word not in vocabulary\")\n",
        "    if n - count_not_in_vocab >0:\n",
        "        average_vector = average_vector / (n - count_not_in_vocab)\n",
        "    else:\n",
        "        average_vector = average_vector/1\n",
        "    jap_val[i]['CBOW_context'] = average_vector\n",
        "    \n",
        "X = []\n",
        "y = [] #0 not answ, 1 is answ.\n",
        "X_VAL = []\n",
        "Y_VAL = []\n",
        "for i in jap_training:\n",
        "    X.append(list(np.concatenate((jap_training[i]['CBOW_question'],jap_training[i]['CBOW_context']),axis = None)))\n",
        "    y.append(jap_training[i]['label'])\n",
        "    \n",
        "for i in jap_val:\n",
        "    X_VAL.append(list(np.concatenate((jap_val[i]['CBOW_question'],jap_val[i]['CBOW_context']),axis = None)))\n",
        "    Y_VAL.append(jap_val[i]['label'])\n",
        "\n",
        "CBOW_rep = csr_matrix(np.array(X))\n",
        "\n",
        "X = hstack([features_jap,CBOW_rep]) #features_eng = features of prev. representations, CBOW_rep current rep.\n",
        "\n",
        "CBOW_rep_val = csr_matrix(np.array(X_VAL))\n",
        "X_VAL = hstack([features_val_jap,CBOW_rep_val])\n",
        "                \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "\n",
        "LR.fit(X, y)\n",
        "y_pred = LR.predict(X)\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(Y_VAL, y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81e33d14",
      "metadata": {
        "id": "81e33d14",
        "outputId": "a9536053-1095-4bda-c02b-404718e0ce40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "68.22738664843928\n",
            "vald_set accuracy\n",
            "63.32046332046332\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "y = [] #0 not answ, 1 is answ.\n",
        "X_VAL = []\n",
        "Y_VAL = []\n",
        "for i in jap_training:\n",
        "    X.append(list(np.concatenate((jap_training[i]['CBOW_question'],jap_training[i]['CBOW_context']),axis = None)))\n",
        "    y.append(jap_training[i]['label'])\n",
        "    \n",
        "for i in jap_val:\n",
        "    X_VAL.append(list(np.concatenate((jap_val[i]['CBOW_question'],jap_val[i]['CBOW_context']),axis = None)))\n",
        "    Y_VAL.append(jap_val[i]['label'])\n",
        "    \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "LR = LogisticRegression(random_state=0, max_iter=1000)\n",
        "#training decision tree\n",
        "LR.fit(X, y)\n",
        "y_pred = LR.predict(X)\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(Y_VAL, y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977ea663",
      "metadata": {
        "id": "977ea663"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5b3e1516",
      "metadata": {
        "id": "5b3e1516"
      },
      "source": [
        "# Week 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b70fa9b",
      "metadata": {
        "id": "6b70fa9b"
      },
      "source": [
        "### utility functions from lab3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1287e498",
      "metadata": {
        "id": "1287e498"
      },
      "outputs": [],
      "source": [
        "def question_parag_combine(questions, paragraphs):\n",
        "    \"\"\"\n",
        "    This function combines the questions and paragraphs into a single text\n",
        "    Args:\n",
        "        questions: list of questions\n",
        "        paragraphs: list of paragraphs\n",
        "    Returns:\n",
        "        list of combined questions and paragraphs\n",
        "    \"\"\"\n",
        "    training_data = []\n",
        "    for index in range(len(questions)):\n",
        "        training_data += [questions[index] + \"\\n\" + paragraphs[index]]\n",
        "        \n",
        "    return training_data\n",
        "\n",
        "def get_data_with_cond(data_set, cond, vectorizer):\n",
        "    \"\"\"\n",
        "    This function returns the data with the given condition (can be used to get data for a particular language).\n",
        "    vectorizer is used to vectorize the data: it can be a CountVectorizer or a TfidfVectorizer, etc.\n",
        "    If vectorizer is None, then the combined data is returned as is.\n",
        "    Args:\n",
        "        data_set: pandas dataframe\n",
        "        cond: condition to be applied\n",
        "        vectorizer: vectorizer to be used\n",
        "    Returns:\n",
        "        data with the given condition\n",
        "    \"\"\"\n",
        "\n",
        "    d_q = data_set[cond]['question_text'].tolist()\n",
        "    d_p = data_set[cond]['document_plaintext'].tolist()\n",
        "    data = question_parag_combine(d_q,d_p)\n",
        "\n",
        "    print(len(d_q))\n",
        "    if vectorizer is None:\n",
        "        return data \n",
        "    \n",
        "    X = vectorizer.transform(data)\n",
        "    y = data_set[cond]['answerable'].tolist()\n",
        "    \n",
        "    return X,y\n",
        "\n",
        "#example use \n",
        "# cond_eng = validation_set['language'] == 'english'\n",
        "# X_eng, y_eng = get_data_with_cond(validation_set, cond_eng, vectorizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f4b3526",
      "metadata": {
        "id": "9f4b3526"
      },
      "source": [
        "#### Re-formatting data for the transformers use case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14bd25c8",
      "metadata": {
        "id": "14bd25c8"
      },
      "outputs": [],
      "source": [
        "training_labels_eng = []\n",
        "training_data_eng = question_parag_combine(corpus_questions_eng_not_tokenized, corpus_context_eng_not_tokenized)\n",
        "for i in eng_training:\n",
        "    training_labels_eng.append(eng_training[i]['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2d41ea6",
      "metadata": {
        "id": "e2d41ea6"
      },
      "outputs": [],
      "source": [
        "validation_labels_eng = []\n",
        "validation_data_eng = question_parag_combine(corpus_questions_VAL_eng_not_t, corpus_context_VAL_eng_not_t)\n",
        "for i in eng_val:\n",
        "    validation_labels_eng.append(eng_val[i]['label'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1a1d740",
      "metadata": {
        "id": "d1a1d740"
      },
      "source": [
        "## lab3 tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a1dbb48",
      "metadata": {
        "id": "6a1dbb48",
        "outputId": "01186e6d-b320-42cd-cf3b-32cb67ba1c1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  3.80ba/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.78ba/s]\n"
          ]
        }
      ],
      "source": [
        "from datasets import DatasetDict, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "data_set = {}\n",
        "sets = [['train',training_data_eng, training_labels_eng], ['val',validation_data_eng, validation_labels_eng]]\n",
        "for meta in sets:\n",
        "    data_set[meta[0]] = {}\n",
        "    data_set[meta[0]]['text'] = []\n",
        "    data_set[meta[0]]['label'] = []\n",
        "    \n",
        "    for ind, text in enumerate(meta[1]):\n",
        "        data_set[meta[0]]['text'].append(text)\n",
        "        data_set[meta[0]]['label'].append(meta[2][ind])\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "data_set = DatasetDict({'train':Dataset.from_dict(data_set['train']),\n",
        "                        'valid':Dataset.from_dict(data_set['val'])\\\n",
        "                       })\n",
        "\n",
        "# training_data = tokenize_data(training_data)\n",
        "#  validation_data = tokenize_data(validation_data)\n",
        "tokenized_datasets = data_set.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "736001bc",
      "metadata": {
        "id": "736001bc",
        "outputId": "02e65b72-fc93-41eb-8704-33edd06d2283"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': Value(dtype='string', id=None),\n",
              " 'label': Value(dtype='int64', id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc46c8c8",
      "metadata": {
        "id": "bc46c8c8",
        "outputId": "39a600ae-96fa-4d06-a0af-7d01bf5f0cac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenized_datasets['valid'][0]['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "319bbf0d",
      "metadata": {
        "id": "319bbf0d"
      },
      "source": [
        "### English"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a7d417",
      "metadata": {
        "id": "b2a7d417",
        "outputId": "7fe17d6e-6154-412a-8017-b6aefe47e6dd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "NOTE: Redirects are currently not supported in Windows or MacOs.\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f88989e",
      "metadata": {
        "id": "9f88989e",
        "outputId": "657f09c8-2708-4080-ec32-527bc6a6d7f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ],
      "source": [
        "#layers that will be trained with these settings:\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        print(name) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12abf551",
      "metadata": {
        "id": "12abf551",
        "outputId": "d9235fcb-15dd-41b5-86c7-51b5ecc8d58c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I will be frozen: bert.embeddings.word_embeddings.weight\n",
            "I will be frozen: bert.embeddings.position_embeddings.weight\n",
            "I will be frozen: bert.embeddings.token_type_embeddings.weight\n",
            "I will be frozen: bert.embeddings.LayerNorm.weight\n",
            "I will be frozen: bert.embeddings.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.0.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.0.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.0.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.0.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.0.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.0.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.1.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.1.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.1.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.1.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.1.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.1.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.2.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.2.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.2.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.2.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.2.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.2.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.3.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.3.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.3.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.3.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.3.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.3.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.4.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.4.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.4.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.4.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.4.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.4.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.5.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.5.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.5.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.5.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.5.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.5.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.6.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.6.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.6.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.6.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.6.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.6.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.7.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.7.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.7.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.7.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.7.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.7.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.8.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.8.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.8.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.8.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.8.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.8.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.9.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.9.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.9.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.9.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.9.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.9.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.10.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.10.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.10.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.10.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.10.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.10.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.11.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.11.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.11.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.11.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.11.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.11.output.LayerNorm.bias\n",
            "I will be frozen: bert.pooler.dense.weight\n",
            "I will be frozen: bert.pooler.dense.bias\n"
          ]
        }
      ],
      "source": [
        "# I want to train only the last layer:\n",
        "for name, param in list(model.named_parameters())[:len(list(model.parameters())) - 2]: \n",
        "    print('I will be frozen: {}'.format(name)) \n",
        "    param.requires_grad = False #do not require gradint computation\n",
        "    \n",
        "#basically freeze everything except calssification layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7276374c",
      "metadata": {
        "id": "7276374c",
        "outputId": "933bdd08-4594-4df4-d52e-b2f89558ce5f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
          ]
        }
      ],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "metric = load_metric('f1')\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", num_train_epochs=5, \\\n",
        "                                  do_train = True)\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ca320c",
      "metadata": {
        "id": "64ca320c"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['valid'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba46ed5",
      "metadata": {
        "id": "9ba46ed5"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "388dd1a0",
      "metadata": {
        "id": "388dd1a0"
      },
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "468538c6",
      "metadata": {
        "id": "468538c6"
      },
      "source": [
        "## ONLY for training, do not run this cell, load the model from local files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4371470c",
      "metadata": {
        "id": "4371470c",
        "outputId": "42dc7244-a7db-4da3-8fa7-a3260425c9a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "C:\\Users\\fiori\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 7389\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4620\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4620' max='4620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4620/4620 50:42, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.687200</td>\n",
              "      <td>0.678378</td>\n",
              "      <td>0.655462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.684100</td>\n",
              "      <td>0.669713</td>\n",
              "      <td>0.624418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.681600</td>\n",
              "      <td>0.668308</td>\n",
              "      <td>0.610301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.678900</td>\n",
              "      <td>0.666906</td>\n",
              "      <td>0.607843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.680100</td>\n",
              "      <td>0.667998</td>\n",
              "      <td>0.630314</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to test_trainer\\checkpoint-500\n",
            "Configuration saved in test_trainer\\checkpoint-500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-500\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 990\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-1000\n",
            "Configuration saved in test_trainer\\checkpoint-1000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-1000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-1500\n",
            "Configuration saved in test_trainer\\checkpoint-1500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-1500\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 990\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-2000\n",
            "Configuration saved in test_trainer\\checkpoint-2000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-2000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-2500\n",
            "Configuration saved in test_trainer\\checkpoint-2500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-2500\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 990\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-3000\n",
            "Configuration saved in test_trainer\\checkpoint-3000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-3000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-3500\n",
            "Configuration saved in test_trainer\\checkpoint-3500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-3500\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 990\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-4000\n",
            "Configuration saved in test_trainer\\checkpoint-4000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-4000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-4500\n",
            "Configuration saved in test_trainer\\checkpoint-4500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-4500\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 990\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4620, training_loss=0.6798232916629676, metrics={'train_runtime': 3043.6259, 'train_samples_per_second': 12.138, 'train_steps_per_second': 1.518, 'total_flos': 9720637940275200.0, 'train_loss': 0.6798232916629676, 'epoch': 5.0})"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20e0bff9",
      "metadata": {
        "id": "20e0bff9",
        "outputId": "2739004e-af6c-44a9-e5d2-45a1511e3c45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to BERT_fine_tuned_english\n",
            "Configuration saved in BERT_fine_tuned_english\\config.json\n",
            "Model weights saved in BERT_fine_tuned_english\\pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "#SAVE MODEL\n",
        "output_dir = \"BERT_fine_tuned_english\"\n",
        "trainer.save_model(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cfba14f",
      "metadata": {
        "id": "9cfba14f"
      },
      "outputs": [],
      "source": [
        "#LOAD MODEL\n",
        "output_dir = \"BERT_fine_tuned_english\"\n",
        "m = AutoModelForSequenceClassification.from_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc24c18",
      "metadata": {
        "id": "ccc24c18"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "133ba7a9",
      "metadata": {
        "id": "133ba7a9"
      },
      "source": [
        "# FINN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723ee3b0",
      "metadata": {
        "id": "723ee3b0",
        "outputId": "644a27c5-2b35-42bc-c8cf-f53583381e2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\vocab.txt\n",
            "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer_config.json\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:04<00:00,  3.41ba/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  4.21ba/s]\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I will be frozen: bert.embeddings.word_embeddings.weight\n",
            "I will be frozen: bert.embeddings.position_embeddings.weight\n",
            "I will be frozen: bert.embeddings.token_type_embeddings.weight\n",
            "I will be frozen: bert.embeddings.LayerNorm.weight\n",
            "I will be frozen: bert.embeddings.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.0.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.0.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.0.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.0.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.0.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.0.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.1.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.1.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.1.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.1.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.1.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.1.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.2.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.2.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.2.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.2.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.2.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.2.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.3.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.3.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.3.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.3.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.3.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.3.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.4.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.4.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.4.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.4.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.4.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.4.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.5.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.5.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.5.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.5.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.5.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.5.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.6.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.6.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.6.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.6.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.6.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.6.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.7.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.7.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.7.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.7.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.7.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.7.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.8.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.8.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.8.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.8.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.8.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.8.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.9.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.9.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.9.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.9.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.9.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.9.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.10.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.10.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.10.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.10.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.10.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.10.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.11.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.11.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.11.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.11.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.11.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.11.output.LayerNorm.bias\n",
            "I will be frozen: bert.pooler.dense.weight\n",
            "I will be frozen: bert.pooler.dense.bias\n"
          ]
        }
      ],
      "source": [
        "training_labels_finn = []\n",
        "training_data_finn = question_parag_combine(corpus_questions_finn_not_tokenized, corpus_context_finn_not_tokenized)\n",
        "for i in finn_training:\n",
        "    training_labels_finn.append(finn_training[i]['label'])\n",
        "    \n",
        "validation_labels_finn = []\n",
        "validation_data_finn = question_parag_combine(corpus_questions_VAL_finn_not_t, corpus_context_VAL_finn_not_t)\n",
        "for i in finn_val:\n",
        "    validation_labels_finn.append(finn_val[i]['label'])\n",
        "    \n",
        "from datasets import DatasetDict, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "data_set = {}\n",
        "sets = [['train',training_data_finn, training_labels_finn], ['val',validation_data_finn, validation_labels_finn]]\n",
        "for meta in sets:\n",
        "    data_set[meta[0]] = {}\n",
        "    data_set[meta[0]]['text'] = []\n",
        "    data_set[meta[0]]['label'] = []\n",
        "    \n",
        "    for ind, text in enumerate(meta[1]):\n",
        "        data_set[meta[0]]['text'].append(text)\n",
        "        data_set[meta[0]]['label'].append(meta[2][ind])\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "data_set = DatasetDict({'train':Dataset.from_dict(data_set['train']),\n",
        "                        'valid':Dataset.from_dict(data_set['val'])\\\n",
        "                       })\n",
        "\n",
        "# training_data = tokenize_data(training_data)\n",
        "#  validation_data = tokenize_data(validation_data)\n",
        "tokenized_datasets = data_set.map(tokenize_function, batched=True)\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "\n",
        "# I want to train only the last layer:\n",
        "for name, param in list(model.named_parameters())[:len(list(model.parameters())) - 2]: \n",
        "    print('I will be frozen: {}'.format(name)) \n",
        "    param.requires_grad = False #do not require gradint computation\n",
        "    \n",
        "#basically freeze everything except calssification layer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['valid'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b4be44f",
      "metadata": {
        "id": "3b4be44f",
        "outputId": "a93f94a3-df0d-4f00-8b81-5204e26ab6cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "C:\\Users\\fiori\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 13701\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 8565\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8565' max='8565' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8565/8565 1:33:19, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.690700</td>\n",
              "      <td>0.684212</td>\n",
              "      <td>0.580805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.685800</td>\n",
              "      <td>0.680502</td>\n",
              "      <td>0.654726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.680500</td>\n",
              "      <td>0.675453</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.680200</td>\n",
              "      <td>0.675543</td>\n",
              "      <td>0.655276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.678000</td>\n",
              "      <td>0.674581</td>\n",
              "      <td>0.654068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to test_trainer\\checkpoint-500\n",
            "Configuration saved in test_trainer\\checkpoint-500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-1000\n",
            "Configuration saved in test_trainer\\checkpoint-1000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-1000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-1500\n",
            "Configuration saved in test_trainer\\checkpoint-1500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-1500\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1686\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-2000\n",
            "Configuration saved in test_trainer\\checkpoint-2000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-2000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-2500\n",
            "Configuration saved in test_trainer\\checkpoint-2500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-2500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-3000\n",
            "Configuration saved in test_trainer\\checkpoint-3000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-3000\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1686\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-3500\n",
            "Configuration saved in test_trainer\\checkpoint-3500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-3500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-4000\n",
            "Configuration saved in test_trainer\\checkpoint-4000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-4000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-4500\n",
            "Configuration saved in test_trainer\\checkpoint-4500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-4500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-5000\n",
            "Configuration saved in test_trainer\\checkpoint-5000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-5000\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1686\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-5500\n",
            "Configuration saved in test_trainer\\checkpoint-5500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-5500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-6000\n",
            "Configuration saved in test_trainer\\checkpoint-6000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-6000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-6500\n",
            "Configuration saved in test_trainer\\checkpoint-6500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-6500\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1686\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-7000\n",
            "Configuration saved in test_trainer\\checkpoint-7000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-7000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-7500\n",
            "Configuration saved in test_trainer\\checkpoint-7500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-7500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-8000\n",
            "Configuration saved in test_trainer\\checkpoint-8000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-8000\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-8500\n",
            "Configuration saved in test_trainer\\checkpoint-8500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-8500\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1686\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=8565, training_loss=0.6846630530683047, metrics={'train_runtime': 5600.0456, 'train_samples_per_second': 12.233, 'train_steps_per_second': 1.529, 'total_flos': 1.80244228474368e+16, 'train_loss': 0.6846630530683047, 'epoch': 5.0})"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b16d6c43",
      "metadata": {
        "id": "b16d6c43",
        "outputId": "dbe160b7-679c-4264-94a0-ed220dc5287c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to BERT_fine_tuned_finn\n",
            "Configuration saved in BERT_fine_tuned_finn\\config.json\n",
            "Model weights saved in BERT_fine_tuned_finn\\pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "#SAVE MODEL\n",
        "output_dir = \"BERT_fine_tuned_finn\"\n",
        "trainer.save_model(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3267a917",
      "metadata": {
        "id": "3267a917"
      },
      "source": [
        "# JAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a7e9400",
      "metadata": {
        "id": "3a7e9400",
        "outputId": "fc17f53f-cb8a-4ca9-e3e4-0fd275729420"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\vocab.txt\n",
            "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer_config.json\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:06<00:00,  1.48ba/s]\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  6.27ba/s]\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I will be frozen: bert.embeddings.word_embeddings.weight\n",
            "I will be frozen: bert.embeddings.position_embeddings.weight\n",
            "I will be frozen: bert.embeddings.token_type_embeddings.weight\n",
            "I will be frozen: bert.embeddings.LayerNorm.weight\n",
            "I will be frozen: bert.embeddings.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.0.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.0.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.0.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.0.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.0.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.0.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.1.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.1.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.1.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.1.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.1.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.1.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.2.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.2.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.2.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.2.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.2.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.2.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.3.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.3.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.3.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.3.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.3.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.3.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.4.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.4.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.4.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.4.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.4.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.4.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.5.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.5.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.5.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.5.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.5.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.5.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.6.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.6.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.6.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.6.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.6.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.6.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.7.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.7.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.7.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.7.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.7.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.7.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.8.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.8.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.8.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.8.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.8.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.8.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.9.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.9.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.9.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.9.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.9.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.9.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.10.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.10.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.10.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.10.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.10.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.10.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.query.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.query.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.key.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.key.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.value.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.self.value.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "I will be frozen: bert.encoder.layer.11.intermediate.dense.weight\n",
            "I will be frozen: bert.encoder.layer.11.intermediate.dense.bias\n",
            "I will be frozen: bert.encoder.layer.11.output.dense.weight\n",
            "I will be frozen: bert.encoder.layer.11.output.dense.bias\n",
            "I will be frozen: bert.encoder.layer.11.output.LayerNorm.weight\n",
            "I will be frozen: bert.encoder.layer.11.output.LayerNorm.bias\n",
            "I will be frozen: bert.pooler.dense.weight\n",
            "I will be frozen: bert.pooler.dense.bias\n"
          ]
        }
      ],
      "source": [
        "training_labels_jap = []\n",
        "training_data_jap = question_parag_combine(corpus_questions_jap_not_tokenized, corpus_context_jap_not_tokenized)\n",
        "for i in jap_training:\n",
        "    training_labels_jap.append(jap_training[i]['label'])\n",
        "    \n",
        "validation_labels_jap = []\n",
        "validation_data_jap = question_parag_combine(corpus_questions_VAL_jap_not_t, corpus_context_VAL_jap_not_t)\n",
        "for i in jap_val:\n",
        "    validation_labels_jap.append(jap_val[i]['label'])\n",
        "    \n",
        "from datasets import DatasetDict, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "data_set = {}\n",
        "sets = [['train',training_data_jap, training_labels_jap], ['val',validation_data_jap, validation_labels_jap]]\n",
        "for meta in sets:\n",
        "    data_set[meta[0]] = {}\n",
        "    data_set[meta[0]]['text'] = []\n",
        "    data_set[meta[0]]['label'] = []\n",
        "    \n",
        "    for ind, text in enumerate(meta[1]):\n",
        "        data_set[meta[0]]['text'].append(text)\n",
        "        data_set[meta[0]]['label'].append(meta[2][ind])\n",
        "\n",
        "        \n",
        "\n",
        "        \n",
        "data_set = DatasetDict({'train':Dataset.from_dict(data_set['train']),\n",
        "                        'valid':Dataset.from_dict(data_set['val'])\\\n",
        "                       })\n",
        "\n",
        "# training_data = tokenize_data(training_data)\n",
        "#  validation_data = tokenize_data(validation_data)\n",
        "tokenized_datasets = data_set.map(tokenize_function, batched=True)\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
        "\n",
        "# I want to train only the last layer:\n",
        "for name, param in list(model.named_parameters())[:len(list(model.parameters())) - 2]: \n",
        "    print('I will be frozen: {}'.format(name)) \n",
        "    param.requires_grad = False #do not require gradint computation\n",
        "    \n",
        "#basically freeze everything except calssification layer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['valid'],\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a08ee49",
      "metadata": {
        "id": "6a08ee49",
        "outputId": "da3791e7-0601-459c-c51b-52eb5fb96ae3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "C:\\Users\\fiori\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 8778\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5490\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5490' max='5490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5490/5490 59:29, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.689700</td>\n",
              "      <td>0.684787</td>\n",
              "      <td>0.497431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.680505</td>\n",
              "      <td>0.646417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.683900</td>\n",
              "      <td>0.678723</td>\n",
              "      <td>0.645719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.686300</td>\n",
              "      <td>0.678615</td>\n",
              "      <td>0.656442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.683900</td>\n",
              "      <td>0.676857</td>\n",
              "      <td>0.631148</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to test_trainer\\checkpoint-500\n",
            "Configuration saved in test_trainer\\checkpoint-500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-1000\n",
            "Configuration saved in test_trainer\\checkpoint-1000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-1000\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1036\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-1500\n",
            "Configuration saved in test_trainer\\checkpoint-1500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-1500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-2000\n",
            "Configuration saved in test_trainer\\checkpoint-2000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-2000\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1036\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-2500\n",
            "Configuration saved in test_trainer\\checkpoint-2500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-2500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-3000\n",
            "Configuration saved in test_trainer\\checkpoint-3000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-3000\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1036\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-3500\n",
            "Configuration saved in test_trainer\\checkpoint-3500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-3500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-4000\n",
            "Configuration saved in test_trainer\\checkpoint-4000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-4000\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1036\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to test_trainer\\checkpoint-4500\n",
            "Configuration saved in test_trainer\\checkpoint-4500\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-4500\\pytorch_model.bin\n",
            "Saving model checkpoint to test_trainer\\checkpoint-5000\n",
            "Configuration saved in test_trainer\\checkpoint-5000\\config.json\n",
            "Model weights saved in test_trainer\\checkpoint-5000\\pytorch_model.bin\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1036\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5490, training_loss=0.6868556399597279, metrics={'train_runtime': 3570.3129, 'train_samples_per_second': 12.293, 'train_steps_per_second': 1.538, 'total_flos': 1.15479442197504e+16, 'train_loss': 0.6868556399597279, 'epoch': 5.0})"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17c77a34",
      "metadata": {
        "id": "17c77a34",
        "outputId": "334b351c-32b8-474a-8272-6c1e41a2b40d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to BERT_fine_tuned_jap\n",
            "Configuration saved in BERT_fine_tuned_jap\\config.json\n",
            "Model weights saved in BERT_fine_tuned_jap\\pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "#SAVE MODEL\n",
        "output_dir = \"BERT_fine_tuned_jap\"\n",
        "trainer.save_model(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "954d80cc",
      "metadata": {
        "id": "954d80cc"
      },
      "source": [
        "# SAMPLING FROM THE MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5479b7a",
      "metadata": {
        "id": "a5479b7a"
      },
      "source": [
        "### BERT (pre-trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a9c40c3",
      "metadata": {
        "id": "5a9c40c3",
        "outputId": "e3d8f84e-d81c-4ece-f89d-6ababcda2dba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\pytorch_model.bin\n",
            "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertLMHeadModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertLMHeadModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "\n",
        "prompt = [\"Today I would like to buy\"]\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True).input_ids\n",
        "\n",
        "outputs = model.generate(input_ids, do_sample=False, max_length=50)\n",
        "sentence_BERT = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c4f869d",
      "metadata": {
        "id": "0c4f869d",
        "outputId": "08563cc5-1695-4014-b623-f511a2814aef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Today I would like to buy..........................................']"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f3a922c",
      "metadata": {
        "id": "4f3a922c"
      },
      "source": [
        "### GPT2 (pre-trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b01fa0d",
      "metadata": {
        "id": "6b01fa0d",
        "outputId": "878b1f73-f923-48ef-a44a-7e6a6206cf72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file vocab.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\vocab.json\n",
            "loading file merges.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\merges.txt\n",
            "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "\n",
        "prompt = \"Today I would like to buy\"\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# generate up to 30 tokens\n",
        "outputs = model.generate(input_ids, do_sample=False, max_length=30)\n",
        "sentence_GPT2 = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57b01057",
      "metadata": {
        "id": "57b01057",
        "outputId": "c2fc1970-51f2-4085-b9df-c693a9595ea7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Today I would like to buy a new car. I am a big fan of the BMW i3 and I am looking forward to the new car.']"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_GPT2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a73280",
      "metadata": {
        "id": "82a73280"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3241bcdd",
      "metadata": {
        "id": "3241bcdd"
      },
      "source": [
        "# PERPLEXITY, Given a model and an input text sequence, perplexity measures how likely the model is to generate the input text sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "758d1d53",
      "metadata": {
        "id": "758d1d53"
      },
      "source": [
        "### gpt2 (on validation data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a59bc511",
      "metadata": {
        "id": "a59bc511",
        "outputId": "32184f5d-d59d-48b6-c513-839767c46768"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "loading file vocab.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\vocab.json\n",
            "loading file merges.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\merges.txt\n",
            "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
            "Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "Using pad_token, but it is not set yet.\n",
            "Assigning <|endoftext|> to the pad_token key of the tokenizer\n",
            "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [01:00<00:00,  1.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['perplexities', 'mean_perplexity']\n",
            "112.91\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
        "\n",
        "results = perplexity.compute(model_id='gpt2', predictions=validation_data_eng)\n",
        "print(list(results.keys()))\n",
        "print(round(results[\"mean_perplexity\"], 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2856b117",
      "metadata": {
        "id": "2856b117"
      },
      "source": [
        "### BERT (on validation data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba77ea32",
      "metadata": {
        "scrolled": true,
        "id": "ba77ea32",
        "outputId": "5bbe57e2-d180-4a32-a447-d183b51e8dfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\pytorch_model.bin\n",
            "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertLMHeadModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertLMHeadModel for predictions without further training.\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\vocab.txt\n",
            "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer_config.json\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:43<00:00,  1.43it/s]\n"
          ]
        }
      ],
      "source": [
        "from evaluate import load\n",
        "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
        "results = perplexity.compute(predictions=validation_data_eng, model_id='bert-base-cased', add_start_token=False) \n",
        "#perplexity based on the base model, aka the tokenizer used before the classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94421db",
      "metadata": {
        "id": "a94421db",
        "outputId": "43e71aa9-5bdc-4a3e-a628-d5bd3fa4fed4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3918316.53"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "round(results[\"mean_perplexity\"], 2) #a lower perplexity indicates a better model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82d811f1",
      "metadata": {
        "id": "82d811f1"
      },
      "source": [
        "# LAST HIDDEN STATE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9da4a87",
      "metadata": {
        "id": "e9da4a87"
      },
      "source": [
        "## TOO MUCH MEMORY NEEDED, use pooled representation? is PCA ok?\n",
        "## used PCA to reduce dimensionality in order to have enough memory to store the tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "948b6227",
      "metadata": {
        "id": "948b6227",
        "outputId": "a8c6943f-9cea-47e7-9e42-4e74c412d124"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\vocab.txt\n",
            "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer_config.json\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "100%|██████████████████████████████████████████████████████████████████████████████| 7389/7389 [34:12<00:00,  3.60it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "tensors_train_eng = []\n",
        "\n",
        "pca = PCA(n_components=5)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "for k in tqdm(training_data_eng):#element by element\n",
        "    i = tokenizer(k, return_tensors=\"pt\", padding = True, truncation=True)\n",
        "    o = m(**i, output_hidden_states=True)\n",
        "    tensor_reduced = pca.fit_transform(o.hidden_states[-1][0].detach().numpy())\n",
        "    tensors_train_eng.append(tensor_reduced)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a9b4add",
      "metadata": {
        "id": "6a9b4add"
      },
      "outputs": [],
      "source": [
        "#more compression\n",
        "X = []\n",
        "for i in tensors_train_eng:\n",
        "    X.append(np.array(np.mean(np.asmatrix(i), axis=0))[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77344866",
      "metadata": {
        "scrolled": true,
        "id": "77344866",
        "outputId": "b32885cd-5056-4814-a0a0-590c43b3cd38"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\vocab.txt\n",
            "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer_config.json\n",
            "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "100%|████████████████████████████████████████████████████████████████████████████████| 990/990 [04:47<00:00,  3.45it/s]\n"
          ]
        }
      ],
      "source": [
        "tensors_val_eng = []\n",
        "\n",
        "pca = PCA(n_components=5)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "for k in tqdm(validation_data_eng):#element by element\n",
        "    i = tokenizer(k, return_tensors=\"pt\", padding = True, truncation=True)\n",
        "    o = m(**i, output_hidden_states=True)\n",
        "    tensor_reduced = pca.fit_transform(o.hidden_states[-1][0].detach().numpy())\n",
        "    tensors_val_eng.append(tensor_reduced)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c72cb29b",
      "metadata": {
        "id": "c72cb29b"
      },
      "outputs": [],
      "source": [
        "#more compression\n",
        "X_VAL = []\n",
        "for i in tensors_val_eng:\n",
        "    X_VAL.append(np.array(np.mean(np.asmatrix(i), axis=0))[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb16305",
      "metadata": {
        "id": "dbb16305",
        "outputId": "0ad04e21-9cbc-4903-bb0f-f714a65ba8d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_set accuracy\n",
            "50.02030044660982\n",
            "vald_set accuracy\n",
            "50.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(X, training_labels_eng)\n",
        "y_pred = LR.predict(X)\n",
        "#training accuracy score\n",
        "print(\"train_set accuracy\")\n",
        "print(accuracy_score(y, y_pred)*100)\n",
        "\n",
        "#accuracy score on val_set\n",
        "y_pred = LR.predict(X_VAL)\n",
        "print(\"vald_set accuracy\")\n",
        "print(accuracy_score(validation_labels_eng, y_pred)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155cabcd",
      "metadata": {
        "id": "155cabcd",
        "outputId": "cdb0bd58-fc89-4eff-b5e1-7ba85d16b7f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[matrix([[-3.2564489e-07,  0.0000000e+00, -1.6136867e-07, -4.3613156e-08,\n",
              "           1.4392342e-07]], dtype=float32),\n",
              " matrix([[3.3609666e-07, 1.4704230e-07, 8.6124771e-08, 2.3316707e-07,\n",
              "          4.2012083e-08]], dtype=float32),\n",
              " matrix([[-1.03801284e-07, -5.19006420e-08,  1.03801284e-07,\n",
              "          -3.24379030e-08,  3.85200103e-08]], dtype=float32),\n",
              " matrix([[-6.1307634e-07, -1.1353266e-08, -1.2488593e-07, -1.2346676e-07,\n",
              "          -5.0734904e-08]], dtype=float32),\n",
              " matrix([[ 1.4128508e-07,  1.6483260e-07, -6.7699105e-08,  3.8626890e-08,\n",
              "           2.0456903e-07]], dtype=float32),\n",
              " matrix([[ 6.9247687e-07,  1.8450865e-07,  1.4274742e-07,  1.2148718e-08,\n",
              "          -1.3743237e-07]], dtype=float32),\n",
              " matrix([[-8.1478970e-07, -1.4814358e-07,  1.2962563e-07, -1.5624518e-07,\n",
              "           3.9784652e-08]], dtype=float32),\n",
              " matrix([[-5.8843733e-07,  3.0436414e-08, -5.0727356e-09, -1.8769123e-07,\n",
              "           1.3315932e-07]], dtype=float32),\n",
              " matrix([[-6.90591719e-07, -4.16547408e-07, -1.78128829e-07,\n",
              "          -9.04346322e-08,  1.14113774e-07]], dtype=float32),\n",
              " matrix([[-4.82582209e-07,  9.26385439e-08,  5.74502579e-09,\n",
              "          -1.01256084e-07, -1.79532069e-08]], dtype=float32),\n",
              " matrix([[-1.7339534e-07, -2.8537983e-07,  7.2248056e-09, -3.2511625e-08,\n",
              "           9.6631773e-08]], dtype=float32),\n",
              " matrix([[ 3.0825836e-07,  2.5045992e-07, -8.6697668e-08, -4.7262269e-08,\n",
              "           2.5286820e-08]], dtype=float32),\n",
              " matrix([[ 5.9604645e-08,  8.8303175e-08, -8.8303175e-08, -7.8369069e-08,\n",
              "           2.4835268e-08]], dtype=float32),\n",
              " matrix([[ 1.77427779e-07,  2.88320138e-07,  2.80003206e-07,\n",
              "          -1.12278514e-07, -4.15846344e-08]], dtype=float32),\n",
              " matrix([[ 3.1292439e-07,  3.5390258e-08, -3.1199306e-08,  2.9662624e-07,\n",
              "          -3.1664968e-08]], dtype=float32),\n",
              " matrix([[-4.4672112e-07, -6.6255268e-07, -3.1119899e-07, -3.2123768e-07,\n",
              "           1.2893426e-07]], dtype=float32),\n",
              " matrix([[-3.92458560e-07, -2.31550558e-07,  7.45671258e-08,\n",
              "          -2.65890691e-07, -1.09397824e-07]], dtype=float32),\n",
              " matrix([[-4.7683716e-07, -1.5894572e-07,  1.3789783e-07, -1.3044725e-07,\n",
              "          -1.7583370e-07]], dtype=float32),\n",
              " matrix([[4.82582209e-07, 6.24771559e-08, 1.12791021e-07, 1.50806926e-07,\n",
              "          1.02333274e-07]], dtype=float32),\n",
              " matrix([[-7.1663391e-07,  1.4194863e-07, -2.7562841e-09, -1.4608305e-07,\n",
              "          -3.2407871e-07]], dtype=float32),\n",
              " matrix([[-1.1464937e-06, -6.5662823e-07, -4.1690680e-07, -4.8465415e-07,\n",
              "          -8.0775692e-08]], dtype=float32),\n",
              " matrix([[ 8.0577831e-07,  5.2401089e-07, -2.2664881e-07,  3.8248970e-07,\n",
              "           1.4279615e-07]], dtype=float32),\n",
              " matrix([[ 2.11927627e-07,  1.05963814e-07,  1.36239194e-07,\n",
              "          -5.67663285e-08,  9.46105505e-09]], dtype=float32),\n",
              " matrix([[-1.2507203e-07, -7.8170022e-09, -6.9131616e-08, -2.3451008e-08,\n",
              "          -9.7712531e-09]], dtype=float32),\n",
              " matrix([[-7.8733575e-07, -4.3248022e-07, -3.8535097e-07, -1.4082464e-07,\n",
              "           1.4416007e-07]], dtype=float32),\n",
              " matrix([[2.0699908e-07, 1.9221343e-07, 9.6106717e-08, 6.8845672e-08,\n",
              "          1.2937443e-07]], dtype=float32),\n",
              " matrix([[ 9.7101383e-07,  3.9013948e-08,  3.0560926e-07, -3.5464763e-07,\n",
              "           6.4210461e-08]], dtype=float32),\n",
              " matrix([[4.2701836e-07, 5.3377295e-08, 7.1169723e-08, 6.0049459e-08,\n",
              "          1.9215825e-07]], dtype=float32),\n",
              " matrix([[1.5676838e-07, 1.9269447e-07, 3.5926089e-08, 6.7769662e-08,\n",
              "          5.6759646e-08]], dtype=float32),\n",
              " matrix([[-3.1789146e-08, -1.5894572e-07, -1.2185839e-07,  1.3245477e-07,\n",
              "          -7.3512396e-08]], dtype=float32),\n",
              " matrix([[ 7.1704832e-08,  6.4534355e-08,  1.3130948e-07,  7.1704838e-09,\n",
              "          -7.2601146e-08]], dtype=float32),\n",
              " matrix([[-2.0290942e-08, -1.0145472e-07,  1.2428202e-07,  1.0462517e-07,\n",
              "          -3.4875058e-08]], dtype=float32),\n",
              " matrix([[ 2.6769806e-07, -1.0038677e-07,  5.4376166e-08, -1.8822519e-08,\n",
              "           1.2130069e-07]], dtype=float32),\n",
              " matrix([[-2.98023224e-07,  7.45058060e-09,  2.04890966e-08,\n",
              "          -2.79396772e-08,  1.17346644e-07]], dtype=float32),\n",
              " matrix([[-1.5258789e-07,  3.0517580e-08, -6.9618224e-08, -1.0395050e-07,\n",
              "           3.8862229e-08]], dtype=float32),\n",
              " matrix([[-1.2761539e-06, -8.1013161e-07,  3.6328109e-07, -6.6953834e-07,\n",
              "          -4.5041449e-07]], dtype=float32),\n",
              " matrix([[ 1.0459654e-06, -1.1985020e-07, -1.8201848e-07, -2.8200047e-08,\n",
              "           1.3971841e-07]], dtype=float32),\n",
              " matrix([[5.8939531e-07, 3.1925578e-07, 2.1155812e-07, 2.4660463e-07,\n",
              "          1.4734883e-07]], dtype=float32),\n",
              " matrix([[ 7.5759175e-07,  4.5455505e-07, -2.5401604e-07,  2.6738531e-08,\n",
              "           4.6346790e-07]], dtype=float32),\n",
              " matrix([[-3.3171281e-07, -1.6499257e-07, -1.0020491e-07,  1.0366025e-08,\n",
              "          -1.3950942e-07]], dtype=float32),\n",
              " matrix([[ 7.41746703e-07,  1.03020376e-07, -7.35859800e-08,\n",
              "          -2.47248892e-07, -1.21416875e-07]], dtype=float32),\n",
              " matrix([[ 6.05507537e-08, -4.54130635e-08, -1.07382974e-07,\n",
              "          -3.78442202e-08,  1.55161302e-07]], dtype=float32),\n",
              " matrix([[ 3.0116030e-07, -1.3552214e-07, -5.0193385e-08,  1.4054147e-07,\n",
              "           9.5367433e-08]], dtype=float32),\n",
              " matrix([[-2.5920380e-07, -1.7117232e-07, -1.9807082e-07,  1.4427381e-07,\n",
              "          -5.2421520e-08]], dtype=float32),\n",
              " matrix([[ 1.0561351e-06, -1.3989850e-07,  3.2708664e-07,  2.0196616e-08,\n",
              "           2.2782767e-07]], dtype=float32),\n",
              " matrix([[-5.8715656e-08,  1.8423253e-07,  2.6009300e-07,  7.5860456e-08,\n",
              "          -7.3151156e-08]], dtype=float32),\n",
              " matrix([[-3.7923891e-07, -3.0116030e-07, -2.8164067e-07, -2.1053337e-07,\n",
              "           8.6444160e-08]], dtype=float32),\n",
              " matrix([[-4.59044713e-07, -1.71696968e-07, -4.91071091e-07,\n",
              "          -2.65107218e-07, -1.12092316e-07]], dtype=float32),\n",
              " matrix([[-8.5669046e-07, -1.7780368e-07, -3.4257516e-07,  6.1423094e-08,\n",
              "           2.1496504e-07]], dtype=float32),\n",
              " matrix([[-2.2496934e-06,  1.6709679e-07, -7.4378448e-08, -1.4671913e-07,\n",
              "          -1.6811566e-07]], dtype=float32),\n",
              " matrix([[ 4.6992648e-07,  2.8074652e-07, -1.2007312e-07,  1.0366025e-08,\n",
              "           1.3216682e-07]], dtype=float32),\n",
              " matrix([[1.0250377e-06, 1.3461730e-07, 1.4840340e-07, 6.2037486e-08,\n",
              "          3.7587418e-07]], dtype=float32),\n",
              " matrix([[-9.7455768e-08,  1.6358646e-07,  5.7429293e-08,  6.4390420e-08,\n",
              "          -8.1793232e-08]], dtype=float32),\n",
              " matrix([[-2.7247839e-07, -2.4977186e-07, -1.7597561e-07, -1.4191582e-07,\n",
              "           2.0152046e-07]], dtype=float32),\n",
              " matrix([[-2.4360159e-07, -1.9177146e-07,  6.9970667e-08, -9.3294226e-08,\n",
              "           2.1128875e-07]], dtype=float32),\n",
              " matrix([[-1.2407025e-06, -2.0832691e-07, -3.9350638e-07, -1.8749422e-07,\n",
              "          -3.1234569e-07]], dtype=float32),\n",
              " matrix([[ 2.68220901e-07,  2.08616257e-07, -8.38190317e-09,\n",
              "          -2.27242708e-07,  1.09896064e-07]], dtype=float32),\n",
              " matrix([[ 4.5610509e-08,  8.2928198e-09, -1.3268512e-07, -4.2500702e-08,\n",
              "          -6.6342558e-08]], dtype=float32),\n",
              " matrix([[-8.7074613e-07, -4.7683716e-07,  4.5351358e-09, -1.5549038e-07,\n",
              "           3.1098075e-08]], dtype=float32),\n",
              " matrix([[ 2.1305490e-07, -4.0581885e-08,  2.2827312e-08,  4.3435300e-08,\n",
              "          -8.8772873e-09]], dtype=float32),\n",
              " matrix([[-3.2367129e-07, -1.0403720e-07, -3.3812088e-07,  2.2396897e-08,\n",
              "           6.7551930e-08]], dtype=float32),\n",
              " matrix([[ 3.4679065e-08,  2.6587284e-07,  2.9047104e-07, -7.8027895e-08,\n",
              "           1.6183564e-07]], dtype=float32),\n",
              " matrix([[ 2.8108295e-07,  3.2625699e-08, -6.2428022e-08,  8.3716095e-08,\n",
              "           2.3841858e-08]], dtype=float32),\n",
              " matrix([[-2.8750475e-07, -7.0123114e-08,  2.8049245e-08, -1.3060429e-07,\n",
              "          -3.4886247e-07]], dtype=float32),\n",
              " matrix([[ 1.8673343e-07,  1.1670839e-07, -4.3348834e-08, -8.5030400e-08,\n",
              "          -2.9593915e-08]], dtype=float32),\n",
              " matrix([[ 3.9268943e-07,  3.9444249e-08,  1.2271545e-07,  0.0000000e+00,\n",
              "          -2.0730145e-07]], dtype=float32),\n",
              " matrix([[ 3.3992353e-07, -2.8326960e-08,  9.2062621e-08,  7.4358269e-08,\n",
              "           1.8943655e-07]], dtype=float32),\n",
              " matrix([[ 1.1051926e-06,  3.1640596e-07,  1.4531243e-07, -2.4482469e-07,\n",
              "           2.4853256e-07]], dtype=float32),\n",
              " matrix([[7.0642540e-07, 6.1812223e-08, 4.0619463e-07, 3.7749609e-07,\n",
              "          2.2075794e-08]], dtype=float32),\n",
              " matrix([[-1.0389623e-06, -5.9604645e-08, -1.9383624e-07,  9.2072213e-08,\n",
              "          -2.1176609e-07]], dtype=float32),\n",
              " matrix([[-3.45139284e-07, -1.22615276e-07, -2.40689246e-07,\n",
              "          -1.24885929e-07,  1.13248824e-07]], dtype=float32),\n",
              " matrix([[-4.2217994e-07, -1.0707633e-07,  3.5809904e-08, -7.6331638e-08,\n",
              "           1.3428715e-07]], dtype=float32),\n",
              " matrix([[-1.0981704e-06,  1.8784495e-07, -2.8537983e-07, -1.4548388e-07,\n",
              "           1.2643409e-07]], dtype=float32),\n",
              " matrix([[3.1305396e-07, 5.8049739e-08, 9.1221018e-08, 2.3634537e-07,\n",
              "          2.4463819e-07]], dtype=float32),\n",
              " matrix([[ 8.2611280e-07, -1.2452435e-07,  6.8336536e-09,  8.2763137e-08,\n",
              "           2.4563187e-07]], dtype=float32),\n",
              " matrix([[-5.9665780e-07, -2.0051614e-07, -1.8584423e-07, -4.6461057e-08,\n",
              "          -1.7911960e-07]], dtype=float32),\n",
              " matrix([[-9.1867707e-07,  9.1867712e-08, -1.9139107e-07, -7.6009592e-08,\n",
              "          -1.2659152e-07]], dtype=float32),\n",
              " matrix([[ 5.2018601e-07,  5.9002577e-08,  1.5375289e-07,  1.4509817e-07,\n",
              "          -6.4722215e-08]], dtype=float32),\n",
              " matrix([[-3.9567340e-07, -9.1309246e-08, -1.1667292e-07,  6.9750115e-08,\n",
              "          -1.3315932e-07]], dtype=float32),\n",
              " matrix([[-4.9802992e-07, -3.1789145e-07,  9.8016528e-08, -3.4968059e-07,\n",
              "           7.1525577e-08]], dtype=float32),\n",
              " matrix([[-2.5221138e-07,  1.1231288e-07, -3.5861308e-07, -1.3398730e-07,\n",
              "           1.1939402e-07]], dtype=float32),\n",
              " matrix([[-1.5745227e-06, -2.1281659e-07, -2.8482219e-07, -1.3121023e-07,\n",
              "           1.8321428e-07]], dtype=float32),\n",
              " matrix([[-3.1140385e-07, -2.2382153e-07,  1.8611246e-07, -1.4597056e-08,\n",
              "          -2.7612765e-07]], dtype=float32),\n",
              " matrix([[ 6.4556417e-07, -7.3359563e-09,  1.2700374e-07,  8.6197488e-08,\n",
              "           8.6197488e-08]], dtype=float32),\n",
              " matrix([[ 7.7220591e-08,  7.3359566e-08, -2.2200920e-08, -1.6698954e-07,\n",
              "          -2.8957723e-09]], dtype=float32),\n",
              " matrix([[1.0640998e-06, 1.3050280e-07, 1.9449936e-07, 3.1245384e-07,\n",
              "          1.7818651e-07]], dtype=float32),\n",
              " matrix([[8.7838424e-07, 3.7645037e-08, 1.4528632e-07, 1.7097122e-07,\n",
              "          7.5290075e-08]], dtype=float32),\n",
              " matrix([[8.6115369e-07, 5.3733140e-07, 1.6191113e-07, 9.7413562e-08,\n",
              "          3.1136756e-07]], dtype=float32),\n",
              " matrix([[-1.4805903e-07, -1.0015758e-07,  1.3499499e-07,  1.9903936e-07,\n",
              "          -2.4957743e-07]], dtype=float32),\n",
              " matrix([[-2.8649475e-07, -1.8445553e-07, -1.6090802e-07, -1.7366291e-07,\n",
              "           9.8114645e-09]], dtype=float32),\n",
              " matrix([[-5.8884586e-07, -1.8561447e-07, -1.7361353e-07,  5.1604022e-08,\n",
              "          -2.0001560e-08]], dtype=float32),\n",
              " matrix([[ 3.8532295e-07, -1.9266148e-08, -3.8532296e-08,  2.3119378e-07,\n",
              "           1.0475968e-07]], dtype=float32),\n",
              " matrix([[ 1.0644886e-06,  9.5367432e-07,  7.3036681e-08,  3.2740580e-08,\n",
              "          -5.2049128e-08]], dtype=float32),\n",
              " matrix([[ 3.0711547e-07, -9.4963333e-08,  8.3513854e-08, -1.2122978e-08,\n",
              "           8.4187349e-08]], dtype=float32),\n",
              " matrix([[-3.8146972e-08,  9.5367430e-09, -9.1393787e-08,  1.6540289e-07,\n",
              "          -6.3578291e-08]], dtype=float32),\n",
              " matrix([[-2.9550472e-07, -9.5913109e-08, -2.4681361e-07,  3.5426987e-07,\n",
              "           6.7160162e-09]], dtype=float32),\n",
              " matrix([[ 3.7703404e-07, -7.2080034e-08,  5.5446183e-08, -2.7723091e-08,\n",
              "          -1.1851621e-07]], dtype=float32),\n",
              " matrix([[ 5.2981907e-08,  7.9472862e-08,  2.5497542e-07, -1.3411045e-07,\n",
              "           1.9081764e-07]], dtype=float32),\n",
              " matrix([[ 6.5251402e-07, -1.7881393e-07, -9.4112593e-09,  8.0779976e-08,\n",
              "           2.3057586e-07]], dtype=float32),\n",
              " matrix([[ 1.9426699e-07,  1.6612036e-07,  1.8764425e-07, -1.4349267e-08,\n",
              "           2.2627690e-08]], dtype=float32),\n",
              " matrix([[ 9.2477512e-07,  9.3922473e-08,  3.3505034e-07, -1.4449611e-08,\n",
              "          -2.2803292e-08]], dtype=float32),\n",
              " matrix([[-1.3449253e-06, -2.2924863e-07, -2.8732495e-07, -1.5588907e-07,\n",
              "          -4.9097416e-08]], dtype=float32),\n",
              " matrix([[-4.4504802e-07, -6.3578291e-08,  7.7486035e-08, -2.8014182e-07,\n",
              "          -1.8725792e-07]], dtype=float32),\n",
              " matrix([[-2.18876067e-07, -2.05847741e-07,  8.07756919e-08,\n",
              "          -1.09438034e-07,  2.89880511e-08]], dtype=float32),\n",
              " matrix([[1.78676908e-06, 5.20684239e-07, 1.53464839e-07, 2.44584584e-07,\n",
              "          1.18181624e-07]], dtype=float32),\n",
              " matrix([[3.7398994e-08, 1.7764522e-07, 1.0109415e-07, 2.9451706e-07,\n",
              "          1.2972775e-07]], dtype=float32),\n",
              " matrix([[-2.8207268e-07, -1.8206700e-07, -2.6864065e-08,  2.9382571e-08,\n",
              "           1.6790041e-08]], dtype=float32),\n",
              " matrix([[ 5.8174135e-07,  4.7683717e-08,  2.8610231e-07,  4.4107438e-08,\n",
              "          -2.8610229e-08]], dtype=float32),\n",
              " matrix([[-6.7268098e-07, -7.9827650e-08, -4.6832220e-08,  2.9270138e-08,\n",
              "          -2.1925995e-07]], dtype=float32),\n",
              " matrix([[ 1.0652745e-06, -2.6378225e-07, -2.0449466e-08, -1.0145472e-07,\n",
              "           1.2265717e-07]], dtype=float32),\n",
              " matrix([[ 7.7850967e-07,  8.4338545e-08, -3.4059799e-08,  2.4166238e-07,\n",
              "           1.9097814e-07]], dtype=float32),\n",
              " matrix([[-5.2756451e-07, -3.9567340e-07, -2.1812764e-07, -1.8261849e-07,\n",
              "          -7.8627401e-08]], dtype=float32),\n",
              " matrix([[-1.3602086e-07,  8.5586159e-08, -2.3326048e-07,  9.1699455e-08,\n",
              "           1.0392605e-07]], dtype=float32),\n",
              " matrix([[-4.6004712e-07,  1.4103634e-07, -2.8543070e-08,  7.7863817e-08,\n",
              "           7.1567548e-08]], dtype=float32),\n",
              " matrix([[-6.8989203e-07,  9.1309246e-08, -2.1643672e-07, -1.1498201e-07,\n",
              "          -4.6838261e-07]], dtype=float32),\n",
              " matrix([[-1.0868690e-06, -1.0122800e-07, -1.5700330e-07,  1.4984408e-07,\n",
              "          -6.6514119e-08]], dtype=float32),\n",
              " matrix([[-1.21116636e-06, -1.14440915e-07, -8.58306919e-08,\n",
              "           8.10623177e-08, -5.37931903e-08]], dtype=float32),\n",
              " matrix([[-6.1307634e-07, -1.7516467e-07, -2.1895584e-08, -3.0653817e-07,\n",
              "           5.8388224e-08]], dtype=float32),\n",
              " matrix([[5.0028814e-07, 1.6806555e-07, 1.7832537e-07, 1.7114960e-08,\n",
              "          1.5145442e-08]], dtype=float32),\n",
              " matrix([[ 5.32778927e-07, -2.83704793e-07,  1.14547476e-07,\n",
              "           7.72529489e-08,  5.11967286e-08]], dtype=float32),\n",
              " matrix([[-3.3824901e-07,  1.3154128e-07,  2.2315039e-08,  9.3958059e-09,\n",
              "           6.6357877e-08]], dtype=float32),\n",
              " matrix([[ 4.1439421e-07, -2.9329270e-08,  1.3955055e-07,  2.7626280e-07,\n",
              "          -4.5413064e-08]], dtype=float32),\n",
              " matrix([[9.83949704e-08, 6.81195971e-08, 1.51376884e-08, 1.13532657e-07,\n",
              "          1.03125494e-07]], dtype=float32),\n",
              " matrix([[-3.0003238e-07, -1.7278650e-07, -2.5047345e-07, -1.5269505e-07,\n",
              "           9.6313407e-08]], dtype=float32),\n",
              " matrix([[-1.1270696e-06,  4.3792173e-07,  8.6697668e-08,  4.1193704e-08,\n",
              "          -2.9900843e-07]], dtype=float32),\n",
              " matrix([[-4.9146405e-07, -2.0569088e-07, -1.6089598e-07, -1.6089597e-08,\n",
              "          -7.1489005e-08]], dtype=float32),\n",
              " matrix([[-4.3934995e-07, -1.1096211e-06,  6.5977468e-07, -1.0076559e-06,\n",
              "          -5.6980542e-07]], dtype=float32),\n",
              " matrix([[-2.2980105e-07, -2.2980103e-08,  0.0000000e+00,  9.3356675e-08,\n",
              "           9.4792931e-08]], dtype=float32),\n",
              " matrix([[ 1.0234554e-06, -3.2564489e-07,  2.6361730e-07,  9.7887302e-08,\n",
              "          -3.4405934e-07]], dtype=float32),\n",
              " matrix([[-7.9842499e-07, -3.7703404e-07, -1.6264214e-07, -1.8482061e-07,\n",
              "          -2.8647193e-08]], dtype=float32),\n",
              " matrix([[1.6442661e-07, 1.2057951e-07, 2.7404434e-08, 9.3175075e-08,\n",
              "          5.4808869e-09]], dtype=float32),\n",
              " matrix([[ 5.9604645e-07,  4.0729842e-07, -7.4505806e-08,  1.9868216e-08,\n",
              "           7.5437129e-08]], dtype=float32),\n",
              " matrix([[ 2.2706532e-08, -3.6898115e-08,  2.2706531e-07,  2.7354275e-07,\n",
              "          -8.0182438e-08]], dtype=float32),\n",
              " matrix([[1.0982621e-06, 1.0468066e-06, 2.7008355e-08, 9.9185854e-08,\n",
              "          7.6368451e-08]], dtype=float32),\n",
              " matrix([[ 2.2587024e-07,  8.7838423e-08,  2.0077354e-07, -1.7253976e-07,\n",
              "          -2.1959606e-08]], dtype=float32),\n",
              " matrix([[-3.5321271e-08,  2.4724889e-07,  1.4128508e-07, -3.8264709e-08,\n",
              "           1.3834165e-07]], dtype=float32),\n",
              " matrix([[ 1.9491154e-07, -1.7402815e-08, -9.6096173e-08,  8.2445844e-08,\n",
              "          -7.4723339e-08]], dtype=float32),\n",
              " matrix([[-8.1603059e-07, -4.5225792e-07, -2.6545572e-07, -1.3641476e-07,\n",
              "           1.2904098e-07]], dtype=float32),\n",
              " matrix([[-9.7585280e-07, -8.7604968e-07,  8.3169276e-09, -3.7133780e-08,\n",
              "          -5.5446183e-08]], dtype=float32),\n",
              " matrix([[ 1.3411045e-07, -4.9670536e-08, -4.5324366e-08, -2.9802322e-08,\n",
              "           6.2088169e-08]], dtype=float32),\n",
              " matrix([[-8.4310341e-07,  1.4512435e-07, -3.0234241e-07,  1.7276708e-08,\n",
              "          -1.9004380e-08]], dtype=float32),\n",
              " matrix([[-1.0149195e-06, -2.4060591e-07, -1.5092552e-07, -2.8653977e-07,\n",
              "          -2.0779601e-07]], dtype=float32),\n",
              " matrix([[-3.4877232e-07,  1.9209726e-07, -1.8256051e-07,  1.1989049e-07,\n",
              "          -1.7438616e-07]], dtype=float32),\n",
              " matrix([[ 5.2495835e-08,  9.6242360e-08, -4.3746528e-08,  5.6870487e-08,\n",
              "          -6.3432466e-08]], dtype=float32),\n",
              " matrix([[-1.4086954e-06, -3.7710652e-07, -9.3497485e-09, -4.7216227e-07,\n",
              "           2.0024044e-07]], dtype=float32),\n",
              " matrix([[-8.7420148e-07, -2.2075795e-09, -6.6227386e-08, -3.1789145e-07,\n",
              "          -8.7268376e-08]], dtype=float32),\n",
              " matrix([[ 6.8425067e-08, -4.2765667e-09, -5.7733647e-08, -1.0156845e-07,\n",
              "           7.8448267e-08]], dtype=float32),\n",
              " matrix([[ 2.6876276e-07,  3.4679065e-08, -8.6697662e-09, -1.9940462e-07,\n",
              "          -6.7190690e-08]], dtype=float32),\n",
              " matrix([[ 5.5101185e-07,  1.3642841e-07,  1.9735761e-07, -1.6821755e-07,\n",
              "          -1.2185839e-07]], dtype=float32),\n",
              " matrix([[-2.2114187e-07, -1.6132127e-07,  3.1098075e-08, -7.0402585e-08,\n",
              "           2.2459721e-08]], dtype=float32),\n",
              " matrix([[-4.8155835e-07, -4.3434673e-07,  2.3133684e-07, -1.1094726e-07,\n",
              "          -8.9702041e-08]], dtype=float32),\n",
              " matrix([[-3.2660080e-07,  6.5320158e-08, -5.2256127e-08,  8.8998718e-08,\n",
              "          -2.5005374e-08]], dtype=float32),\n",
              " matrix([[6.7318190e-08, 5.6098490e-09, 9.5367433e-08, 1.1570314e-08,\n",
              "          2.5244320e-08]], dtype=float32),\n",
              " matrix([[ 2.2125244e-07,  2.2888184e-08,  8.5830692e-08,  1.6939640e-07,\n",
              "          -7.3432922e-08]], dtype=float32),\n",
              " matrix([[ 4.7039342e-07,  6.4437451e-08,  3.0124511e-07, -1.3249951e-07,\n",
              "          -4.8328088e-09]], dtype=float32),\n",
              " matrix([[-5.4836274e-08, -2.6702881e-07, -3.5285950e-07, -1.3828277e-07,\n",
              "          -7.6293944e-08]], dtype=float32),\n",
              " matrix([[ 2.0154089e-07,  1.6466319e-07,  3.4712201e-07,  1.1149070e-07,\n",
              "          -5.8747023e-08]], dtype=float32),\n",
              " matrix([[ 2.0385419e-06,  3.2546029e-07,  4.4498495e-07,  4.2133232e-07,\n",
              "          -7.5057699e-08]], dtype=float32),\n",
              " matrix([[ 2.2942166e-07,  2.7890476e-07, -2.2492319e-09, -1.4395084e-07,\n",
              "          -2.6990783e-08]], dtype=float32),\n",
              " matrix([[5.4041544e-07, 2.8014182e-07, 2.3345153e-07, 1.5695890e-07,\n",
              "          2.9057265e-08]], dtype=float32),\n",
              " matrix([[-3.1972897e-07, -8.1654917e-08,  6.8562571e-08,  8.5444810e-08,\n",
              "          -9.0957379e-08]], dtype=float32),\n",
              " matrix([[ 9.8826355e-08, -2.7177247e-08,  1.3588624e-07,  1.2723893e-07,\n",
              "          -1.1426797e-08]], dtype=float32),\n",
              " matrix([[-2.18876067e-07, -1.65012040e-07,  1.78813934e-07,\n",
              "          -5.32533306e-08, -1.10415165e-07]], dtype=float32),\n",
              " matrix([[-4.6083591e-07, -1.3121023e-07,  5.7604488e-08,  3.9303064e-08,\n",
              "          -6.0804737e-08]], dtype=float32),\n",
              " matrix([[-4.8008093e-07, -3.9736431e-08, -1.2143940e-07, -3.7303586e-08,\n",
              "           4.6743523e-08]], dtype=float32),\n",
              " matrix([[-1.2466332e-07, -2.2751054e-07, -5.6098489e-08, -1.9634471e-07,\n",
              "          -2.0101959e-07]], dtype=float32),\n",
              " matrix([[-9.0101747e-07, -1.7625423e-07,  7.0209154e-08,  3.3641886e-08,\n",
              "          -2.4865741e-08]], dtype=float32),\n",
              " matrix([[-2.1409015e-07,  7.1768859e-08,  8.2716653e-08, -2.8038511e-07,\n",
              "           1.7638110e-08]], dtype=float32),\n",
              " matrix([[-9.74557679e-08, -2.26236612e-08,  1.84469855e-07,\n",
              "           6.30852099e-08,  1.12248166e-07]], dtype=float32),\n",
              " matrix([[ 2.4151493e-07, -4.6445177e-08,  6.9667763e-08,  6.6184377e-08,\n",
              "          -3.1350496e-08]], dtype=float32),\n",
              " matrix([[-3.8442687e-07, -2.9571297e-08, -2.5690065e-07, -6.6535421e-08,\n",
              "           7.2773112e-09]], dtype=float32),\n",
              " matrix([[ 5.1606912e-07,  1.0652002e-07,  1.5578553e-07, -2.3122993e-07,\n",
              "           9.1851689e-08]], dtype=float32),\n",
              " matrix([[ 6.0343109e-07, -2.5318787e-08, -2.1520970e-07,  1.2342909e-07,\n",
              "           1.4241817e-07]], dtype=float32),\n",
              " matrix([[ 5.7070275e-07,  5.6319351e-08,  1.2601454e-07,  1.6426478e-07,\n",
              "          -5.8665988e-09]], dtype=float32),\n",
              " matrix([[-7.3737705e-09, -7.8653549e-08,  1.8188634e-07,  6.2677046e-08,\n",
              "          -1.7159378e-07]], dtype=float32),\n",
              " matrix([[ 5.7001222e-07, -3.1789145e-07,  9.4545300e-08,  1.2606040e-07,\n",
              "           1.3702217e-08]], dtype=float32),\n",
              " matrix([[ 7.5688440e-08, -3.1032260e-07, -1.1826318e-07, -2.6490953e-08,\n",
              "           1.9300552e-07]], dtype=float32),\n",
              " matrix([[-3.0670932e-07, -5.4153367e-07,  1.1741216e-07, -1.0183708e-07,\n",
              "          -1.2699684e-07]], dtype=float32),\n",
              " matrix([[-2.0861626e-07, -5.6810677e-08, -1.3411045e-07, -1.1548400e-07,\n",
              "           8.2887709e-08]], dtype=float32),\n",
              " matrix([[ 1.6585641e-07,  1.6585641e-07,  1.3734983e-07,  1.7832802e-07,\n",
              "          -1.5549038e-07]], dtype=float32),\n",
              " matrix([[-7.5636240e-07, -4.1791761e-08, -6.7277887e-07,  2.6034213e-08,\n",
              "          -1.4764139e-07]], dtype=float32),\n",
              " matrix([[-3.4863095e-07, -3.0589553e-07, -2.2492319e-09,  4.0486174e-08,\n",
              "           2.0243087e-08]], dtype=float32),\n",
              " matrix([[ 1.3821366e-07,  2.7642734e-08,  1.9954598e-07, -8.6383540e-09,\n",
              "          -3.1098075e-08]], dtype=float32),\n",
              " matrix([[ 2.8545352e-07, -1.2975161e-07,  1.1353266e-07, -7.7850963e-08,\n",
              "           5.8388224e-08]], dtype=float32),\n",
              " matrix([[ 1.25122074e-06,  1.14440915e-07,  7.58171055e-08,\n",
              "           3.48091135e-07, -8.22544095e-08]], dtype=float32),\n",
              " matrix([[ 4.6548388e-07, -2.0719710e-07,  1.4475414e-07,  6.8119597e-08,\n",
              "           1.2240240e-07]], dtype=float32),\n",
              " matrix([[-2.7939677e-07, -8.9406967e-08,  0.0000000e+00, -2.9802322e-08,\n",
              "           8.8475645e-08]], dtype=float32),\n",
              " matrix([[ 5.5285466e-07,  6.9106836e-09, -1.1057094e-07, -1.3907750e-07,\n",
              "          -2.0300132e-07]], dtype=float32),\n",
              " matrix([[-1.2558951e-06,  1.3599933e-07,  2.9382571e-08,  1.6790040e-09,\n",
              "          -8.3215639e-08]], dtype=float32),\n",
              " matrix([[-1.07490405e-06, -4.84919155e-07, -5.41493023e-07,\n",
              "          -1.17378214e-07, -1.47496237e-07]], dtype=float32),\n",
              " matrix([[-1.3351440e-07,  0.0000000e+00, -1.0299683e-07, -1.3351441e-08,\n",
              "          -4.5776368e-08]], dtype=float32),\n",
              " matrix([[-1.3432032e-08, -6.7160162e-09,  3.3580083e-08,  6.0444144e-08,\n",
              "           6.0758957e-08]], dtype=float32),\n",
              " matrix([[-7.4330501e-07, -1.4024623e-07, -8.5900808e-08,  8.5900808e-08,\n",
              "           2.2790012e-08]], dtype=float32),\n",
              " matrix([[-8.4771051e-07, -4.1138892e-07, -3.8957286e-09, -4.5190450e-08,\n",
              "          -5.2981907e-08]], dtype=float32),\n",
              " matrix([[ 9.3212236e-07,  3.8793530e-07, -1.0102482e-08, -1.5086373e-07,\n",
              "           2.3168359e-07]], dtype=float32),\n",
              " matrix([[1.73874326e-07, 1.15916215e-07, 8.69371632e-08, 7.90337840e-09,\n",
              "          2.48627117e-07]], dtype=float32),\n",
              " matrix([[-2.0492175e-07, -6.3052845e-08, -8.4727262e-08, -1.2684460e-07,\n",
              "          -9.5564474e-08]], dtype=float32),\n",
              " matrix([[ 8.6697668e-07,  3.3956584e-07,  2.2396897e-07, -3.2511625e-07,\n",
              "           3.3956584e-07]], dtype=float32),\n",
              " matrix([[-8.8713890e-08, -2.7723090e-07, -3.0495400e-08,  5.6832334e-08,\n",
              "           3.6040017e-08]], dtype=float32),\n",
              " matrix([[ 1.6633855e-08,  2.8092731e-07, -1.8482060e-08,  2.4396320e-07,\n",
              "           6.9307724e-08]], dtype=float32),\n",
              " matrix([[ 1.8384083e-07,  0.0000000e+00, -2.5852618e-08, -4.8832721e-08,\n",
              "           1.2459525e-07]], dtype=float32),\n",
              " matrix([[ 1.9277481e-06, -1.0531217e-06,  2.2949381e-08, -8.1597804e-08,\n",
              "           4.0543907e-07]], dtype=float32),\n",
              " matrix([[ 2.0604075e-08, -1.5011540e-07, -1.7513463e-07, -1.4717196e-07,\n",
              "          -6.0156538e-08]], dtype=float32),\n",
              " matrix([[-6.2319310e-07, -1.6760119e-07,  3.5408700e-08, -1.6524060e-08,\n",
              "          -8.6161172e-08]], dtype=float32),\n",
              " matrix([[-5.2452089e-07, -4.7683717e-08,  1.1473894e-07,  1.4454126e-07,\n",
              "           8.6054207e-08]], dtype=float32),\n",
              " matrix([[-6.3578290e-07, -1.5440442e-07, -2.2025336e-07, -1.5326908e-07,\n",
              "           1.4759245e-08]], dtype=float32),\n",
              " matrix([[ 5.3738790e-07, -1.5705351e-07,  1.7029899e-08,  5.8658539e-08,\n",
              "          -1.3529308e-07]], dtype=float32),\n",
              " matrix([[ 4.87158331e-07,  1.13532657e-07, -1.03211505e-07,\n",
              "          -1.03211506e-09,  1.38819473e-07]], dtype=float32),\n",
              " matrix([[-8.8576564e-07, -6.4956147e-08, -2.7680176e-07, -1.8047474e-07,\n",
              "          -1.7530779e-08]], dtype=float32),\n",
              " matrix([[ 3.0275376e-07, -5.6766329e-09, -5.6766329e-08,  7.0957911e-09,\n",
              "           1.3600266e-08]], dtype=float32),\n",
              " matrix([[2.8257017e-07, 8.4771051e-07, 4.7297388e-07, 1.5453055e-07,\n",
              "          1.8322909e-07]], dtype=float32),\n",
              " matrix([[1.1460822e-06, 6.1068619e-07, 2.6769806e-07, 1.8613380e-07,\n",
              "          2.7083513e-07]], dtype=float32),\n",
              " matrix([[ 2.8207268e-07, -2.2834456e-07, -9.4024230e-08, -8.3950205e-08,\n",
              "          -8.2271200e-08]], dtype=float32),\n",
              " matrix([[-2.6661863e-07, -2.4610949e-07, -7.6268307e-08, -1.3587295e-07,\n",
              "          -1.6771818e-07]], dtype=float32),\n",
              " matrix([[-8.9128440e-07,  3.3200345e-07, -1.2700802e-07, -2.0778067e-07,\n",
              "           4.4564219e-09]], dtype=float32),\n",
              " matrix([[-1.3563368e-07, -7.2055393e-08, -4.7683717e-08, -2.7550593e-07,\n",
              "          -2.6702881e-07]], dtype=float32),\n",
              " matrix([[-5.1549961e-07, -2.2553108e-07, -1.0551633e-07, -5.7993709e-08,\n",
              "          -4.1239971e-07]], dtype=float32),\n",
              " matrix([[ 9.81723588e-07,  5.49297710e-08, -2.36081135e-07,\n",
              "           2.28484467e-07, -1.04673354e-07]], dtype=float32),\n",
              " matrix([[-1.5641855e-06, -3.9902690e-09, -2.8879572e-07,  3.2420935e-08,\n",
              "          -1.9103413e-07]], dtype=float32),\n",
              " matrix([[ 1.00183968e-06, -1.30046502e-07,  1.05963814e-07,\n",
              "           9.69328084e-08,  1.54129182e-07]], dtype=float32),\n",
              " matrix([[-3.9013949e-07, -5.4186042e-08,  1.0385658e-07, -1.8965114e-08,\n",
              "           5.6895342e-08]], dtype=float32),\n",
              " matrix([[-1.9073486e-06,  6.1988828e-07, -2.1934510e-07, -1.1786818e-07,\n",
              "          -2.2629276e-07]], dtype=float32),\n",
              " matrix([[-1.14440915e-07, -2.70605085e-07, -5.90085989e-08,\n",
              "           9.65595248e-08,  1.04606151e-07]], dtype=float32),\n",
              " matrix([[-5.5770425e-07, -5.5770428e-08, -2.2587024e-07, -2.1785323e-07,\n",
              "          -1.2095211e-07]], dtype=float32),\n",
              " matrix([[-6.8233601e-07, -1.4364969e-07, -1.1571780e-07,  1.3267645e-07,\n",
              "           2.5188573e-08]], dtype=float32),\n",
              " matrix([[ 2.3072765e-07,  1.3459113e-07,  4.2300069e-08, -4.4658421e-08,\n",
              "           8.1475704e-08]], dtype=float32),\n",
              " matrix([[-6.3578291e-08, -1.9073487e-07,  1.4702479e-07, -2.9802322e-08,\n",
              "          -2.5331975e-08]], dtype=float32),\n",
              " matrix([[-3.8875896e-07, -1.1541282e-07, -1.0630128e-07,  3.4168266e-08,\n",
              "          -6.0553766e-08]], dtype=float32),\n",
              " matrix([[ 4.4878792e-07,  1.8432361e-07,  2.8550124e-08, -8.0140703e-09,\n",
              "           2.5294408e-08]], dtype=float32),\n",
              " matrix([[ 1.9771296e-07,  1.2211683e-07,  1.3374701e-07, -3.5617411e-08,\n",
              "           4.8519635e-08]], dtype=float32),\n",
              " matrix([[ 4.5776366e-07,  5.9405963e-08, -2.9404958e-07, -9.8546344e-08,\n",
              "           1.1603038e-07]], dtype=float32),\n",
              " matrix([[ 5.6573901e-07,  1.0102482e-06, -2.2225461e-08,  3.3540240e-07,\n",
              "           6.6676385e-08]], dtype=float32),\n",
              " matrix([[ 4.0266249e-07,  9.0069243e-08,  3.9363901e-08, -6.4902835e-08,\n",
              "           1.6490618e-07]], dtype=float32),\n",
              " matrix([[-4.9212929e-07, -4.9015263e-08,  1.6682350e-07, -1.9184702e-07,\n",
              "          -4.4347246e-07]], dtype=float32),\n",
              " matrix([[-6.4777879e-07,  7.6473881e-08,  1.2520724e-07, -1.1995904e-07,\n",
              "          -8.0972349e-08]], dtype=float32),\n",
              " matrix([[-7.4635381e-07, -1.1402628e-07, -1.4857969e-07,  2.3107597e-07,\n",
              "           9.9772990e-08]], dtype=float32),\n",
              " matrix([[-8.3257282e-07, -4.9449778e-07, -1.4885393e-07, -2.0068524e-07,\n",
              "           3.1852217e-08]], dtype=float32),\n",
              " matrix([[-2.06629437e-07, -3.70873352e-07,  4.83459885e-08,\n",
              "          -1.37752963e-07,  1.11262004e-07]], dtype=float32),\n",
              " matrix([[ 4.1106651e-07,  1.7264793e-07,  1.0584963e-07, -1.1385820e-07,\n",
              "          -8.8379302e-08]], dtype=float32),\n",
              " matrix([[ 7.5470632e-07,  1.3721933e-07,  2.4913885e-07,  6.6894422e-08,\n",
              "          -1.2521264e-07]], dtype=float32),\n",
              " matrix([[-1.6391277e-07, -2.9802322e-08,  1.5832484e-08, -1.1874363e-07,\n",
              "          -9.7323209e-08]], dtype=float32),\n",
              " matrix([[-1.3067172e-06, -1.6139104e-06,  5.0205449e-07, -4.9746956e-07,\n",
              "          -2.3232916e-07]], dtype=float32),\n",
              " matrix([[ 1.3268512e-07, -3.3171279e-08, -4.1464099e-09,  1.0521516e-07,\n",
              "          -3.1098075e-09]], dtype=float32),\n",
              " matrix([[ 7.2294665e-07,  4.2300069e-08,  1.4324343e-07, -1.6343209e-08,\n",
              "           7.7269732e-08]], dtype=float32),\n",
              " matrix([[ 6.2995002e-07,  2.0123403e-07,  4.1340471e-07,  2.6685382e-07,\n",
              "          -8.9680384e-08]], dtype=float32),\n",
              " matrix([[ 9.3497482e-07, -7.7062374e-08,  5.1423615e-07, -9.3205301e-08,\n",
              "           7.1584012e-08]], dtype=float32),\n",
              " matrix([[-1.0933846e-07,  2.3082563e-07,  3.0371794e-09,  5.4669229e-08,\n",
              "           4.8594870e-08]], dtype=float32),\n",
              " matrix([[-3.7831708e-07,  1.6551373e-07,  7.0934455e-08, -7.5860456e-08,\n",
              "          -1.7438053e-07]], dtype=float32),\n",
              " matrix([[ 7.6439545e-07,  2.3295861e-07,  1.8927888e-07, -4.3679741e-08,\n",
              "           2.5479849e-07]], dtype=float32),\n",
              " matrix([[-5.0108309e-07, -1.7780368e-07, -3.1267183e-07, -4.5713733e-08,\n",
              "           1.8184467e-08]], dtype=float32),\n",
              " matrix([[ 6.4247536e-07,  6.1251612e-08, -5.0193387e-09,  1.3803181e-07,\n",
              "          -5.2703054e-08]], dtype=float32),\n",
              " matrix([[-7.4582221e-07,  1.2837924e-07,  2.1090874e-07, -2.4911685e-07,\n",
              "           1.8951221e-07]], dtype=float32),\n",
              " matrix([[5.80012454e-07, 8.36556424e-08, 1.14329374e-07, 5.57704283e-09,\n",
              "          1.51277291e-07]], dtype=float32),\n",
              " matrix([[-4.09843494e-07, -4.41369934e-07, -2.36448177e-08,\n",
              "          -1.37928104e-08, -4.60088756e-07]], dtype=float32),\n",
              " matrix([[ 4.9273171e-07,  1.9073487e-07, -1.5894573e-08,  9.1393787e-08,\n",
              "          -1.2467305e-07]], dtype=float32),\n",
              " matrix([[ 2.4165504e-07, -3.0206881e-08, -2.0605407e-07,  1.7692601e-07,\n",
              "          -2.0807684e-07]], dtype=float32),\n",
              " matrix([[ 3.2648310e-07, -1.2887490e-07,  1.1598742e-07, -1.6216759e-07,\n",
              "           1.7398112e-07]], dtype=float32),\n",
              " matrix([[ 4.6624078e-07,  2.9669869e-07,  5.5796569e-08, -1.1920929e-07,\n",
              "          -5.5299864e-08]], dtype=float32),\n",
              " matrix([[ 6.1926904e-08, -2.1674417e-08, -1.1379068e-07,  1.2385381e-08,\n",
              "           6.9667763e-08]], dtype=float32),\n",
              " matrix([[ 1.2500866e-06,  8.0224629e-07, -3.1413259e-07,  1.2887490e-07,\n",
              "          -1.6109363e-08]], dtype=float32),\n",
              " matrix([[-2.66141683e-07,  1.12740565e-07, -1.14588772e-07,\n",
              "          -1.58945724e-07, -1.25678014e-07]], dtype=float32),\n",
              " matrix([[ 4.2130191e-07, -6.1280275e-08, -9.1920413e-08,  1.8192582e-08,\n",
              "          -1.3093872e-07]], dtype=float32),\n",
              " matrix([[ 2.9764357e-07, -4.5557691e-09,  2.3082563e-07,  1.4578461e-07,\n",
              "           1.3363589e-07]], dtype=float32),\n",
              " matrix([[ 8.4486584e-07,  2.2721771e-07, -3.2002493e-08,  1.7761384e-07,\n",
              "          -1.9201496e-08]], dtype=float32),\n",
              " matrix([[ 4.1018250e-08, -1.5381843e-08, -5.2554633e-08, -2.2752310e-08,\n",
              "           2.3713676e-08]], dtype=float32),\n",
              " matrix([[-2.1923547e-07,  2.6856347e-07, -1.1235818e-07, -1.8086926e-07,\n",
              "          -3.3912986e-08]], dtype=float32),\n",
              " matrix([[-1.3623919e-06,  7.5514158e-08,  1.6850636e-07, -2.5634478e-07,\n",
              "           6.1397266e-08]], dtype=float32),\n",
              " matrix([[-1.8458212e-07, -1.5381843e-07, -1.8169803e-07, -3.6531880e-08,\n",
              "           1.0815359e-07]], dtype=float32),\n",
              " matrix([[ 6.6283746e-07, -6.0872829e-08,  1.3907750e-07,  1.3009453e-07,\n",
              "           1.4964570e-07]], dtype=float32),\n",
              " matrix([[-1.0309993e-07, -1.5464988e-07, -2.0942172e-08, -1.2565303e-07,\n",
              "           6.5645658e-08]], dtype=float32),\n",
              " matrix([[-5.8507629e-07, -1.2871678e-07, -2.4500068e-07, -3.0533666e-08,\n",
              "           2.1026179e-09]], dtype=float32),\n",
              " matrix([[ 9.84046096e-07, -3.64461528e-08,  4.03755024e-07,\n",
              "           3.55349982e-07,  1.05162336e-07]], dtype=float32),\n",
              " matrix([[-5.2113353e-07, -5.6673269e-08, -3.6479346e-08, -1.0878662e-07,\n",
              "          -1.5975999e-07]], dtype=float32),\n",
              " matrix([[-8.9303609e-07,  2.7011583e-07,  3.3316584e-07, -3.1146010e-07,\n",
              "          -2.0051968e-07]], dtype=float32),\n",
              " matrix([[4.9756920e-07, 2.8506570e-08, 2.1509503e-07, 1.0366025e-07,\n",
              "          1.9792630e-07]], dtype=float32),\n",
              " matrix([[7.8376684e-07, 4.8231806e-07, 9.0434632e-08, 2.2745681e-07,\n",
              "          9.8655967e-08]], dtype=float32),\n",
              " matrix([[8.8303178e-09, 2.0309731e-07, 6.6227384e-09, 5.2981907e-08,\n",
              "          6.2916016e-08]], dtype=float32),\n",
              " matrix([[ 3.9608247e-07, -4.9990991e-08,  3.8454610e-07, -8.4600138e-08,\n",
              "           9.8059253e-08]], dtype=float32),\n",
              " matrix([[ 2.0435878e-07,  2.2564616e-07,  2.8383165e-09,  7.3796230e-08,\n",
              "          -1.3934360e-07]], dtype=float32),\n",
              " matrix([[-3.4890525e-07, -1.6645687e-07,  5.5243330e-08, -6.9781045e-08,\n",
              "          -3.1636574e-07]], dtype=float32),\n",
              " matrix([[-1.8352686e-06,  2.8762706e-08,  3.1751600e-08, -7.1148713e-07,\n",
              "           4.9139180e-07]], dtype=float32),\n",
              " matrix([[ 2.9724913e-07, -1.2695016e-07,  3.1215029e-07,  1.2849833e-07,\n",
              "           2.1287374e-08]], dtype=float32),\n",
              " matrix([[-5.9758133e-07, -3.0288368e-07, -3.8560751e-07, -1.1665115e-07,\n",
              "           1.3506975e-07]], dtype=float32),\n",
              " matrix([[ 1.1126200e-06, -2.0861626e-07, -4.2219956e-08,  2.2475918e-07,\n",
              "           2.1358331e-07]], dtype=float32),\n",
              " matrix([[ 2.1908734e-07,  8.2479943e-07,  1.4433989e-07, -1.0567742e-07,\n",
              "           1.4176240e-07]], dtype=float32),\n",
              " matrix([[ 1.7271267e-07, -3.7546233e-09,  2.0181101e-07, -2.7221018e-08,\n",
              "          -3.7546233e-08]], dtype=float32),\n",
              " matrix([[ 2.8984221e-07, -2.8516732e-07,  4.1489507e-08,  8.1810299e-08,\n",
              "           1.0503858e-07]], dtype=float32),\n",
              " matrix([[ 8.6697668e-08, -5.7798445e-08, -9.6631773e-08,  1.3004650e-07,\n",
              "           1.2756297e-07]], dtype=float32),\n",
              " matrix([[-8.3545024e-07, -3.9408028e-09,  1.0443128e-07, -1.5212115e-07,\n",
              "          -4.9260035e-10]], dtype=float32),\n",
              " matrix([[ 5.2399690e-07, -1.5719907e-07,  5.3273016e-08, -2.9201908e-08,\n",
              "           7.5979550e-08]], dtype=float32),\n",
              " matrix([[-3.7252903e-08, -1.7881393e-07, -1.5832484e-08, -2.6077032e-07,\n",
              "          -7.2759576e-08]], dtype=float32),\n",
              " matrix([[ 4.9541523e-08,  0.0000000e+00,  9.4825573e-08,  2.6318935e-08,\n",
              "          -4.6058133e-08]], dtype=float32),\n",
              " matrix([[ 6.9472961e-08,  1.7684027e-07,  9.1577995e-08, -8.2104414e-08,\n",
              "           5.4473119e-08]], dtype=float32),\n",
              " matrix([[-4.8972464e-07, -5.7993709e-08, -2.7385918e-08, -1.1528263e-07,\n",
              "          -1.0753000e-07]], dtype=float32),\n",
              " matrix([[-1.3601584e-06, -2.6056675e-08,  2.0193923e-07,  9.1198366e-08,\n",
              "          -1.6431991e-07]], dtype=float32),\n",
              " matrix([[ 2.87778676e-07,  1.35973096e-07,  2.98023224e-08,\n",
              "          -1.03376806e-07, -4.14438546e-08]], dtype=float32),\n",
              " matrix([[ 1.2185839e-06, -1.3686993e-07,  1.4473443e-07,  1.9205942e-07,\n",
              "           1.1976118e-07]], dtype=float32),\n",
              " matrix([[ 4.8828127e-07, -1.9073487e-09, -1.4305115e-09,  1.8119812e-07,\n",
              "           1.3732910e-07]], dtype=float32),\n",
              " matrix([[6.1575821e-07, 2.2903203e-07, 1.2014794e-07, 2.6282363e-08,\n",
              "          5.3034054e-08]], dtype=float32),\n",
              " matrix([[-1.40246229e-07,  5.76324339e-08,  9.02835069e-08,\n",
              "           5.12775244e-08, -1.35863525e-08]], dtype=float32),\n",
              " matrix([[ 4.1464099e-07,  4.9238619e-08, -5.9604645e-08, -1.4253285e-08,\n",
              "           5.6689199e-08]], dtype=float32),\n",
              " matrix([[ 1.0028327e-06, -1.4092095e-07,  2.7528742e-07,  5.2620044e-07,\n",
              "           7.4864253e-08]], dtype=float32),\n",
              " matrix([[-1.5464989e-06,  4.4676634e-07, -3.3829664e-07, -1.2887490e-07,\n",
              "           7.9472862e-08]], dtype=float32),\n",
              " matrix([[ 6.6342562e-07,  2.2546105e-07,  3.4467033e-07, -1.8140543e-08,\n",
              "           3.1130469e-07]], dtype=float32),\n",
              " matrix([[-5.2018601e-07, -1.8423253e-07,  1.4268991e-07, -1.6978292e-07,\n",
              "           1.0295348e-07]], dtype=float32),\n",
              " matrix([[-1.6495989e-07, -3.8146973e-07,  2.8352479e-08,  4.8972463e-08,\n",
              "          -8.3768690e-08]], dtype=float32),\n",
              " matrix([[ 3.96728524e-07, -2.17437744e-07, -7.10487384e-08,\n",
              "           2.52246849e-07, -1.09910964e-07]], dtype=float32),\n",
              " matrix([[-8.9009603e-08,  2.5431316e-08, -1.8278757e-07, -4.3710074e-08,\n",
              "           2.8610229e-08]], dtype=float32),\n",
              " matrix([[ 9.0307117e-07,  1.0509880e-07,  1.7759751e-07, -1.0412567e-07,\n",
              "           2.0922447e-07]], dtype=float32),\n",
              " matrix([[ 1.9073486e-08, -1.5497207e-07,  1.2874604e-07,  4.6491621e-08,\n",
              "          -2.5041402e-07]], dtype=float32),\n",
              " matrix([[-9.7274778e-07, -2.9981138e-07, -1.5027821e-07, -1.3232231e-07,\n",
              "          -1.7881393e-07]], dtype=float32),\n",
              " matrix([[-9.2589737e-08, -1.9212371e-07,  9.4904486e-08,  7.7543909e-08,\n",
              "           5.5553844e-08]], dtype=float32),\n",
              " matrix([[-7.1363382e-07, -1.8165225e-07, -2.0435878e-07,  7.1363381e-08,\n",
              "           7.5823593e-08]], dtype=float32),\n",
              " matrix([[-5.1468140e-07,  4.1628642e-08, -4.1628642e-08, -1.8117920e-07,\n",
              "          -5.6766329e-08]], dtype=float32),\n",
              " matrix([[-3.7216557e-07, -4.6520697e-08, -1.7445261e-08, -9.8856482e-08,\n",
              "           5.8150874e-08]], dtype=float32),\n",
              " matrix([[-1.1490052e-07,  2.6427119e-07, -6.6067798e-08, -3.8778925e-08,\n",
              "           6.2477156e-08]], dtype=float32),\n",
              " matrix([[ 5.4808869e-09,  9.5230412e-08,  9.5915517e-08,  5.4808869e-09,\n",
              "          -5.5665257e-08]], dtype=float32),\n",
              " matrix([[ 3.0215423e-07,  1.5786378e-08, -8.0259717e-08,  1.9002668e-07,\n",
              "           9.3242910e-08]], dtype=float32),\n",
              " matrix([[ 2.5357815e-07, -3.3075409e-08,  4.6856830e-08, -2.8940983e-08,\n",
              "           1.4677214e-07]], dtype=float32),\n",
              " matrix([[-1.1089236e-08, -3.0218169e-07,  7.2080034e-08, -1.3861546e-08,\n",
              "           5.1287717e-08]], dtype=float32),\n",
              " matrix([[ 6.11791052e-07,  4.04861737e-07,  1.55197000e-07,\n",
              "           1.23707755e-08, -7.08508026e-08]], dtype=float32),\n",
              " matrix([[ 6.8119596e-07,  1.9949310e-07, -7.2985280e-09, -1.7212362e-07,\n",
              "          -1.3015708e-07]], dtype=float32),\n",
              " matrix([[ 8.3526510e-07, -8.9606985e-08,  4.2883343e-07,  4.8003741e-08,\n",
              "           4.1603241e-07]], dtype=float32),\n",
              " matrix([[ 5.6098492e-07, -2.6646782e-07,  1.7029899e-07,  1.9233768e-07,\n",
              "           1.1119522e-07]], dtype=float32),\n",
              " matrix([[ 1.5894572e-07, -2.2990363e-07,  8.5149496e-09,  9.6502760e-08,\n",
              "          -2.9092742e-08]], dtype=float32),\n",
              " matrix([[-1.4992260e-07,  1.6241616e-07, -8.9537110e-08, -1.2441494e-07,\n",
              "           1.1608590e-07]], dtype=float32),\n",
              " matrix([[ 2.2178473e-07, -2.9571297e-08,  7.0231827e-08, -1.0742698e-07,\n",
              "           1.3283982e-07]], dtype=float32),\n",
              " matrix([[1.0638009e-06, 1.0127113e-06, 1.9584384e-08, 7.4477424e-07,\n",
              "          1.5894572e-07]], dtype=float32),\n",
              " matrix([[ 7.5718867e-07, -3.5942499e-08,  4.9121414e-08,  5.3913748e-08,\n",
              "           3.3246812e-07]], dtype=float32),\n",
              " matrix([[-1.4834934e-07, -7.2055394e-07, -4.2385526e-08, -2.2517310e-07,\n",
              "          -7.4174672e-08]], dtype=float32),\n",
              " matrix([[ 1.0058284e-07,  2.6449561e-07,  2.0675361e-07,  1.4901161e-07,\n",
              "          -5.5275450e-08]], dtype=float32),\n",
              " matrix([[ 1.2174566e-07, -2.4856405e-07,  2.1326626e-07, -5.4109179e-08,\n",
              "          -7.1018299e-08]], dtype=float32),\n",
              " matrix([[ 2.2007869e-07, -1.8339891e-07,  6.4189621e-08,  5.5019672e-08,\n",
              "           2.1033563e-07]], dtype=float32),\n",
              " matrix([[ 6.5208503e-08,  8.5586159e-08, -4.4830845e-08, -6.3170738e-08,\n",
              "           2.7382476e-09]], dtype=float32),\n",
              " matrix([[ 4.0323141e-07,  1.7281347e-07,  1.6961322e-07, -2.0251578e-07,\n",
              "           6.7205235e-08]], dtype=float32),\n",
              " matrix([[-5.1724709e-07, -1.9497790e-07, -2.3134685e-07, -3.5406043e-08,\n",
              "          -5.5816216e-08]], dtype=float32),\n",
              " matrix([[ 6.15273734e-08, -1.03827446e-07, -2.69182259e-08,\n",
              "          -6.54930048e-08, -9.19305521e-09]], dtype=float32),\n",
              " matrix([[ 1.3004650e-07, -1.9601211e-07,  9.8006055e-08, -1.3570069e-07,\n",
              "           8.4812932e-08]], dtype=float32),\n",
              " matrix([[-1.3172297e-06,  3.4511419e-07, -3.1350066e-07, -2.1734290e-07,\n",
              "          -4.0537745e-07]], dtype=float32),\n",
              " matrix([[ 1.5411377e-06,  7.4386598e-08, -5.6584675e-08,  1.3287863e-07,\n",
              "           1.3065338e-07]], dtype=float32),\n",
              " matrix([[-1.2439230e-07, -1.2093696e-07, -7.6017521e-08,  5.4421633e-08,\n",
              "           1.4253285e-08]], dtype=float32),\n",
              " matrix([[7.7905787e-07, 1.3432032e-08, 2.5185061e-08, 1.8607562e-07,\n",
              "          2.7502088e-07]], dtype=float32),\n",
              " matrix([[-2.9394071e-08, -8.1650198e-09, -3.5272885e-07, -1.8616245e-07,\n",
              "          -7.5934686e-08]], dtype=float32),\n",
              " matrix([[-7.6293944e-08, -7.1525577e-08,  9.0599059e-08, -1.3649463e-07,\n",
              "           5.7220458e-08]], dtype=float32),\n",
              " matrix([[-6.2099724e-07, -4.4356945e-08, -5.2673872e-08,  2.0099241e-08,\n",
              "          -7.3466190e-08]], dtype=float32),\n",
              " matrix([[-9.8232545e-07,  5.9348832e-08,  2.2409300e-07, -1.7088371e-07,\n",
              "          -2.4634880e-07]], dtype=float32),\n",
              " matrix([[ 3.2372432e-07,  1.8811008e-07, -1.4162939e-07, -5.9057815e-08,\n",
              "          -1.7772027e-08]], dtype=float32),\n",
              " matrix([[ 4.8287308e-07, -1.8107739e-08,  1.4486191e-07, -3.0179568e-09,\n",
              "          -2.6708918e-07]], dtype=float32),\n",
              " matrix([[-7.5180168e-07,  4.1766757e-08, -8.7014079e-08, -2.7844505e-08,\n",
              "           1.5662534e-08]], dtype=float32),\n",
              " matrix([[ 3.2285848e-07,  1.0430813e-07,  1.6298145e-08,  9.9341072e-08,\n",
              "          -5.8362883e-08]], dtype=float32),\n",
              " matrix([[ 5.0862631e-08, -6.9936114e-08,  9.5764797e-08,  1.3033549e-07,\n",
              "           1.2278556e-07]], dtype=float32),\n",
              " matrix([[ 2.8500611e-07,  1.7812882e-08,  1.0071130e-07,  1.1920929e-07,\n",
              "          -4.7572385e-08]], dtype=float32),\n",
              " matrix([[ 2.2057773e-07,  7.7040019e-09, -3.7303586e-08, -8.2716653e-08,\n",
              "          -1.0010134e-08]], dtype=float32),\n",
              " matrix([[ 2.0217895e-07, -4.1961670e-08,  1.7166138e-07, -1.0871887e-07,\n",
              "           4.0054321e-08]], dtype=float32),\n",
              " matrix([[ 2.4056649e-07,  1.5464988e-07,  1.1061763e-07, -7.6519477e-08,\n",
              "           2.0512590e-07]], dtype=float32),\n",
              " matrix([[-1.4671913e-07, -3.4845792e-07, -5.2154064e-08,  3.7826023e-08,\n",
              "          -1.5818156e-07]], dtype=float32),\n",
              " matrix([[-3.5135369e-07, -1.1293512e-07,  6.9015904e-08,  6.8231635e-08,\n",
              "          -1.0607274e-07]], dtype=float32),\n",
              " matrix([[2.3841858e-07, 1.4901161e-07, 7.4505806e-09, 1.3317913e-07,\n",
              "          2.4121255e-07]], dtype=float32),\n",
              " matrix([[ 8.1163769e-08, -9.1309246e-08,  2.5363678e-09, -1.1160019e-07,\n",
              "          -9.2577430e-08]], dtype=float32),\n",
              " matrix([[ 1.4901161e-07,  3.5390258e-08,  8.9406967e-08, -9.4529241e-08,\n",
              "           3.5390258e-08]], dtype=float32),\n",
              " matrix([[-7.7952507e-07,  1.4512435e-08,  3.3171279e-08, -1.3683153e-07,\n",
              "          -3.1098075e-08]], dtype=float32),\n",
              " matrix([[-8.45711213e-07,  2.11427803e-07,  1.03464664e-07,\n",
              "          -1.41982767e-07, -2.87901685e-07]], dtype=float32),\n",
              " matrix([[-1.3463638e-07,  2.3911980e-07,  8.9757584e-08, -3.0854171e-08,\n",
              "          -1.2271545e-08]], dtype=float32),\n",
              " matrix([[ 8.4147736e-08,  1.0693775e-07, -1.4725853e-07, -1.9152375e-07,\n",
              "          -1.1745621e-07]], dtype=float32),\n",
              " matrix([[7.2660903e-08, 8.1743515e-08, 2.6772420e-07, 7.0390250e-08,\n",
              "          1.9231368e-07]], dtype=float32),\n",
              " matrix([[-3.15264231e-07,  3.54672274e-08,  1.02460874e-07,\n",
              "           6.60084467e-08,  1.58617325e-07]], dtype=float32),\n",
              " matrix([[ 3.3659094e-07, -9.5834920e-08, -8.1810301e-09,  4.2073868e-08,\n",
              "          -8.5754721e-08]], dtype=float32),\n",
              " matrix([[ 1.2557277e-06, -7.9755679e-08,  2.3810040e-07,  2.0363153e-08,\n",
              "          -1.3236050e-07]], dtype=float32),\n",
              " matrix([[ 5.0193387e-07, -3.3462257e-08,  1.1502651e-07, -3.5815070e-08,\n",
              "           4.5553112e-08]], dtype=float32),\n",
              " matrix([[-1.2214548e-07,  1.8791612e-08, -2.5838466e-07,  6.8119597e-08,\n",
              "          -1.1157520e-07]], dtype=float32),\n",
              " matrix([[ 3.6941779e-07,  3.6679783e-08,  1.5195910e-07, -5.7639657e-08,\n",
              "           5.2399688e-08]], dtype=float32),\n",
              " matrix([[ 7.0209154e-07,  1.6820943e-08,  3.2618001e-07,  2.2306033e-07,\n",
              "          -3.3641885e-07]], dtype=float32),\n",
              " matrix([[ 3.0697672e-07,  1.3097673e-07,  5.4744181e-08, -1.6218603e-07,\n",
              "          -3.0697670e-08]], dtype=float32),\n",
              " matrix([[-4.9449778e-07,  1.3422083e-07, -1.2362444e-08, -6.8876481e-08,\n",
              "          -1.2472823e-07]], dtype=float32),\n",
              " matrix([[-1.34129675e-06, -4.12233419e-07,  1.03827446e-07,\n",
              "           3.73009712e-08,  3.24556908e-07]], dtype=float32),\n",
              " matrix([[-7.3598778e-07,  1.2568806e-07, -5.6624413e-07, -2.3582707e-07,\n",
              "          -3.1616378e-07]], dtype=float32),\n",
              " matrix([[-7.4505806e-08, -4.4703484e-08, -1.4714897e-07,  5.3783879e-08,\n",
              "          -9.5926225e-08]], dtype=float32),\n",
              " matrix([[-3.2744182e-07, -2.6604649e-08,  1.0232557e-08, -1.0232557e-08,\n",
              "           2.8139533e-09]], dtype=float32),\n",
              " matrix([[-1.4901161e-07, -2.0116568e-07, -3.1839591e-08,  8.3819032e-09,\n",
              "          -1.3969839e-09]], dtype=float32),\n",
              " matrix([[-3.5408701e-07, -1.6996177e-07, -1.7586321e-07,  7.3177979e-08,\n",
              "           2.3605800e-09]], dtype=float32),\n",
              " matrix([[-8.8809213e-07, -1.0008115e-07,  1.7317797e-07, -8.0884701e-07,\n",
              "          -4.4677864e-07]], dtype=float32),\n",
              " matrix([[4.2276284e-07, 1.1920929e-07, 9.0943168e-08, 8.7870767e-08,\n",
              "          4.3013659e-09]], dtype=float32),\n",
              " matrix([[-1.6867709e-06, -3.3086661e-07, -3.6817019e-07, -1.7840846e-07,\n",
              "          -1.9138362e-07]], dtype=float32),\n",
              " matrix([[-2.6490954e-07, -1.4128508e-07, -2.7594742e-08,  9.1200626e-08,\n",
              "           9.3822123e-08]], dtype=float32),\n",
              " matrix([[ 2.6822090e-07,  3.7252903e-09, -1.1175871e-07,  6.7055225e-08,\n",
              "          -1.0104850e-07]], dtype=float32),\n",
              " matrix([[ 2.8487515e-08,  8.4147736e-08,  9.1160047e-08,  1.1219698e-07,\n",
              "          -1.2622161e-07]], dtype=float32),\n",
              " matrix([[-3.4438239e-07, -2.9669869e-07,  2.2517311e-08,  6.0929196e-08,\n",
              "          -2.4504132e-08]], dtype=float32),\n",
              " matrix([[-8.8201091e-08, -4.9613114e-08, -1.2403278e-07, -2.8940983e-08,\n",
              "           1.3988142e-07]], dtype=float32),\n",
              " matrix([[ 2.1674417e-07,  8.6697668e-08,  3.2511625e-08, -1.5894572e-07,\n",
              "          -1.4449611e-08]], dtype=float32),\n",
              " matrix([[ 2.2587024e-07,  2.3841858e-07, -3.1370867e-08,  8.3132797e-08,\n",
              "           3.1370866e-09]], dtype=float32),\n",
              " matrix([[ 5.6578841e-07,  3.4049381e-07, -1.6404948e-07,  6.9265333e-08,\n",
              "          -1.5037870e-07]], dtype=float32),\n",
              " matrix([[-1.2692788e-06, -4.6654571e-07, -1.0737413e-06, -2.4699477e-07,\n",
              "          -2.0068326e-07]], dtype=float32),\n",
              " matrix([[-8.0553076e-07, -5.5553844e-08, -4.1665382e-07,  1.9067700e-07,\n",
              "          -2.1990063e-07]], dtype=float32),\n",
              " matrix([[ 8.8526730e-07,  1.6095768e-08, -1.0261053e-07,  1.7981992e-07,\n",
              "           1.2323324e-07]], dtype=float32),\n",
              " matrix([[ 2.2149855e-07, -1.0613472e-07,  3.0763687e-08,  5.0760086e-08,\n",
              "          -5.5374638e-08]], dtype=float32),\n",
              " matrix([[-7.37139558e-08,  4.13201278e-08, -5.64372478e-08,\n",
              "          -2.90824591e-08, -1.23816415e-08]], dtype=float32),\n",
              " matrix([[-1.8353733e-06, -1.1995903e-08, -6.9163882e-08,  3.7112326e-08,\n",
              "           1.7244110e-07]], dtype=float32),\n",
              " matrix([[ 5.9193576e-07,  3.3707454e-07, -2.0553326e-09,  7.2964305e-08,\n",
              "           3.3193621e-07]], dtype=float32),\n",
              " matrix([[-2.3496324e-07, -1.6585641e-07,  2.2805256e-07, -2.7642733e-07,\n",
              "          -9.3294226e-08]], dtype=float32),\n",
              " matrix([[ 1.7029899e-08, -3.0653817e-07, -1.1920929e-07,  7.4505806e-08,\n",
              "          -2.0223004e-08]], dtype=float32),\n",
              " matrix([[ 8.4032780e-07,  2.2669307e-07,  4.6315739e-07, -5.6062564e-08,\n",
              "           2.3451008e-08]], dtype=float32),\n",
              " matrix([[ 4.12081505e-07, -1.34294410e-07, -2.50192329e-08,\n",
              "           5.88687854e-08,  1.03204336e-07]], dtype=float32),\n",
              " matrix([[6.8263006e-07, 1.5308983e-07, 1.6752043e-07, 1.1669962e-07,\n",
              "          1.6563817e-07]], dtype=float32),\n",
              " matrix([[-3.4455331e-07, -4.3069164e-08, -1.6150936e-07,  1.5151116e-07,\n",
              "          -1.7227666e-07]], dtype=float32),\n",
              " matrix([[ 6.1338596e-07, -2.7363951e-08,  2.6009300e-08, -9.9702312e-08,\n",
              "          -1.3004650e-08]], dtype=float32),\n",
              " matrix([[-7.5688440e-08,  8.5386020e-08,  8.3257284e-08,  1.5137688e-08,\n",
              "          -8.0182438e-08]], dtype=float32),\n",
              " matrix([[-1.6232754e-07, -9.1309246e-08,  1.0145471e-08, -9.5113792e-09,\n",
              "           1.5598663e-07]], dtype=float32),\n",
              " matrix([[-1.0899136e-06, -2.9867823e-07, -2.9998822e-07,  6.5008365e-08,\n",
              "          -7.4997054e-08]], dtype=float32),\n",
              " matrix([[-1.7136335e-07, -1.0430813e-07, -3.9115548e-08, -2.6449561e-07,\n",
              "           3.7194695e-08]], dtype=float32),\n",
              " matrix([[ 5.7220461e-07,  4.8535210e-08,  1.9754683e-07, -6.7693847e-08,\n",
              "          -2.9802322e-08]], dtype=float32),\n",
              " matrix([[ 6.5565109e-07,  3.4272671e-07,  3.0547380e-07, -1.8812716e-07,\n",
              "           2.9802322e-08]], dtype=float32),\n",
              " matrix([[ 6.2442962e-07,  4.3993904e-07, -2.8383164e-08,  2.0893779e-07,\n",
              "           1.6178403e-07]], dtype=float32),\n",
              " matrix([[ 3.9586482e-07,  4.6334176e-07, -1.1312055e-08, -4.2735405e-08,\n",
              "           5.1732332e-08]], dtype=float32),\n",
              " matrix([[ 6.3578290e-07,  2.3496324e-07, -1.4814778e-07,  1.4166901e-07,\n",
              "           1.1775157e-07]], dtype=float32),\n",
              " matrix([[ 1.0355850e-06,  9.1783839e-08, -3.7737419e-07, -2.7462016e-07,\n",
              "          -3.0533666e-08]], dtype=float32),\n",
              " matrix([[-2.7673585e-07,  2.1287373e-07,  9.3664440e-08,  5.9604645e-08,\n",
              "           7.2377070e-08]], dtype=float32),\n",
              " matrix([[-3.5170967e-07, -2.4518222e-08,  8.1903542e-09,  1.4541843e-07,\n",
              "          -1.6909119e-09]], dtype=float32),\n",
              " matrix([[1.0977546e-07, 4.8026766e-07, 1.7495464e-07, 4.8884385e-08,\n",
              "          3.6020072e-08]], dtype=float32),\n",
              " matrix([[3.3060709e-07, 2.2888183e-07, 1.1044244e-07, 1.3351440e-07,\n",
              "          3.4650168e-07]], dtype=float32),\n",
              " matrix([[1.2882093e-06, 6.1414630e-07, 7.2961080e-07, 4.1442391e-07,\n",
              "          3.9320341e-08]], dtype=float32),\n",
              " matrix([[ 3.3826910e-07, -1.4264360e-07, -3.1381592e-07, -8.1510629e-09,\n",
              "           6.5717941e-08]], dtype=float32),\n",
              " matrix([[ 8.0917822e-08, -8.6697668e-08,  8.3085261e-08, -1.5822324e-07,\n",
              "           2.6248622e-07]], dtype=float32),\n",
              " matrix([[-5.9604645e-07, -3.3527613e-07, -1.7974526e-07, -2.9802322e-08,\n",
              "          -3.7252903e-09]], dtype=float32),\n",
              " matrix([[7.1916423e-07, 5.7064119e-07, 3.3808536e-07, 5.7650393e-08,\n",
              "          1.5780574e-07]], dtype=float32),\n",
              " matrix([[ 2.1534581e-07,  9.2291060e-08, -1.9996396e-07, -1.7400711e-07,\n",
              "           4.0377341e-08]], dtype=float32),\n",
              " matrix([[-3.57973391e-07,  1.25774434e-07, -6.91068323e-08,\n",
              "           1.09534334e-07, -1.38213672e-08]], dtype=float32),\n",
              " matrix([[ 6.6811083e-07, -9.8667577e-08, -4.7144915e-09,  2.2898959e-07,\n",
              "          -1.2897502e-07]], dtype=float32),\n",
              " matrix([[ 1.0097729e-06,  1.2341668e-07,  2.3000381e-07, -4.4878792e-08,\n",
              "           6.4513266e-08]], dtype=float32),\n",
              " matrix([[-4.7969246e-07, -5.4821999e-07, -2.1129311e-07, -1.3991030e-07,\n",
              "          -1.1492632e-07]], dtype=float32),\n",
              " matrix([[ 9.9055671e-07,  4.3732027e-07, -8.3644089e-08,  5.2491606e-07,\n",
              "           3.7080017e-07]], dtype=float32),\n",
              " matrix([[-1.6303173e-07, -7.1096544e-08,  1.6180593e-07, -4.5661142e-08,\n",
              "           5.9451420e-08]], dtype=float32),\n",
              " matrix([[-2.1390825e-07,  1.3369267e-07,  2.3396217e-08, -1.0249771e-07,\n",
              "           7.2416860e-08]], dtype=float32),\n",
              " matrix([[-1.0066562e-06, -5.9604645e-07, -4.2716661e-07,  7.6161491e-08,\n",
              "          -2.4255780e-07]], dtype=float32),\n",
              " matrix([[-9.5367432e-07, -1.5524931e-07, -2.1953223e-07,  2.6336936e-08,\n",
              "           1.6911085e-07]], dtype=float32),\n",
              " matrix([[-5.3752552e-07, -1.8423253e-07, -4.7683717e-08,  5.6353482e-08,\n",
              "           7.6944175e-08]], dtype=float32),\n",
              " matrix([[-3.8146973e-07,  7.2660903e-08,  1.8732888e-07, -1.2829190e-07,\n",
              "          -1.9584384e-07]], dtype=float32),\n",
              " matrix([[ 4.5413063e-07,  2.9329269e-07,  2.8950828e-07,  1.8922110e-08,\n",
              "          -3.3409350e-08]], dtype=float32),\n",
              " matrix([[-1.0421595e-06, -6.3906009e-07,  1.5177677e-07, -8.2954919e-08,\n",
              "           1.3211339e-07]], dtype=float32),\n",
              " matrix([[-3.8767249e-07, -1.3956209e-07,  3.7313477e-08, -7.7534494e-08,\n",
              "          -8.3925038e-08]], dtype=float32),\n",
              " matrix([[-6.7512588e-07, -2.0773103e-07,  1.1802900e-07, -6.1375083e-08,\n",
              "          -8.4980883e-08]], dtype=float32),\n",
              " matrix([[1.4240386e-06, 7.4438383e-08, 2.6431019e-07, 1.3215509e-07,\n",
              "          5.6887376e-07]], dtype=float32),\n",
              " matrix([[-4.63949675e-07, -2.31974838e-07,  9.66561799e-08,\n",
              "          -1.17598354e-07, -1.61093638e-07]], dtype=float32),\n",
              " matrix([[ 0.0000000e+00,  2.6551160e-07, -8.1279063e-09, -1.4562498e-07,\n",
              "           3.1495635e-08]], dtype=float32),\n",
              " matrix([[ 4.2087035e-07,  2.1155451e-07,  2.3226224e-07,  1.0857560e-07,\n",
              "          -1.4565360e-07]], dtype=float32),\n",
              " matrix([[ 2.19464795e-07, -1.19708075e-08,  3.95286044e-08,\n",
              "           1.65596163e-07,  9.52676729e-08]], dtype=float32),\n",
              " matrix([[-1.6736668e-07,  1.0105158e-07,  0.0000000e+00, -9.4735860e-08,\n",
              "          -4.7367930e-08]], dtype=float32),\n",
              " matrix([[ 5.4495676e-08,  2.0435879e-08,  6.6416604e-08, -1.0217939e-07,\n",
              "          -1.0430813e-08]], dtype=float32),\n",
              " matrix([[-1.9462742e-07,  2.4328426e-07,  1.6786615e-07, -9.8530130e-08,\n",
              "          -5.0177380e-08]], dtype=float32),\n",
              " matrix([[ 1.3443361e-06, -3.4470156e-07,  4.3949450e-07, -2.7989049e-07,\n",
              "           1.2567244e-09]], dtype=float32),\n",
              " matrix([[ 3.0901180e-07,  1.5983369e-08, -3.3964659e-07,  8.0333074e-09,\n",
              "           1.4851213e-07]], dtype=float32),\n",
              " matrix([[-1.1219698e-07,  2.3140626e-07, -1.3936969e-07,  1.7530778e-09,\n",
              "          -1.4725853e-07]], dtype=float32),\n",
              " matrix([[ 1.93967651e-07, -1.33352771e-07,  1.34363006e-07,\n",
              "          -6.06148909e-09,  1.14915736e-07]], dtype=float32),\n",
              " matrix([[-9.5367432e-07,  3.9408029e-08,  1.4580971e-07, -1.4975052e-07,\n",
              "          -9.4579271e-08]], dtype=float32),\n",
              " matrix([[ 8.1510628e-08,  1.6098349e-07, -1.5283243e-08,  1.2736035e-07,\n",
              "           1.5537964e-08]], dtype=float32),\n",
              " matrix([[ 9.8655967e-08,  8.2213305e-08,  4.5217316e-08,  1.3051361e-07,\n",
              "          -1.0276663e-08]], dtype=float32),\n",
              " matrix([[ 1.0699761e-06,  1.0757911e-07, -5.5243330e-08,  3.5472033e-07,\n",
              "           3.4018259e-07]], dtype=float32),\n",
              " matrix([[-6.8530363e-07,  6.2300330e-08, -1.1980833e-07, -4.3130999e-08,\n",
              "          -4.4688508e-07]], dtype=float32),\n",
              " matrix([[ 5.1172771e-07,  1.1533256e-07, -1.5506899e-07,  2.0352806e-08,\n",
              "           1.7445262e-07]], dtype=float32),\n",
              " matrix([[-1.1444092e-08, -3.3569336e-07,  3.8146972e-08,  1.6212464e-08,\n",
              "           5.7220458e-08]], dtype=float32),\n",
              " matrix([[-4.88136607e-07, -6.77967504e-09, -5.52614132e-09,\n",
              "          -1.11864644e-07, -2.82486461e-08]], dtype=float32),\n",
              " matrix([[5.2904562e-07, 1.4966422e-07, 3.5284211e-07, 1.8446985e-07,\n",
              "          2.6104225e-08]], dtype=float32),\n",
              " matrix([[ 1.3351440e-07,  2.8610229e-08, -1.1205673e-07,  1.5616416e-07,\n",
              "           3.8146972e-08]], dtype=float32),\n",
              " matrix([[ 6.6173322e-07,  3.9330956e-08, -4.7034959e-08,  9.4069918e-08,\n",
              "          -9.0826127e-08]], dtype=float32),\n",
              " matrix([[-5.7353839e-07, -3.7346686e-07, -4.7183536e-07, -1.5588907e-07,\n",
              "          -5.8354196e-08]], dtype=float32),\n",
              " matrix([[-5.7549311e-08,  1.6442661e-07, -1.2331995e-07, -9.8655967e-08,\n",
              "          -5.8576980e-08]], dtype=float32),\n",
              " matrix([[-4.0999083e-07, -5.3477063e-08,  6.1275802e-09, -4.4564219e-09,\n",
              "          -1.4566929e-07]], dtype=float32),\n",
              " matrix([[-5.3405762e-07, -2.8882707e-07, -7.4250359e-08,  2.4523054e-08,\n",
              "          -1.1989049e-07]], dtype=float32),\n",
              " matrix([[-4.8047713e-07,  1.0919935e-07, -5.0959695e-08,  9.0999457e-08,\n",
              "          -4.5499728e-08]], dtype=float32),\n",
              " matrix([[ 3.0453467e-07,  1.2021106e-07, -6.6116080e-08, -2.5544848e-08,\n",
              "          -4.2073868e-08]], dtype=float32),\n",
              " matrix([[-5.1208968e-07, -2.5604484e-07, -4.8240334e-08,  8.3492884e-09,\n",
              "          -2.2543080e-07]], dtype=float32),\n",
              " matrix([[2.0435878e-07, 5.1089696e-08, 2.9802322e-08, 1.0856560e-07,\n",
              "          5.9604645e-08]], dtype=float32),\n",
              " matrix([[-7.3693013e-07,  9.1032547e-08,  1.7339532e-08,  3.2511625e-09,\n",
              "          -4.1614879e-07]], dtype=float32),\n",
              " matrix([[ 1.2964985e-06,  1.7297035e-07,  0.0000000e+00,  2.0569446e-07,\n",
              "          -1.9089069e-07]], dtype=float32),\n",
              " matrix([[1.1626988e-06, 6.8912766e-07, 6.6749038e-08, 5.5277184e-07,\n",
              "          3.2905029e-07]], dtype=float32),\n",
              " matrix([[ 1.2362445e-07, -7.0642542e-08,  6.6227386e-08,  1.1037897e-08,\n",
              "           4.4151587e-08]], dtype=float32),\n",
              " matrix([[-4.0154708e-07,  1.1842502e-07, -1.3332618e-07, -1.3411045e-07,\n",
              "           1.4116890e-08]], dtype=float32),\n",
              " matrix([[-1.5137688e-07, -4.1628642e-08, -1.3387393e-07, -1.4901161e-08,\n",
              "          -3.5952009e-08]], dtype=float32),\n",
              " matrix([[-2.7350660e-07, -7.7373578e-08,  7.0176036e-08, -5.2182180e-08,\n",
              "           6.2078797e-08]], dtype=float32),\n",
              " matrix([[ 6.52514018e-07, -6.77610714e-08, -1.13562535e-07,\n",
              "          -4.39192114e-08,  2.25870238e-08]], dtype=float32),\n",
              " matrix([[-6.5051955e-07,  7.4209758e-08,  1.2631448e-08,  6.8683498e-08,\n",
              "          -1.6420883e-07]], dtype=float32),\n",
              " matrix([[ 5.0603126e-07,  1.6421689e-07, -1.3137350e-07,  1.2164213e-07,\n",
              "          -2.5544848e-08]], dtype=float32),\n",
              " matrix([[ 5.1272815e-07,  9.7418344e-08, -1.5125480e-07,  2.7430954e-07,\n",
              "           4.9670536e-08]], dtype=float32),\n",
              " matrix([[ 1.1630174e-08,  1.0176403e-07, -2.3551104e-07,  1.8899033e-08,\n",
              "          -1.8317525e-07]], dtype=float32),\n",
              " matrix([[-1.1402628e-07,  2.7383584e-07,  0.0000000e+00,  7.6017521e-08,\n",
              "          -9.3294226e-08]], dtype=float32),\n",
              " matrix([[6.61274157e-07, 4.40849448e-07, 1.07963132e-07, 1.67427203e-07,\n",
              "          1.00653125e-07]], dtype=float32),\n",
              " matrix([[-6.8940309e-08,  9.1920413e-08, -9.4792931e-08,  1.3500811e-07,\n",
              "           8.3302879e-08]], dtype=float32),\n",
              " matrix([[ 1.0451225e-06,  1.4370436e-07,  4.3642032e-07, -1.2553718e-08,\n",
              "           7.2668676e-08]], dtype=float32),\n",
              " matrix([[ 4.1919751e-08, -1.5195910e-07,  2.9474825e-07, -1.5163160e-07,\n",
              "           1.2575926e-07]], dtype=float32),\n",
              " matrix([[-7.0892605e-07, -2.3208888e-07, -8.8615757e-08, -2.4131969e-08,\n",
              "          -1.7617656e-07]], dtype=float32),\n",
              " matrix([[ 3.8793530e-07,  3.3136141e-07, -3.7177134e-07,  2.0204965e-08,\n",
              "           5.9099520e-08]], dtype=float32),\n",
              " matrix([[ 1.4975052e-07, -1.2807610e-07,  5.3200839e-08, -2.0984776e-07,\n",
              "          -1.4285411e-07]], dtype=float32),\n",
              " matrix([[-1.5777700e-07, -4.2073868e-08, -3.3659094e-07, -2.5594935e-07,\n",
              "          -1.7092509e-08]], dtype=float32),\n",
              " matrix([[-7.7259693e-07,  5.0928019e-08,  2.1125697e-08, -1.2977213e-07,\n",
              "          -5.2814244e-08]], dtype=float32),\n",
              " matrix([[-3.24878073e-07, -1.07419361e-07, -1.83398910e-07,\n",
              "          -7.27045659e-08, -1.10203096e-07]], dtype=float32),\n",
              " matrix([[ 3.0763687e-07,  1.7304575e-07,  1.2497748e-07,  0.0000000e+00,\n",
              "          -6.2969420e-08]], dtype=float32),\n",
              " matrix([[-1.5206051e-06, -2.6808357e-07,  3.6476945e-07,  3.3180834e-07,\n",
              "           1.2257407e-08]], dtype=float32),\n",
              " matrix([[-5.5057484e-07, -1.8557323e-07, -2.4579235e-08, -1.3764371e-07,\n",
              "          -1.3242062e-07]], dtype=float32),\n",
              " matrix([[-8.9545580e-07, -4.4356946e-07, -3.9089556e-07,  1.1588333e-07,\n",
              "           1.2648660e-08]], dtype=float32),\n",
              " matrix([[ 1.5894573e-08, -1.1920929e-07, -2.2947788e-07, -4.4703485e-09,\n",
              "          -5.7121117e-08]], dtype=float32),\n",
              " matrix([[-2.5234681e-07,  3.9654500e-07,  5.3582733e-07, -4.0965393e-08,\n",
              "          -2.1711658e-08]], dtype=float32),\n",
              " matrix([[ 2.9045918e-08, -4.8409863e-08,  6.4143066e-08,  1.0196327e-07,\n",
              "          -1.7064477e-07]], dtype=float32),\n",
              " matrix([[-1.09438034e-07, -5.47190169e-08, -7.62157768e-08,\n",
              "          -9.77125314e-09, -9.28269017e-09]], dtype=float32),\n",
              " matrix([[ 4.2737273e-07, -1.1871465e-08,  3.0173307e-08,  7.7411840e-08,\n",
              "          -2.5412353e-08]], dtype=float32),\n",
              " matrix([[-2.6786009e-07, -3.0018805e-07, -8.7169987e-08, -7.2737869e-08,\n",
              "           2.4029475e-08]], dtype=float32),\n",
              " matrix([[7.4488173e-07, 4.6272956e-07, 5.6430434e-08, 1.4883527e-07,\n",
              "          2.3982935e-08]], dtype=float32),\n",
              " matrix([[-1.8567111e-07,  1.5191273e-07,  6.3296966e-08, -3.7978182e-08,\n",
              "           4.2197978e-09]], dtype=float32),\n",
              " matrix([[7.35363301e-07, 1.60860722e-07, 2.32673557e-07, 1.17773034e-07,\n",
              "          1.71991715e-07]], dtype=float32),\n",
              " matrix([[-4.6669169e-07, -2.3334584e-07, -3.5001875e-07,  1.5218207e-08,\n",
              "          -1.6470538e-07]], dtype=float32),\n",
              " matrix([[-4.9476336e-07, -1.9360306e-07, -1.2010560e-07, -2.5007063e-07,\n",
              "           6.2741734e-08]], dtype=float32),\n",
              " matrix([[ 1.3821367e-08, -1.1057094e-07,  0.0000000e+00,  2.5396761e-07,\n",
              "           4.1464101e-08]], dtype=float32),\n",
              " matrix([[-7.3145895e-07, -1.9443846e-07,  1.3425512e-07, -2.3147434e-08,\n",
              "          -1.5045832e-07]], dtype=float32),\n",
              " matrix([[-2.7033289e-07, -8.4479026e-08,  6.1951283e-08,  1.0325214e-07,\n",
              "           3.0740978e-07]], dtype=float32),\n",
              " matrix([[ 9.2330254e-07,  1.9741665e-07, -1.6248910e-07,  2.1715833e-07,\n",
              "          -1.8716618e-07]], dtype=float32),\n",
              " matrix([[ 1.2557925e-06,  6.4791612e-07,  2.5343348e-07, -2.7299838e-09,\n",
              "          -4.8229712e-08]], dtype=float32),\n",
              " matrix([[-1.5633016e-06,  5.6813036e-07, -3.5083747e-08, -4.6778329e-08,\n",
              "           1.2524521e-07]], dtype=float32),\n",
              " matrix([[2.8128034e-07, 4.6344286e-07, 4.7549772e-08, 2.1162998e-07,\n",
              "          5.1233204e-08]], dtype=float32),\n",
              " matrix([[ 1.9210705e-07, -1.7666989e-07,  1.2349739e-07,  7.5041822e-09,\n",
              "           7.0968120e-08]], dtype=float32),\n",
              " matrix([[-1.7425943e-08,  1.9960625e-07, -8.8713890e-08,  1.5208096e-07,\n",
              "          -1.8079416e-07]], dtype=float32),\n",
              " matrix([[ 2.3972140e-07, -1.3288904e-07,  2.6056675e-08,  2.2083033e-07,\n",
              "           1.5992285e-07]], dtype=float32),\n",
              " matrix([[ 2.03697425e-07, -1.08792946e-07, -6.94423052e-09,\n",
              "          -5.26604147e-08, -1.06622871e-07]], dtype=float32),\n",
              " matrix([[ 1.03827446e-07, -1.96118506e-07,  1.53818434e-08,\n",
              "          -6.34501092e-08,  5.29952580e-08]], dtype=float32),\n",
              " matrix([[-3.0611767e-07,  3.5358065e-07, -5.5925344e-08, -6.7699105e-08,\n",
              "           6.6227386e-08]], dtype=float32),\n",
              " matrix([[ 0.0000000e+00, -5.8687650e-08, -7.3359566e-08,  5.1351694e-08,\n",
              "          -4.5849728e-09]], dtype=float32),\n",
              " matrix([[ 7.0390246e-07,  1.0217939e-07,  3.8884934e-07, -1.2488593e-07,\n",
              "          -1.6746067e-07]], dtype=float32),\n",
              " matrix([[1.51243498e-07, 0.00000000e+00, 1.82883852e-07, 1.07130816e-07,\n",
              "          6.30181276e-08]], dtype=float32),\n",
              " matrix([[ 1.17005425e-06,  2.08365819e-07,  4.97874112e-07,\n",
              "          -1.08189944e-07,  9.21618053e-08]], dtype=float32),\n",
              " matrix([[ 4.8165367e-07,  3.5160718e-07, -1.3245477e-08,  1.3727130e-07,\n",
              "           3.8532296e-08]], dtype=float32),\n",
              " matrix([[ 1.2945384e-07,  9.6857548e-08, -5.9953891e-08,  5.6810677e-08,\n",
              "          -1.3969839e-07]], dtype=float32),\n",
              " matrix([[-3.5321270e-07, -2.9434393e-08,  1.6924776e-07, -2.9728736e-07,\n",
              "           8.0944581e-08]], dtype=float32),\n",
              " matrix([[-5.7081235e-07, -4.3507040e-08,  6.9611261e-08, -2.4755505e-07,\n",
              "          -1.3530689e-07]], dtype=float32),\n",
              " matrix([[-1.7166138e-07,  4.2915346e-08, -5.0067900e-08, -4.1723252e-09,\n",
              "           4.4405461e-08]], dtype=float32),\n",
              " matrix([[ 3.24878073e-07,  1.04799376e-07, -1.67679005e-07,\n",
              "           6.81195971e-08,  1.10039345e-07]], dtype=float32),\n",
              " matrix([[ 9.5367432e-07,  1.7759751e-07,  3.4303082e-07,  4.7927000e-07,\n",
              "          -6.2037486e-08]], dtype=float32),\n",
              " matrix([[ 1.1786986e-07, -2.1430884e-08, -6.9650369e-08,  6.4962364e-08,\n",
              "          -9.2085827e-08]], dtype=float32),\n",
              " matrix([[-2.5045992e-07, -3.1307490e-08, -2.1915243e-07, -2.0470281e-07,\n",
              "           1.0235141e-07]], dtype=float32),\n",
              " matrix([[ 2.1375459e-07,  6.9752851e-08,  1.5414994e-08, -5.1897146e-08,\n",
              "           9.5059129e-08]], dtype=float32),\n",
              " matrix([[-8.1383263e-07, -4.3786488e-07,  4.3499929e-07, -2.3669921e-07,\n",
              "          -1.7537521e-07]], dtype=float32),\n",
              " matrix([[1.0331472e-06, 1.7660636e-08, 3.9736429e-07, 6.1812223e-08,\n",
              "          9.9617019e-08]], dtype=float32),\n",
              " matrix([[ 6.4074993e-07, -2.5611371e-08, -1.7136335e-07,  3.3527613e-08,\n",
              "           5.4715201e-08]], dtype=float32),\n",
              " matrix([[ 3.8146973e-07, -3.6784581e-07,  2.9291425e-07, -2.0435879e-08,\n",
              "          -8.4297994e-08]], dtype=float32),\n",
              " matrix([[-4.2162443e-07, -1.3552214e-07,  1.5618770e-07, -8.7838421e-09,\n",
              "          -4.6428880e-08]], dtype=float32),\n",
              " matrix([[-3.6964121e-07, -1.0349954e-07, -2.1346780e-07,  1.1089236e-08,\n",
              "           1.2937442e-08]], dtype=float32),\n",
              " matrix([[-9.3804033e-08,  2.2669307e-07, -2.6382384e-08,  1.4168317e-08,\n",
              "           1.7588256e-08]], dtype=float32),\n",
              " matrix([[ 1.8804846e-07,  1.6790041e-07, -3.0222072e-08,  9.9061239e-08,\n",
              "           9.5703236e-08]], dtype=float32),\n",
              " matrix([[-1.3847873e-06, -5.5032234e-07, -5.9604645e-07, -1.3472282e-07,\n",
              "          -4.1559952e-07]], dtype=float32),\n",
              " matrix([[-2.2007869e-07, -3.0566486e-07, -2.0479544e-07,  2.2084285e-07,\n",
              "           4.9670539e-09]], dtype=float32),\n",
              " matrix([[-6.7636478e-08,  8.4545597e-08, -1.3527295e-08,  2.4433677e-07,\n",
              "          -5.0727356e-09]], dtype=float32),\n",
              " matrix([[ 1.7801921e-07, -2.7974446e-07,  2.0980835e-07, -1.9073486e-08,\n",
              "           1.2715658e-07]], dtype=float32),\n",
              " matrix([[-9.9513841e-07,  8.5001403e-08, -1.9073487e-07, -4.9756920e-08,\n",
              "           6.6342558e-08]], dtype=float32),\n",
              " matrix([[-2.7876635e-07,  8.8031477e-08,  1.3938318e-07,  4.9976201e-08,\n",
              "          -3.2094810e-08]], dtype=float32),\n",
              " matrix([[-1.8289644e-07,  4.5724111e-08,  4.7357116e-08, -1.2614956e-07,\n",
              "          -2.0157392e-08]], dtype=float32),\n",
              " matrix([[-3.3302913e-07, -1.8922110e-07, -3.7844221e-09, -4.6201485e-08,\n",
              "          -6.9381070e-09]], dtype=float32),\n",
              " matrix([[ 1.6617052e-07, -2.8899223e-08,  4.6961237e-08,  1.4990060e-07,\n",
              "           6.6829450e-08]], dtype=float32),\n",
              " matrix([[ 1.0288603e-06,  1.6817908e-07, -5.9357324e-09, -1.4245758e-07,\n",
              "           3.0074378e-07]], dtype=float32),\n",
              " matrix([[ 2.0662944e-07,  2.3841858e-07, -9.3380613e-08,  6.4571701e-08,\n",
              "           6.2088170e-09]], dtype=float32),\n",
              " matrix([[ 3.2885321e-08, -6.1659975e-08, -1.2075078e-07, -5.1383315e-09,\n",
              "          -5.1383314e-08]], dtype=float32),\n",
              " matrix([[ 1.5258789e-07,  5.4041546e-08,  2.4159749e-07, -6.3578289e-09,\n",
              "           5.0862631e-08]], dtype=float32),\n",
              " matrix([[ 7.9472864e-09,  1.2715658e-07,  1.4305115e-07,  1.3584892e-07,\n",
              "          -7.8479452e-08]], dtype=float32),\n",
              " matrix([[-8.2104413e-07, -8.2735983e-07, -3.5052267e-07, -1.0894624e-07,\n",
              "          -7.1051893e-08]], dtype=float32),\n",
              " matrix([[ 1.4093710e-06,  5.4025886e-08,  2.0553325e-07,  1.9731193e-07,\n",
              "          -1.8732888e-07]], dtype=float32),\n",
              " matrix([[-1.8994671e-06, -1.1113065e-06, -5.0109770e-07,  1.3201689e-07,\n",
              "          -2.9950104e-07]], dtype=float32),\n",
              " matrix([[-4.0581885e-08,  1.8430940e-07,  1.3527295e-08,  1.6909119e-09,\n",
              "          -8.4017188e-08]], dtype=float32),\n",
              " matrix([[ 6.4052756e-08, -9.9637617e-08,  3.7008257e-07, -2.1350918e-07,\n",
              "          -9.7413562e-08]], dtype=float32),\n",
              " matrix([[-9.1360397e-07, -6.2509747e-07, -2.5945550e-07, -3.2056281e-08,\n",
              "           1.7230251e-07]], dtype=float32),\n",
              " matrix([[-5.3688331e-07, -2.7992107e-07,  2.0133125e-07, -1.3422083e-07,\n",
              "          -8.8303178e-09]], dtype=float32),\n",
              " matrix([[ 4.3710074e-07, -1.4404456e-07,  1.6142925e-08,  4.6566129e-08,\n",
              "           7.8851976e-08]], dtype=float32),\n",
              " matrix([[5.4868934e-07, 2.3188656e-07, 2.5964763e-07, 9.8796740e-08,\n",
              "          2.7597767e-07]], dtype=float32),\n",
              " matrix([[-9.8145119e-07, -4.5658317e-07, -9.0274995e-08, -4.5137497e-07,\n",
              "          -2.4304807e-08]], dtype=float32),\n",
              " matrix([[2.1430884e-08, 9.6438974e-08, 2.7458320e-08, 1.8484137e-07,\n",
              "          1.7077735e-07]], dtype=float32),\n",
              " matrix([[-3.3378601e-07, -7.1525577e-08, -1.0579824e-07,  1.2367964e-07,\n",
              "           7.4505806e-08]], dtype=float32),\n",
              " matrix([[-1.4458933e-06, -6.6526474e-07,  3.6676084e-07, -5.0247354e-07,\n",
              "          -1.2690022e-07]], dtype=float32),\n",
              " matrix([[-1.9927523e-07,  1.7080734e-07,  7.2504157e-08,  1.7792431e-09,\n",
              "           2.0461297e-08]], dtype=float32),\n",
              " matrix([[ 7.3892443e-07,  3.1866117e-07, -2.3784129e-07,  6.0037607e-08,\n",
              "           5.8305755e-08]], dtype=float32),\n",
              " matrix([[-5.2881467e-07, -4.1130031e-07, -1.7175178e-07, -1.4011329e-07,\n",
              "          -1.7471788e-07]], dtype=float32),\n",
              " matrix([[-2.5471672e-07, -2.2910535e-07, -1.4342368e-07,  1.9557774e-08,\n",
              "          -1.8626451e-07]], dtype=float32),\n",
              " matrix([[ 6.3578290e-07,  1.5330895e-07, -5.7149023e-08,  1.6742878e-07,\n",
              "           1.0626147e-07]], dtype=float32),\n",
              " matrix([[ 2.1108112e-07,  1.5775063e-07, -6.0052798e-08,  1.8643257e-07,\n",
              "          -3.7645037e-08]], dtype=float32),\n",
              " matrix([[-1.1656019e-06,  1.2068101e-07, -2.6638125e-07,  3.0170252e-08,\n",
              "          -1.0541192e-07]], dtype=float32),\n",
              " matrix([[ 1.6061884e-07,  2.3590891e-07, -1.7442201e-07, -1.5042330e-07,\n",
              "           2.1857650e-07]], dtype=float32),\n",
              " matrix([[ 2.2423755e-07, -3.0577848e-08,  3.1907319e-07,  5.3178866e-08,\n",
              "           1.7604420e-07]], dtype=float32),\n",
              " matrix([[4.1060977e-07, 1.4238887e-07, 5.7948959e-08, 5.4637592e-08,\n",
              "          5.2154064e-08]], dtype=float32),\n",
              " matrix([[ 1.5026382e-07,  1.6028140e-07,  5.6098489e-08, -4.4077385e-08,\n",
              "           2.9652060e-07]], dtype=float32),\n",
              " matrix([[-1.0084832e-06, -2.2471636e-07,  3.2405742e-07, -7.1594087e-08,\n",
              "          -3.5283211e-08]], dtype=float32),\n",
              " matrix([[ 6.3996566e-07, -3.7645037e-08,  4.0782126e-08,  2.4586916e-07,\n",
              "          -7.7642895e-08]], dtype=float32),\n",
              " matrix([[ 2.8500611e-07, -2.4663992e-08,  4.5217316e-08, -1.2229229e-07,\n",
              "          -2.5349102e-08]], dtype=float32),\n",
              " matrix([[-9.6905616e-08, -3.0763687e-09, -4.3069164e-08,  2.0919308e-07,\n",
              "          -2.1534581e-07]], dtype=float32),\n",
              " matrix([[1.0299683e-06, 1.2516975e-07, 1.2397766e-07, 1.6212464e-07,\n",
              "          3.5017729e-07]], dtype=float32),\n",
              " matrix([[-6.9936118e-07,  9.5367433e-08,  5.0001674e-08, -1.8874805e-07,\n",
              "           1.0463926e-07]], dtype=float32),\n",
              " matrix([[-1.1299459e-06, -5.3785425e-07, -2.5084799e-07, -2.2598918e-09,\n",
              "          -5.9463403e-08]], dtype=float32),\n",
              " matrix([[ 5.9989191e-07,  4.6722351e-07, -3.4609148e-08,  1.9227304e-09,\n",
              "          -1.7304574e-08]], dtype=float32),\n",
              " matrix([[-1.0899135e-07, -1.9073487e-07, -1.4532181e-07,  4.9812453e-08,\n",
              "          -1.7370496e-07]], dtype=float32),\n",
              " matrix([[ 2.6822090e-07,  6.9538750e-08,  1.3286869e-07,  5.5879354e-08,\n",
              "          -5.9604645e-08]], dtype=float32),\n",
              " matrix([[ 5.57809528e-07, -3.28387841e-07, -1.03464664e-07,\n",
              "           1.61944698e-07,  2.74406290e-07]], dtype=float32),\n",
              " matrix([[-1.7438616e-06, -6.2670028e-07, -2.0163399e-07, -4.8637389e-07,\n",
              "          -3.0926296e-07]], dtype=float32),\n",
              " matrix([[ 3.9719521e-07,  8.5982869e-08, -8.2431953e-08, -2.8407321e-08,\n",
              "           3.6472969e-07]], dtype=float32),\n",
              " matrix([[ 9.4432454e-07,  3.3659094e-07,  1.5646219e-07,  6.8954392e-08,\n",
              "          -1.9868214e-07]], dtype=float32),\n",
              " matrix([[ 3.3181968e-07, -4.0309945e-07, -1.8434426e-07, -2.7037157e-07,\n",
              "          -1.1736585e-07]], dtype=float32),\n",
              " matrix([[-4.56105113e-07,  2.93704048e-08, -2.41873916e-08,\n",
              "           1.07115596e-07, -3.02342400e-08]], dtype=float32),\n",
              " matrix([[ 2.5142322e-07,  5.2018599e-08, -7.3693016e-08,  4.0097671e-08,\n",
              "           3.1725926e-07]], dtype=float32),\n",
              " matrix([[4.05311596e-07, 1.49011614e-09, 1.13248824e-07, 2.38418579e-07,\n",
              "          1.28149992e-07]], dtype=float32),\n",
              " matrix([[-6.6425076e-07,  1.6606269e-07, -4.5074160e-07, -8.5403670e-08,\n",
              "          -1.3759480e-07]], dtype=float32),\n",
              " matrix([[-3.9951220e-07, -2.5774980e-07, -4.8972464e-07, -1.9331235e-08,\n",
              "           1.3290225e-08]], dtype=float32),\n",
              " matrix([[ 2.7454260e-07,  2.0229456e-07,  8.3085261e-08,  3.6124028e-08,\n",
              "          -1.4088370e-07]], dtype=float32),\n",
              " matrix([[-8.1296827e-07,  0.0000000e+00,  2.3451008e-07, -2.1692182e-07,\n",
              "          -6.6200244e-08]], dtype=float32),\n",
              " matrix([[7.6001629e-07, 1.6808053e-07, 2.9779486e-07, 7.3078489e-08,\n",
              "          2.0096586e-07]], dtype=float32),\n",
              " matrix([[ 5.2275482e-07, -2.7903803e-07, -1.2009232e-07, -1.2892264e-07,\n",
              "           3.5321270e-09]], dtype=float32),\n",
              " matrix([[-2.0435878e-07, -3.4059798e-07,  1.3198171e-07,  6.3862117e-08,\n",
              "           8.0892015e-08]], dtype=float32),\n",
              " matrix([[-5.5905048e-07,  1.1098796e-07, -1.9731193e-07, -1.5723295e-07,\n",
              "          -1.0276663e-07]], dtype=float32),\n",
              " matrix([[ 8.6284821e-08,  1.8165226e-08, -7.2660903e-08,  6.0172312e-08,\n",
              "           3.7465778e-08]], dtype=float32),\n",
              " matrix([[ 6.3143671e-07,  2.5890768e-07,  6.4261258e-07, -4.4936314e-08,\n",
              "           3.4179538e-07]], dtype=float32),\n",
              " matrix([[1.2737431e-07, 8.9815217e-08, 2.0167599e-07, 1.8289644e-07,\n",
              "          8.4916209e-08]], dtype=float32),\n",
              " matrix([[ 6.3578290e-07,  2.5857897e-08,  1.6263449e-07,  2.5010576e-07,\n",
              "          -6.8370035e-08]], dtype=float32),\n",
              " matrix([[ 2.1347940e-07,  3.9902691e-08,  4.8880796e-08,  1.2469592e-07,\n",
              "          -6.4841871e-08]], dtype=float32),\n",
              " matrix([[ 1.1711790e-07,  1.5058015e-07, -3.0325172e-08,  3.2416562e-08,\n",
              "          -1.1764074e-09]], dtype=float32),\n",
              " matrix([[-8.2232992e-07,  3.5691404e-08, -4.4542873e-07, -3.2265029e-07,\n",
              "          -2.1985905e-07]], dtype=float32),\n",
              " matrix([[ 5.0193387e-07,  1.8822520e-07, -2.1645897e-07,  1.2548346e-08,\n",
              "           1.5267155e-07]], dtype=float32),\n",
              " matrix([[-6.68810571e-07, -6.19269036e-09, -2.70930212e-08,\n",
              "          -1.11081384e-07,  1.16112941e-08]], dtype=float32),\n",
              " matrix([[-1.6348703e-07,  8.8555474e-08,  2.5885447e-07,  6.1307638e-08,\n",
              "           1.2814999e-07]], dtype=float32),\n",
              " matrix([[ 6.4683996e-07, -2.3219896e-07,  7.4635381e-08, -7.4829742e-08,\n",
              "           1.2957531e-07]], dtype=float32),\n",
              " matrix([[ 5.35874165e-07,  1.81652258e-08, -7.26609031e-08,\n",
              "          -5.67663305e-10,  1.04450045e-07]], dtype=float32),\n",
              " matrix([[-3.5591674e-07,  1.4601711e-07, -1.3917257e-07, -5.9319454e-08,\n",
              "          -4.6200729e-08]], dtype=float32),\n",
              " matrix([[-3.4263749e-07,  3.2407794e-07,  2.9552481e-07,  7.2810465e-08,\n",
              "           4.4257341e-08]], dtype=float32),\n",
              " matrix([[ 1.5361196e-07, -9.6007478e-09,  1.4081097e-07,  1.6801309e-08,\n",
              "          -7.5205861e-08]], dtype=float32),\n",
              " matrix([[-6.8119596e-07, -6.9822585e-07,  8.5149495e-08, -4.3506068e-07,\n",
              "          -1.7029899e-07]], dtype=float32),\n",
              " matrix([[-4.7192131e-07, -1.1798033e-07, -2.9003496e-07, -1.2228169e-07,\n",
              "          -2.9725513e-07]], dtype=float32),\n",
              " matrix([[ 1.4449611e-07,  2.6490954e-07,  1.7098706e-07, -2.8899223e-08,\n",
              "           9.6330737e-08]], dtype=float32),\n",
              " matrix([[-7.2702949e-07, -9.1246619e-08, -1.6704018e-07,  2.0972005e-08,\n",
              "           2.2922033e-07]], dtype=float32),\n",
              " matrix([[ 9.4296411e-09, -1.1101365e-06, -1.5459955e-06, -5.0337985e-07,\n",
              "          -1.5459955e-07]], dtype=float32),\n",
              " matrix([[ 9.67698952e-07,  4.72162270e-07,  1.26221607e-07,\n",
              "          -3.92689429e-07, -1.07522105e-07]], dtype=float32),\n",
              " matrix([[-2.36774312e-07, -1.18387156e-07, -1.54561008e-07,\n",
              "          -7.89247707e-08, -5.09722469e-08]], dtype=float32),\n",
              " matrix([[-5.0401439e-07,  8.4002401e-08, -1.5194551e-07, -1.2693010e-07,\n",
              "          -2.8289043e-07]], dtype=float32),\n",
              " matrix([[-2.2293685e-07, -1.2385381e-08, -1.3159467e-07,  4.2574747e-08,\n",
              "          -1.2520846e-07]], dtype=float32),\n",
              " matrix([[-6.6173322e-07, -3.2437903e-08,  6.4875806e-08, -6.0010116e-08,\n",
              "           3.6898115e-08]], dtype=float32),\n",
              " matrix([[ 3.0517577e-07,  1.4495849e-07,  1.5258789e-07,  6.6757204e-09,\n",
              "          -1.3446808e-07]], dtype=float32),\n",
              " matrix([[ 3.46790671e-07, -1.12706964e-07,  1.14874403e-07,\n",
              "          -2.76348811e-08,  1.53888351e-07]], dtype=float32),\n",
              " matrix([[-9.6381984e-07,  2.9802322e-08,  1.4457297e-07, -5.9921689e-08,\n",
              "           1.8117197e-07]], dtype=float32),\n",
              " matrix([[-5.2018601e-07, -7.1427053e-08, -1.8915854e-07,  3.7591565e-08,\n",
              "           3.5929041e-08]], dtype=float32),\n",
              " matrix([[1.0229356e-06, 5.0613998e-08, 1.5983369e-08, 4.1956341e-08,\n",
              "          1.1821033e-07]], dtype=float32),\n",
              " matrix([[ 1.7498611e-07, -6.9994442e-08, -8.8860136e-10,  8.7493053e-09,\n",
              "           7.2728604e-08]], dtype=float32),\n",
              " matrix([[ 9.5945416e-07,  6.6468209e-07,  1.3510386e-07, -1.6761548e-07,\n",
              "          -1.4449611e-08]], dtype=float32),\n",
              " matrix([[7.5531005e-07, 3.4332277e-07, 4.0817261e-07, 1.2207032e-07,\n",
              "          3.1471252e-08]], dtype=float32),\n",
              " matrix([[ 2.2936472e-07,  2.2936472e-07, -1.0261053e-07,  5.5832199e-08,\n",
              "          -7.5448919e-10]], dtype=float32),\n",
              " matrix([[ 8.2157754e-08,  9.6656176e-09,  2.5774982e-08, -2.4486232e-07,\n",
              "          -1.5464988e-07]], dtype=float32),\n",
              " matrix([[-6.0532619e-07, -1.0279124e-07,  8.8514682e-08, -8.2804057e-08,\n",
              "          -9.7080616e-08]], dtype=float32),\n",
              " matrix([[-6.0550752e-07, -1.0091791e-08, -2.1823500e-07, -4.0367166e-08,\n",
              "          -7.3165488e-08]], dtype=float32),\n",
              " matrix([[ 5.1657361e-07,  2.5828680e-07,  2.5828680e-07, -2.4276474e-07,\n",
              "           2.0861626e-07]], dtype=float32),\n",
              " matrix([[ 1.4395084e-07, -5.8480030e-08, -4.2735405e-08, -4.7796178e-08,\n",
              "          -4.8920793e-08]], dtype=float32),\n",
              " matrix([[-1.6312850e-07,  3.6076496e-08,  4.2350667e-08, -5.0193385e-08,\n",
              "           3.6076496e-08]], dtype=float32),\n",
              " matrix([[ 9.42454619e-07,  2.52443204e-08, -1.65490547e-07,\n",
              "          -2.30705041e-07,  1.02379744e-07]], dtype=float32),\n",
              " matrix([[ 9.4911127e-07,  2.7150060e-07,  6.9015904e-08, -6.1600971e-08,\n",
              "           9.6964492e-08]], dtype=float32),\n",
              " matrix([[ 4.0581887e-07, -4.7345534e-08,  2.1981855e-07, -7.4400127e-08,\n",
              "          -6.2141012e-08]], dtype=float32),\n",
              " matrix([[-3.0179567e-07,  2.1729288e-07, -6.9413005e-08, -1.2071827e-08,\n",
              "           1.1468236e-07]], dtype=float32),\n",
              " matrix([[ 2.2049062e-06,  1.2721866e-06, -1.4295802e-07,  2.3283064e-08,\n",
              "           8.9406967e-07]], dtype=float32),\n",
              " matrix([[ 1.1951417e-07,  0.0000000e+00, -5.6098489e-08,  6.7684049e-08,\n",
              "           1.4664877e-07]], dtype=float32),\n",
              " matrix([[ 8.9528612e-07, -2.4977186e-07,  3.2437902e-07, -2.9031924e-07,\n",
              "          -2.7126197e-07]], dtype=float32),\n",
              " matrix([[ 2.7359508e-07,  2.5796109e-07,  1.7197405e-07,  3.4199386e-09,\n",
              "          -4.8856265e-08]], dtype=float32),\n",
              " matrix([[ 3.9085012e-07,  3.7326188e-07,  2.0715056e-07, -1.8321099e-08,\n",
              "          -1.1725504e-08]], dtype=float32),\n",
              " matrix([[ 2.5675848e-07, -1.4671913e-07,  2.2924864e-08,  1.6047404e-07,\n",
              "           9.1699455e-08]], dtype=float32),\n",
              " matrix([[-1.3854374e-06, -9.7265293e-08,  6.5238915e-08, -2.6273491e-07,\n",
              "           2.1588150e-07]], dtype=float32),\n",
              " matrix([[ 4.0154710e-08,  1.5058015e-08, -6.5251399e-08, -3.2625699e-08,\n",
              "           4.7056300e-08]], dtype=float32),\n",
              " matrix([[-2.1538037e-06, -2.5181288e-07, -6.1783311e-07,  1.5671334e-07,\n",
              "           1.9036652e-07]], dtype=float32),\n",
              " matrix([[ 3.7134222e-07,  2.0255030e-07,  1.7723151e-07, -1.5191273e-07,\n",
              "           2.9538585e-08]], dtype=float32),\n",
              " matrix([[ 1.8699497e-08,  1.6829547e-07,  6.1357724e-08, -4.5580023e-08,\n",
              "          -1.2388416e-07]], dtype=float32),\n",
              " matrix([[-3.0199686e-07,  1.5894573e-08,  6.3578291e-08,  3.0919910e-08,\n",
              "          -6.0101350e-08]], dtype=float32),\n",
              " matrix([[ 1.0427719e-06,  1.6499555e-07, -9.7347382e-08,  1.0312222e-08,\n",
              "           1.0430813e-07]], dtype=float32),\n",
              " matrix([[4.4750050e-07, 7.0803799e-07, 7.6158904e-07, 1.3076933e-06,\n",
              "          1.7759157e-07]], dtype=float32),\n",
              " matrix([[ 7.4317865e-07,  2.0942173e-07,  1.7183321e-07,  8.9138474e-08,\n",
              "          -5.0207515e-08]], dtype=float32),\n",
              " matrix([[-2.22524008e-07, -2.78155010e-08, -1.30136812e-07,\n",
              "          -1.13248824e-07,  1.11262004e-07]], dtype=float32),\n",
              " matrix([[-9.6516442e-07,  3.3321152e-07, -2.3590513e-07, -7.8994105e-08,\n",
              "          -2.7001622e-07]], dtype=float32),\n",
              " matrix([[-6.9266872e-07,  4.5174048e-08, -1.3677698e-07, -7.5290075e-08,\n",
              "          -1.3552214e-07]], dtype=float32),\n",
              " matrix([[ 8.6697668e-08,  4.4897003e-08, -8.5149495e-08,  2.1674417e-07,\n",
              "           3.7930228e-08]], dtype=float32),\n",
              " matrix([[-1.0182658e-06,  1.8047622e-07,  3.7615044e-07,  3.0039789e-08,\n",
              "          -8.5132534e-08]], dtype=float32),\n",
              " matrix([[-4.1018250e-08,  1.2818203e-08,  3.1815182e-07, -2.0252762e-07,\n",
              "          -1.1350118e-07]], dtype=float32),\n",
              " matrix([[ 1.8060734e-06,  1.9833050e-07, -2.1626464e-08,  3.3125414e-07,\n",
              "           1.7406666e-08]], dtype=float32),\n",
              " matrix([[ 0.0000000e+00,  5.0727358e-08, -1.1286837e-07, -9.8918349e-08,\n",
              "           4.8190991e-08]], dtype=float32),\n",
              " matrix([[ 2.70545897e-08,  6.08728286e-08,  2.87455020e-08,\n",
              "           3.93137007e-08, -1.14136554e-07]], dtype=float32),\n",
              " matrix([[ 1.9972236e-07, -4.2441005e-08,  1.9254485e-07, -1.4042979e-08,\n",
              "           6.9902832e-08]], dtype=float32),\n",
              " matrix([[-2.6702881e-07,  1.4781952e-07,  1.6063451e-07,  3.8146972e-08,\n",
              "          -3.9219856e-07]], dtype=float32),\n",
              " matrix([[ 4.35009326e-07,  2.00773542e-07, -5.85589497e-08,\n",
              "           1.06660941e-07, -1.18686444e-07]], dtype=float32),\n",
              " matrix([[-5.6499192e-07,  4.0070351e-09, -1.5376996e-07, -6.2509747e-07,\n",
              "          -1.6028140e-07]], dtype=float32),\n",
              " matrix([[ 8.8424974e-07, -6.9881310e-08, -2.0827370e-07,  2.9962180e-07,\n",
              "          -1.5392158e-07]], dtype=float32),\n",
              " matrix([[-2.7247838e-08,  8.3446501e-08,  2.4182455e-07,  1.3113022e-07,\n",
              "          -7.0886955e-08]], dtype=float32),\n",
              " matrix([[ 1.3154128e-07, -2.1375459e-07,  1.6442661e-07,  1.3154128e-07,\n",
              "           1.6031593e-07]], dtype=float32),\n",
              " matrix([[ 3.6808481e-07, -1.3384903e-07,  4.6010604e-07, -6.3787425e-08,\n",
              "          -3.7645037e-08]], dtype=float32),\n",
              " matrix([[-2.1311158e-07,  1.4917811e-07, -6.1269581e-08, -1.1188358e-07,\n",
              "           1.0322592e-07]], dtype=float32),\n",
              " matrix([[ 8.3446503e-07,  1.5050173e-07,  2.3841858e-08, -1.7881394e-08,\n",
              "           2.8312206e-07]], dtype=float32),\n",
              " matrix([[-1.1506909e-06, -3.9546075e-07, -6.5672182e-08,  1.5561452e-07,\n",
              "          -5.1110089e-07]], dtype=float32),\n",
              " matrix([[-6.2355628e-07, -1.4366248e-07, -3.1177814e-07, -7.5804883e-07,\n",
              "           1.5283243e-07]], dtype=float32),\n",
              " matrix([[3.4090621e-07, 1.6829547e-07, 3.0206881e-08, 2.1576343e-09,\n",
              "          1.6182257e-08]], dtype=float32),\n",
              " matrix([[1.5207239e-06, 1.9331235e-08, 2.1828187e-07, 2.1727504e-07,\n",
              "          4.2448173e-07]], dtype=float32),\n",
              " matrix([[ 9.1816514e-07,  5.0727358e-08,  1.0621041e-07, -1.2745248e-07,\n",
              "           2.0290943e-07]], dtype=float32),\n",
              " matrix([[ 7.4768064e-07,  2.4795531e-07, -3.8146974e-09,  1.9359588e-07,\n",
              "           7.7128412e-08]], dtype=float32),\n",
              " matrix([[-2.7528742e-07, -1.2781202e-07,  1.4747541e-08, -1.8434426e-08,\n",
              "           2.7037158e-08]], dtype=float32),\n",
              " matrix([[-1.83398910e-07, -1.83398914e-08,  1.10039345e-07,\n",
              "           4.58497285e-09,  2.98739629e-08]], dtype=float32),\n",
              " matrix([[-1.6348703e-07, -2.8865679e-07, -3.7040028e-08,  4.2574747e-08,\n",
              "           8.0040522e-08]], dtype=float32),\n",
              " matrix([[-1.76970488e-07,  1.08148633e-07, -1.03232786e-07,\n",
              "           8.11114731e-08, -1.40101633e-07]], dtype=float32),\n",
              " matrix([[ 1.7579251e-07, -1.0767290e-07, -4.8342937e-08, -2.5709653e-07,\n",
              "          -1.1914062e-07]], dtype=float32),\n",
              " matrix([[-9.6502754e-07, -4.7116052e-07, -4.8960959e-07,  1.5153948e-07,\n",
              "          -1.3960968e-07]], dtype=float32),\n",
              " matrix([[ 1.8289644e-07,  3.9192095e-08,  3.2660079e-09, -2.4821659e-07,\n",
              "          -9.4714231e-08]], dtype=float32),\n",
              " matrix([[-5.1770894e-07, -1.8392291e-07,  5.8114530e-08, -2.0265580e-07,\n",
              "          -4.8109463e-08]], dtype=float32),\n",
              " matrix([[ 9.3149583e-07, -5.6370283e-08,  8.3169269e-08,  2.4119089e-07,\n",
              "          -1.3491903e-07]], dtype=float32),\n",
              " matrix([[1.3258399e-06, 3.0238454e-07, 4.8846732e-07, 2.8145021e-07,\n",
              "          1.6631149e-07]], dtype=float32),\n",
              " matrix([[-7.7934675e-07,  3.5314150e-07,  2.1534581e-07, -5.2554633e-08,\n",
              "          -2.5892771e-07]], dtype=float32),\n",
              " matrix([[-5.6624413e-07, -2.9802322e-08, -2.6077032e-08, -1.1920929e-07,\n",
              "           2.5052577e-07]], dtype=float32),\n",
              " matrix([[ 4.1181391e-07,  2.7634880e-07,  2.6009300e-07, -2.4383718e-08,\n",
              "          -2.0861626e-07]], dtype=float32),\n",
              " matrix([[-4.1239971e-08, -1.7333674e-07, -2.3197483e-08, -1.6238238e-07,\n",
              "           2.0458891e-08]], dtype=float32),\n",
              " matrix([[ 6.5878815e-08, -3.5135369e-07,  2.1332188e-07,  5.0193385e-08,\n",
              "           6.5878815e-08]], dtype=float32),\n",
              " matrix([[-2.6822090e-07,  2.2351742e-07, -3.3527613e-08, -2.0721927e-07,\n",
              "          -3.2596290e-08]], dtype=float32),\n",
              " matrix([[-1.6412069e-06, -3.7333763e-07, -3.9311919e-07, -2.5747821e-07,\n",
              "          -1.9918751e-08]], dtype=float32),\n",
              " matrix([[-3.74448803e-07, -1.17015254e-07, -7.53285718e-08,\n",
              "           5.30225357e-08, -2.12090150e-08]], dtype=float32),\n",
              " matrix([[ 7.4400127e-08,  1.3527296e-07,  1.0483654e-07, -1.3527295e-08,\n",
              "           4.8613717e-08]], dtype=float32),\n",
              " matrix([[-4.0154708e-07,  9.6801529e-08, -3.2939408e-08,  5.3778626e-09,\n",
              "           8.9631044e-08]], dtype=float32),\n",
              " matrix([[ 1.8658845e-07,  1.7622243e-07, -2.3453131e-07,  3.7900779e-08,\n",
              "          -1.1920929e-07]], dtype=float32),\n",
              " matrix([[ 5.0108309e-07,  2.4650058e-07,  1.5961922e-07, -2.7781826e-09,\n",
              "           1.1617854e-08]], dtype=float32),\n",
              " matrix([[-2.1192763e-07, -1.4570024e-07,  3.7844221e-09, -3.0275376e-07,\n",
              "          -6.2916016e-08]], dtype=float32),\n",
              " matrix([[ 4.4356945e-08, -1.5524931e-07,  3.6964121e-09,  3.1419503e-08,\n",
              "           4.9901562e-08]], dtype=float32),\n",
              " matrix([[ 1.1235068e-06,  1.7636442e-07,  4.8990119e-09,  2.2606899e-07,\n",
              "          -7.6342936e-08]], dtype=float32),\n",
              " matrix([[-5.8572124e-07, -1.5769417e-07,  3.1914297e-08, -2.4405052e-08,\n",
              "          -1.2624920e-07]], dtype=float32),\n",
              " matrix([[ 5.239969e-07, -8.121952e-08,  6.156964e-08,  7.597955e-08,\n",
              "           9.743067e-08]], dtype=float32),\n",
              " matrix([[-4.7683716e-07, -1.2874604e-07, -1.2397766e-07, -5.8412553e-08,\n",
              "          -8.0466272e-08]], dtype=float32),\n",
              " matrix([[ 6.8664548e-08,  1.1253357e-07,  4.3869019e-08, -4.2438508e-08,\n",
              "          -9.8228455e-08]], dtype=float32),\n",
              " matrix([[ 2.6009300e-07, -8.2362781e-08,  5.2018599e-08, -1.1595813e-07,\n",
              "           1.4955347e-07]], dtype=float32),\n",
              " matrix([[-3.2885321e-08, -9.0434632e-08, -7.3991970e-08,  1.0276663e-08,\n",
              "           4.1106651e-09]], dtype=float32),\n",
              " matrix([[-1.1704185e-06, -2.0373952e-07,  8.0195342e-08,  8.6697662e-09,\n",
              "           5.7979065e-08]], dtype=float32),\n",
              " matrix([[-3.7715932e-08, -5.9267894e-08, -3.5021937e-08,  2.9633947e-08,\n",
              "          -6.7349881e-10]], dtype=float32),\n",
              " matrix([[2.62078430e-07, 2.18398696e-07, 1.05559373e-07, 9.50944354e-08,\n",
              "          1.08289356e-07]], dtype=float32),\n",
              " matrix([[ 1.2715658e-06,  3.2243275e-07,  5.1770894e-07, -2.2706531e-07,\n",
              "           4.1297503e-07]], dtype=float32),\n",
              " matrix([[-1.1032051e-06, -1.8774425e-07, -1.6282245e-07, -1.8940570e-07,\n",
              "          -5.6904781e-08]], dtype=float32),\n",
              " matrix([[-1.2925257e-07, -1.1178600e-07,  1.6898899e-07,  7.8599534e-08,\n",
              "          -3.5806455e-08]], dtype=float32),\n",
              " matrix([[-2.5431316e-07, -1.2516975e-07, -2.4139882e-07, -7.3512396e-08,\n",
              "          -5.8114530e-08]], dtype=float32),\n",
              " matrix([[ 1.3830037e-06,  4.5044396e-07, -4.9267307e-08, -2.4721632e-07,\n",
              "          -2.1334504e-08]], dtype=float32),\n",
              " matrix([[ 3.8552793e-07,  3.0816869e-07,  2.7519590e-07,  1.9561737e-07,\n",
              "          -5.6434185e-08]], dtype=float32),\n",
              " matrix([[-1.5600568e-06, -5.8433221e-07, -3.8295124e-07,  5.2093770e-07,\n",
              "           9.5780877e-08]], dtype=float32),\n",
              " matrix([[ 3.2011445e-07, -2.7093021e-08,  1.7339534e-07, -1.6672628e-08,\n",
              "           1.6839354e-07]], dtype=float32),\n",
              " matrix([[-1.4059005e-06, -2.1996037e-07, -1.6612391e-07, -8.6753602e-07,\n",
              "          -7.7582172e-08]], dtype=float32),\n",
              " matrix([[-1.7100368e-07, -9.3723166e-08, -7.8924771e-08,  3.8640252e-08,\n",
              "           1.5003927e-08]], dtype=float32),\n",
              " matrix([[-2.4573202e-07, -2.3110512e-07,  6.6186750e-08, -6.1433006e-08,\n",
              "           5.7044936e-08]], dtype=float32),\n",
              " matrix([[ 2.9669869e-07,  1.2715658e-07,  5.6955550e-08, -1.5894573e-08,\n",
              "           3.2451418e-08]], dtype=float32),\n",
              " matrix([[-9.4190057e-08, -1.7071947e-07, -5.8868785e-08,  2.9434393e-08,\n",
              "          -1.8543668e-07]], dtype=float32),\n",
              " matrix([[ 1.0775981e-08,  8.3513854e-08, -8.0819859e-08,  1.8453868e-07,\n",
              "           8.6207848e-08]], dtype=float32),\n",
              " matrix([[-1.3398731e-06, -1.2425845e-07,  3.9408029e-08, -3.2954964e-07,\n",
              "          -3.2511625e-08]], dtype=float32),\n",
              " matrix([[1.2223149e-06, 3.7609692e-07, 3.0222072e-08, 1.9938174e-08,\n",
              "          3.0389972e-07]], dtype=float32),\n",
              " matrix([[ 9.8546343e-07,  2.2384856e-07,  1.8013849e-07, -5.8559493e-08,\n",
              "           4.2716660e-08]], dtype=float32),\n",
              " matrix([[ 1.6348703e-07,  4.0871758e-08, -6.8119594e-09,  2.1798270e-07,\n",
              "          -2.1117074e-07]], dtype=float32),\n",
              " matrix([[ 4.0871757e-07, -3.4059799e-08,  1.0217939e-07,  2.9802322e-08,\n",
              "           1.4901161e-08]], dtype=float32),\n",
              " matrix([[ 4.8618693e-07,  4.3826944e-08, -1.4024623e-07,  1.5738743e-07,\n",
              "           1.9011155e-07]], dtype=float32),\n",
              " matrix([[ 9.3236315e-07,  3.0901180e-07,  2.5839779e-07, -1.5483889e-07,\n",
              "           8.8740997e-08]], dtype=float32),\n",
              " matrix([[-1.5570193e-06, -2.1084637e-07, -3.5681690e-08, -3.0005060e-07,\n",
              "          -5.5833738e-07]], dtype=float32),\n",
              " matrix([[ 4.5684996e-07,  7.4951949e-08, -1.3277203e-07, -5.7106245e-08,\n",
              "           1.1278484e-07]], dtype=float32),\n",
              " matrix([[ 1.0940264e-06,  3.2388940e-08, -2.9150044e-07, -6.8376650e-08,\n",
              "           1.8938532e-07]], dtype=float32),\n",
              " matrix([[-2.3119378e-07,  5.2018599e-08, -1.5894573e-08,  1.1848681e-07,\n",
              "           1.0403720e-07]], dtype=float32),\n",
              " matrix([[-3.2002495e-07,  3.6871622e-08, -8.4006544e-08, -1.9639030e-08,\n",
              "          -8.5406654e-08]], dtype=float32),\n",
              " matrix([[ 1.0234554e-07, -4.7102208e-08,  8.6063295e-08,  1.6805602e-07,\n",
              "          -1.6049641e-07]], dtype=float32),\n",
              " matrix([[ 1.2858530e-07,  8.7062965e-08,  1.1117271e-07, -1.7123779e-07,\n",
              "          -5.0228635e-09]], dtype=float32),\n",
              " matrix([[ 1.08382665e-07, -2.40281224e-07,  4.09781933e-07,\n",
              "           2.02562660e-07,  1.82539225e-07]], dtype=float32),\n",
              " matrix([[7.5290075e-08, 8.1564252e-08, 1.2862056e-07, 1.9998927e-07,\n",
              "          3.2155139e-08]], dtype=float32),\n",
              " matrix([[ 2.9903347e-07,  5.0647111e-07,  1.1314780e-07, -1.8049768e-07,\n",
              "          -2.1551962e-08]], dtype=float32),\n",
              " matrix([[-2.6207843e-07,  2.5206850e-07, -6.1424636e-08,  7.2799566e-09,\n",
              "          -1.0191939e-07]], dtype=float32),\n",
              " matrix([[-5.6653920e-07, -1.0386552e-07, -9.3242910e-08, -1.1802900e-07,\n",
              "          -1.8648582e-07]], dtype=float32),\n",
              " matrix([[ 0.0000000e+00,  5.8218490e-08, -9.3911972e-08, -6.9307724e-08,\n",
              "          -6.2550221e-08]], dtype=float32),\n",
              " matrix([[-1.4512435e-07, -1.1726566e-07,  1.2957531e-08,  4.7942866e-08,\n",
              "          -3.0450199e-08]], dtype=float32),\n",
              " matrix([[ 3.6215479e-07, -3.0179567e-07,  4.7344194e-08, -1.5391579e-07,\n",
              "           6.3377094e-08]], dtype=float32),\n",
              " matrix([[2.5796109e-07, 1.0162103e-07, 2.0519632e-07, 2.9313760e-09,\n",
              "          8.1101405e-08]], dtype=float32),\n",
              " matrix([[-2.89880518e-07, -7.40009568e-07, -1.78488222e-07,\n",
              "           1.14649374e-07, -2.34510082e-07]], dtype=float32),\n",
              " matrix([[-4.7923333e-08,  1.4174823e-07,  2.8754000e-08, -1.0483229e-07,\n",
              "           1.7492016e-07]], dtype=float32),\n",
              " matrix([[ 2.8141210e-07,  3.1268009e-08, -3.9085011e-09,  2.9313760e-09,\n",
              "           2.3451008e-08]], dtype=float32),\n",
              " matrix([[8.0841266e-07, 9.4735860e-08, 1.6262989e-07, 6.3946707e-08,\n",
              "          8.4867544e-08]], dtype=float32),\n",
              " matrix([[-4.7202062e-07,  1.2041342e-08, -1.2041342e-07, -2.9862528e-07,\n",
              "           1.0957621e-07]], dtype=float32),\n",
              " matrix([[ 5.2756451e-07,  1.2681839e-07, -1.7754575e-08, -2.7900047e-08,\n",
              "           5.1995542e-08]], dtype=float32),\n",
              " matrix([[-1.5915214e-06, -4.3348834e-07, -3.5298336e-07,  1.0295348e-07,\n",
              "          -1.4746344e-07]], dtype=float32),\n",
              " matrix([[-4.6428880e-07,  9.4112593e-09, -1.5058015e-07, -4.1566398e-08,\n",
              "           5.7643966e-08]], dtype=float32),\n",
              " matrix([[-2.0980835e-07, -1.6212464e-07, -2.7716160e-07, -1.6689301e-08,\n",
              "           3.2484532e-08]], dtype=float32),\n",
              " matrix([[-9.7980241e-08, -3.9192096e-07, -2.7761068e-08, -7.6751185e-08,\n",
              "           7.0219173e-08]], dtype=float32),\n",
              " matrix([[-1.50184931e-08, -1.48307620e-07,  4.36474963e-08,\n",
              "           1.07241426e-07,  7.41538102e-08]], dtype=float32),\n",
              " matrix([[ 6.86645535e-07,  2.73386632e-07, -6.35782893e-09,\n",
              "          -1.13248824e-07, -4.86771246e-09]], dtype=float32),\n",
              " matrix([[ 5.6704960e-07,  2.5774980e-07, -1.1276555e-08, -7.5177027e-08,\n",
              "           2.5238002e-08]], dtype=float32),\n",
              " matrix([[ 1.4395084e-08, -5.0382795e-08, -3.8686789e-08, -2.0468010e-08,\n",
              "          -2.9240015e-08]], dtype=float32),\n",
              " matrix([[ 1.0049471e-06,  5.2554633e-08, -5.8963735e-08,  3.1773121e-07,\n",
              "           1.2561839e-07]], dtype=float32),\n",
              " matrix([[-6.2951898e-07, -7.0468545e-08, -2.4076753e-08,  6.0925927e-08,\n",
              "          -1.8409908e-07]], dtype=float32),\n",
              " matrix([[ 1.0732157e-06,  3.6659347e-07,  3.9780704e-07, -1.6944364e-07,\n",
              "           3.7970980e-07]], dtype=float32),\n",
              " matrix([[ 4.6624078e-07,  3.7087335e-07, -3.7087336e-08,  4.3875641e-08,\n",
              "          -9.6691977e-08]], dtype=float32),\n",
              " matrix([[ 5.8248372e-07, -2.1414843e-07,  2.7982060e-07,  2.8196209e-07,\n",
              "          -4.8718768e-08]], dtype=float32),\n",
              " matrix([[ 8.3164014e-07,  6.4632906e-07, -5.8757184e-08,  1.3559351e-07,\n",
              "          -6.2500128e-08]], dtype=float32),\n",
              " matrix([[-1.1219698e-07, -6.1107286e-08,  2.0235527e-07, -6.2109045e-08,\n",
              "          -8.0140701e-08]], dtype=float32),\n",
              " matrix([[-2.5902264e-07, -1.2362445e-07,  4.4151587e-08, -2.1339934e-08,\n",
              "          -3.6792990e-08]], dtype=float32),\n",
              " matrix([[-1.1080263e-06, -6.3945794e-07, -8.9579238e-08, -4.1929974e-07,\n",
              "          -2.2050273e-08]], dtype=float32),\n",
              " matrix([[ 7.4797987e-07, -1.0284723e-07,  4.2073868e-08,  1.2768250e-07,\n",
              "          -4.7917460e-08]], dtype=float32),\n",
              " matrix([[1.0103793e-06, 2.5259482e-07, 1.3660740e-07, 1.8783518e-07,\n",
              "          8.6990561e-08]], dtype=float32),\n",
              " matrix([[ 4.9793613e-07,  3.4602343e-07,  4.3041939e-07, -1.0444000e-07,\n",
              "          -2.6901212e-08]], dtype=float32),\n",
              " matrix([[-1.3987223e-07, -1.7007191e-07, -3.1789146e-08, -3.6358834e-08,\n",
              "           6.0399373e-08]], dtype=float32),\n",
              " matrix([[ 2.6053988e-07,  7.3737702e-08, -2.9495082e-08,  3.1953004e-08,\n",
              "          -1.7973566e-08]], dtype=float32),\n",
              " matrix([[-5.7757740e-07, -8.2271200e-08, -1.0929267e-07, -5.0370122e-08,\n",
              "          -1.7965344e-07]], dtype=float32),\n",
              " matrix([[-2.47518528e-07, -5.82396531e-08,  2.41148570e-07,\n",
              "           4.00397617e-08, -1.08289356e-07]], dtype=float32),\n",
              " matrix([[-3.5321271e-08, -1.3245477e-07, -7.7265279e-09,  1.6073939e-08,\n",
              "          -1.1976118e-07]], dtype=float32),\n",
              " matrix([[8.7193081e-07, 4.3596540e-07, 2.0499741e-07, 1.5241760e-07,\n",
              "          4.3851987e-08]], dtype=float32),\n",
              " matrix([[ 3.63304508e-07,  1.01044066e-07,  1.13532659e-08,\n",
              "           1.36239189e-08, -1.36239189e-08]], dtype=float32),\n",
              " matrix([[-3.1590463e-07, -9.5367433e-08,  1.8775464e-07, -2.3618341e-07,\n",
              "           1.2516975e-07]], dtype=float32),\n",
              " matrix([[-2.4523055e-07,  4.0871758e-08,  1.0217939e-08, -1.5433345e-08,\n",
              "           1.8307141e-07]], dtype=float32),\n",
              " matrix([[ 4.80591780e-07,  2.52498410e-07, -1.31411815e-08,\n",
              "          -2.62823630e-08,  5.96046448e-08]], dtype=float32),\n",
              " matrix([[-1.24561541e-06,  1.61784030e-07,  1.17688764e-07,\n",
              "          -2.95590382e-07, -2.32944686e-07]], dtype=float32),\n",
              " matrix([[-1.0561351e-06, -2.7585621e-08, -2.4432978e-07, -7.6845659e-08,\n",
              "          -2.6616175e-07]], dtype=float32),\n",
              " matrix([[ 4.9221899e-07, -2.9738231e-07,  1.4869116e-07, -1.3659398e-08,\n",
              "           3.8835150e-08]], dtype=float32),\n",
              " matrix([[ 3.4570695e-07,  4.9173831e-08,  2.9802322e-07, -9.3877318e-08,\n",
              "           6.1467289e-09]], dtype=float32),\n",
              " matrix([[-2.9550472e-07,  8.0592194e-08, -4.1975103e-08, -9.7382234e-08,\n",
              "           1.5593750e-07]], dtype=float32),\n",
              " matrix([[-2.1430884e-08,  1.5537391e-07, -3.9848050e-08, -1.9229195e-07,\n",
              "          -9.5936691e-08]], dtype=float32),\n",
              " matrix([[ 3.1268009e-08, -7.8170025e-08, -2.1985320e-08,  2.7359508e-08,\n",
              "           1.4950018e-07]], dtype=float32),\n",
              " matrix([[ 1.4901161e-07,  1.2665987e-07,  2.0395964e-07,  2.3283064e-08,\n",
              "          -6.1467290e-08]], dtype=float32),\n",
              " matrix([[ 7.0445628e-07, -2.8410855e-07,  1.5534590e-07,  1.0176403e-07,\n",
              "           2.0986235e-07]], dtype=float32),\n",
              " matrix([[-1.5283243e-07, -8.2529510e-08,  7.9472862e-08, -1.0469021e-07,\n",
              "          -1.5283243e-08]], dtype=float32),\n",
              " matrix([[-9.3944038e-07,  5.7825403e-08,  1.5079085e-07, -2.0806024e-07,\n",
              "          -1.2187816e-07]], dtype=float32),\n",
              " matrix([[-1.8517948e-06,  1.6203204e-07,  5.4396475e-07, -3.8728552e-07,\n",
              "          -3.1075430e-07]], dtype=float32),\n",
              " matrix([[1.1309058e-06, 3.6975979e-07, 2.1098990e-07, 2.6795718e-07,\n",
              "          4.2197978e-09]], dtype=float32),\n",
              " matrix([[ 2.8049246e-07, -3.0854170e-07, -1.2885121e-07, -7.1876187e-08,\n",
              "          -1.1219698e-07]], dtype=float32),\n",
              " matrix([[-3.4355969e-07, -2.1620566e-07,  1.1846886e-08,  8.4409059e-08,\n",
              "          -3.8872594e-09]], dtype=float32),\n",
              " matrix([[-2.19634089e-07, -2.36973619e-07,  1.10900764e-07,\n",
              "          -8.66976677e-08, -6.03271246e-08]], dtype=float32),\n",
              " matrix([[ 3.3775964e-07, -4.9670539e-09, -2.9802322e-08, -1.3411045e-07,\n",
              "          -3.1044085e-08]], dtype=float32),\n",
              " matrix([[ 1.5894572e-07,  4.7683716e-07,  1.4106432e-07, -6.0598055e-08,\n",
              "           2.6822089e-08]], dtype=float32),\n",
              " matrix([[-1.9073487e-07, -7.1525577e-08, -2.3841858e-08, -3.4059797e-09,\n",
              "          -6.8971090e-08]], dtype=float32),\n",
              " matrix([[-4.5654622e-07, -2.3334584e-07,  1.1920929e-07, -6.6024825e-08,\n",
              "           1.3950023e-08]], dtype=float32),\n",
              " matrix([[ 1.2588501e-06, -5.3942202e-08,  2.6240946e-07,  2.8371812e-07,\n",
              "          -2.6226044e-08]], dtype=float32),\n",
              " matrix([[3.3395816e-07, 3.4428675e-07, 7.5743088e-08, 4.2691559e-07,\n",
              "          9.3387783e-08]], dtype=float32),\n",
              " matrix([[-6.1527373e-08,  3.6531878e-07, -4.0377341e-08, -1.7208438e-07,\n",
              "           3.5570515e-08]], dtype=float32),\n",
              " matrix([[ 1.2341668e-07, -1.1219698e-08, -6.7318190e-08, -1.6829548e-08,\n",
              "          -1.9283856e-07]], dtype=float32),\n",
              " matrix([[-6.4437455e-07, -1.3531866e-07, -2.3761311e-07,  8.6185096e-08,\n",
              "          -1.3209679e-07]], dtype=float32),\n",
              " matrix([[-1.5874062e-06,  9.9981982e-08, -2.6610590e-07, -1.8294780e-07,\n",
              "          -6.2296465e-08]], dtype=float32),\n",
              " matrix([[-2.1107992e-06,  2.8186375e-07,  8.9009603e-08,  7.0412955e-07,\n",
              "           3.3809080e-08]], dtype=float32),\n",
              " matrix([[-1.6282245e-07,  1.2502437e-07,  3.0529208e-08, -7.0144488e-08,\n",
              "          -7.7776789e-08]], dtype=float32),\n",
              " matrix([[-1.6163972e-07, -1.3739376e-07,  2.8286950e-08, -6.3645636e-08,\n",
              "           7.6021180e-08]], dtype=float32),\n",
              " matrix([[-4.4803491e-07,  2.3201808e-08,  6.4004988e-09,  4.8803802e-08,\n",
              "          -1.3441047e-07]], dtype=float32),\n",
              " matrix([[-4.9569513e-07, -1.6163972e-07, -1.5355774e-07, -1.4951674e-07,\n",
              "          -5.7247398e-09]], dtype=float32),\n",
              " matrix([[-4.4627066e-07, -1.1768096e-07,  1.1768096e-07, -1.3754918e-07,\n",
              "          -1.1691680e-07]], dtype=float32),\n",
              " matrix([[ 1.8232009e-07, -7.7135425e-08,  4.3826944e-08, -3.5061557e-08,\n",
              "           1.9174289e-10]], dtype=float32),\n",
              " matrix([[ 1.5053095e-06, -1.6829547e-07,  5.0488643e-07,  1.0518467e-07,\n",
              "           3.3483786e-07]], dtype=float32),\n",
              " matrix([[ 5.5019672e-08,  1.4213416e-07, -1.9142261e-07, -2.1090874e-07,\n",
              "          -1.5818156e-07]], dtype=float32),\n",
              " matrix([[-5.5770425e-07, -3.3462257e-08,  1.2408920e-07,  1.1851216e-08,\n",
              "           2.1262476e-08]], dtype=float32),\n",
              " matrix([[-3.8146973e-07,  2.7857328e-07, -2.4312422e-07, -5.3016763e-08,\n",
              "           7.5917498e-08]], dtype=float32),\n",
              " matrix([[-5.9838391e-07, -8.4147736e-08, -2.8049245e-08, -6.9830932e-08,\n",
              "          -1.0942127e-07]], dtype=float32),\n",
              " matrix([[ 1.0360906e-06,  2.7668329e-07, -8.0944581e-08,  3.6792991e-09,\n",
              "           3.0685354e-07]], dtype=float32),\n",
              " matrix([[ 3.1370865e-07,  4.0782126e-08,  1.2548346e-08, -8.1564252e-08,\n",
              "          -7.6858619e-08]], dtype=float32),\n",
              " matrix([[ 3.3801115e-07, -4.5269348e-09, -1.1468236e-07, -3.4329258e-08,\n",
              "           9.7706348e-08]], dtype=float32),\n",
              " matrix([[-1.2362445e-07,  6.1812223e-08, -1.5011540e-07,  3.5321271e-08,\n",
              "           5.7397067e-08]], dtype=float32),\n",
              " matrix([[ 2.2649765e-07, -1.2144446e-07, -1.1920929e-08,  1.9371509e-08,\n",
              "          -6.8545340e-08]], dtype=float32),\n",
              " matrix([[-2.1192763e-07, -3.8853398e-07, -1.6336088e-07, -5.8765306e-08,\n",
              "           5.1510187e-09]], dtype=float32),\n",
              " matrix([[-6.3148707e-07, -2.4486232e-07,  9.6656180e-08, -1.5679781e-07,\n",
              "          -2.7922896e-08]], dtype=float32),\n",
              " matrix([[ 1.93967651e-07, -1.16809948e-08,  3.05094972e-07,\n",
              "           9.39530835e-08,  1.17693915e-07]], dtype=float32),\n",
              " matrix([[-1.2818203e-06, -3.0250959e-07, -7.0500117e-09,  1.9227305e-07,\n",
              "           1.5510025e-07]], dtype=float32),\n",
              " matrix([[-4.3679739e-07,  8.0079523e-08,  3.6399783e-08, -2.0201880e-07,\n",
              "           3.4124795e-08]], dtype=float32),\n",
              " matrix([[ 1.7660635e-07, -4.7095028e-08, -7.8001143e-08,  7.0642542e-08,\n",
              "           2.0751247e-07]], dtype=float32),\n",
              " matrix([[3.1789145e-07, 1.5610740e-07, 2.4125690e-08, 3.4059798e-07,\n",
              "          1.1353266e-07]], dtype=float32),\n",
              " matrix([[ 1.1336128e-06,  5.7580337e-07,  1.5744624e-07,  2.4629088e-07,\n",
              "          -1.8781085e-07]], dtype=float32),\n",
              " matrix([[-7.3958415e-07, -1.3928025e-07,  1.2002023e-07,  8.9204226e-09,\n",
              "          -1.0876834e-07]], dtype=float32),\n",
              " matrix([[-3.6784581e-07, -2.5885447e-07, -4.0871758e-08, -2.1287373e-07,\n",
              "          -3.6614281e-08]], dtype=float32),\n",
              " matrix([[-9.7440636e-07,  1.3475832e-07, -2.0732051e-08, -3.1292439e-07,\n",
              "          -1.0106874e-07]], dtype=float32),\n",
              " matrix([[-7.9111618e-07,  1.9168311e-07, -1.5984882e-07, -9.8974191e-08,\n",
              "          -2.2351742e-07]], dtype=float32),\n",
              " matrix([[5.0727357e-07, 3.3289829e-09, 1.7754575e-08, 7.2920578e-08,\n",
              "          2.5458792e-07]], dtype=float32),\n",
              " matrix([[-2.7743252e-07,  2.8176741e-08, -3.3866275e-08,  1.7339532e-08,\n",
              "           2.6009300e-08]], dtype=float32),\n",
              " matrix([[-4.5413064e-08,  4.3993904e-08, -1.7739478e-07, -5.3218432e-08,\n",
              "          -8.5149496e-09]], dtype=float32),\n",
              " matrix([[ 4.5473212e-07,  1.3578807e-07, -1.4526165e-07,  8.4078074e-08,\n",
              "           1.8157706e-08]], dtype=float32),\n",
              " matrix([[-6.7551929e-07, -2.0662944e-07,  1.8477439e-07, -3.9736432e-09,\n",
              "          -1.0033448e-07]], dtype=float32),\n",
              " matrix([[ 2.7148394e-07,  3.2717293e-07,  1.0175209e-07, -7.2874293e-09,\n",
              "           1.6793717e-07]], dtype=float32),\n",
              " matrix([[ 2.8049246e-07,  3.5061557e-08, -8.2394656e-08, -1.6654239e-07,\n",
              "           6.3110804e-08]], dtype=float32),\n",
              " matrix([[ 5.8342431e-07, -4.7122731e-07,  1.6081567e-07,  3.1321658e-08,\n",
              "           1.4492110e-07]], dtype=float32),\n",
              " matrix([[ 6.2482110e-07, -1.7675860e-07, -2.6102722e-07,  1.5894572e-07,\n",
              "           9.2489969e-08]], dtype=float32),\n",
              " matrix([[-2.4453189e-07, -2.3841858e-07, -1.9562550e-07,  1.0851102e-07,\n",
              "          -9.5138184e-08]], dtype=float32),\n",
              " matrix([[-7.5963669e-07, -3.2305201e-07, -9.7018813e-08, -1.4088370e-07,\n",
              "           1.9661792e-07]], dtype=float32),\n",
              " matrix([[ 1.4561479e-06,  5.1272814e-08,  1.6279118e-07,  2.5636407e-08,\n",
              "          -2.2816401e-07]], dtype=float32),\n",
              " matrix([[-1.5119227e-07, -1.0757911e-07, -3.1871107e-07, -1.7445261e-08,\n",
              "          -1.4246964e-07]], dtype=float32),\n",
              " matrix([[-1.5435191e-07, -7.7175955e-08,  3.3075409e-08,  2.0672131e-07,\n",
              "          -1.7088962e-07]], dtype=float32),\n",
              " matrix([[-4.6748741e-07, -8.4147736e-08, -5.0254897e-08, -6.6616956e-08,\n",
              "           7.2168369e-08]], dtype=float32),\n",
              " matrix([[ 9.3078614e-07,  2.5939943e-07, -2.2315979e-07,  2.4437904e-07,\n",
              "           3.3473970e-07]], dtype=float32),\n",
              " matrix([[ 3.5321270e-07, -1.4901161e-07,  5.9604645e-08, -7.1263422e-08,\n",
              "          -3.5376459e-07]], dtype=float32),\n",
              " matrix([[-4.6811454e-07, -3.6053541e-07, -1.3083947e-07, -1.4537719e-08,\n",
              "          -8.1411223e-08]], dtype=float32),\n",
              " matrix([[ 1.1951627e-06,  5.6893015e-07,  1.2279068e-07, -1.6218603e-07,\n",
              "           6.6511618e-08]], dtype=float32),\n",
              " matrix([[ 7.2660902e-07,  2.5828680e-07,  3.7607691e-08, -1.9158636e-08,\n",
              "          -8.5149496e-09]], dtype=float32),\n",
              " matrix([[ 1.3746657e-07,  4.0219712e-07, -8.5916604e-08,  8.1083797e-08,\n",
              "           9.1554881e-08]], dtype=float32),\n",
              " matrix([[-2.3231687e-06,  1.2743671e-07,  3.0734529e-07, -1.0192111e-06,\n",
              "          -6.7796755e-08]], dtype=float32),\n",
              " matrix([[6.0232060e-07, 5.0695320e-07, 5.0193385e-08, 2.4092824e-07,\n",
              "          2.3214440e-08]], dtype=float32),\n",
              " matrix([[-1.2327985e-06, -8.5772541e-08, -1.8680969e-07, -1.8790001e-07,\n",
              "           2.1897438e-07]], dtype=float32),\n",
              " matrix([[-2.6247918e-08, -4.8121180e-08,  1.2249028e-07, -2.0615552e-07,\n",
              "           2.6247918e-08]], dtype=float32),\n",
              " matrix([[-3.2056280e-07,  5.6975029e-08,  6.6116080e-08,  3.0052764e-08,\n",
              "          -1.5226733e-07]], dtype=float32),\n",
              " matrix([[ 1.3070362e-06, -6.0371923e-07, -6.8823812e-07,  1.1281038e-07,\n",
              "          -1.1363987e-07]], dtype=float32),\n",
              " matrix([[ 3.79571873e-07,  1.28105512e-07,  3.49917819e-08,\n",
              "           4.74464841e-08, -1.05568425e-07]], dtype=float32),\n",
              " matrix([[-2.8861197e-07, -1.7920607e-07, -1.5528579e-07,  6.4285764e-08,\n",
              "          -8.5877744e-08]], dtype=float32),\n",
              " matrix([[-1.8384083e-07, -4.5960209e-07, -1.5619289e-08, -1.3563647e-07,\n",
              "           6.7324521e-08]], dtype=float32),\n",
              " matrix([[-1.2170701e-06, -3.4059799e-08, -3.6898115e-07,  2.2649765e-07,\n",
              "           8.1743515e-08]], dtype=float32),\n",
              " matrix([[-3.5422190e-07, -5.3133283e-07, -9.8773413e-08, -2.0095280e-07,\n",
              "          -1.3283321e-07]], dtype=float32),\n",
              " matrix([[-1.12196979e-07, -1.18430144e-07,  1.18430144e-07,\n",
              "           6.23316581e-08, -5.60984894e-08]], dtype=float32),\n",
              " matrix([[8.0532499e-07, 6.7110413e-08, 1.2980567e-07, 1.6777604e-07,\n",
              "          1.5651739e-07]], dtype=float32),\n",
              " matrix([[-1.9868214e-07,  3.9736431e-08, -9.9341072e-08, -6.7676105e-08,\n",
              "          -1.4901161e-08]], dtype=float32),\n",
              " matrix([[ 1.5307384e-06, -5.4061792e-07,  1.1845000e-07,  1.5375720e-07,\n",
              "           1.5489614e-07]], dtype=float32),\n",
              " matrix([[ 9.5763153e-07,  2.0493734e-07,  3.9571550e-09, -4.5754605e-09,\n",
              "           1.7807197e-07]], dtype=float32),\n",
              " matrix([[ 1.3494167e-06,  4.3791168e-08,  1.7070445e-07, -1.5408004e-08,\n",
              "           1.7526604e-07]], dtype=float32),\n",
              " matrix([[-7.15255737e-07, -1.09275184e-07, -1.22934580e-07,\n",
              "          -2.53319740e-07, -2.95462087e-07]], dtype=float32),\n",
              " matrix([[ 2.0807440e-07,  8.6697662e-09, -2.2107905e-07, -1.4088370e-07,\n",
              "           2.0157208e-07]], dtype=float32),\n",
              " matrix([[ 1.9836426e-07, -6.8664548e-08,  2.5177002e-07, -4.8160555e-08,\n",
              "          -7.1763992e-08]], dtype=float32),\n",
              " matrix([[ 3.5110398e-07, -7.1169723e-08,  2.6451414e-07,  1.0675459e-08,\n",
              "           1.7792431e-07]], dtype=float32),\n",
              " matrix([[-6.0187443e-07, -3.0517577e-07, -1.4570024e-07, -2.0133124e-08,\n",
              "          -2.6649900e-07]], dtype=float32),\n",
              " matrix([[-2.3355290e-07,  7.7850963e-08, -3.7709061e-08, -1.4353772e-07,\n",
              "           2.5164717e-08]], dtype=float32),\n",
              " matrix([[3.6413019e-07, 8.6697668e-08, 1.0010871e-07, 1.1487440e-07,\n",
              "          6.2720339e-08]], dtype=float32),\n",
              " matrix([[ 7.9472858e-07,  3.9736431e-08,  1.3464263e-07, -2.2706532e-08,\n",
              "          -8.6568647e-08]], dtype=float32),\n",
              " matrix([[ 1.6829547e-07,  1.4024623e-07, -5.9604645e-08, -7.7135425e-08,\n",
              "           1.3148083e-07]], dtype=float32),\n",
              " matrix([[3.9268943e-07, 1.6362060e-07, 1.4258366e-07, 3.7398993e-07,\n",
              "          5.6098489e-08]], dtype=float32),\n",
              " matrix([[-4.5413064e-08,  1.8922110e-07, -5.2981907e-08,  9.8394970e-08,\n",
              "           8.9880018e-08]], dtype=float32),\n",
              " matrix([[9.0715361e-07, 1.9189788e-07, 2.9802322e-07, 3.4890522e-08,\n",
              "          4.3613156e-08]], dtype=float32),\n",
              " matrix([[-8.4548435e-07, -1.6028140e-07, -2.5444672e-07,  1.2722336e-07,\n",
              "           1.2722336e-07]], dtype=float32),\n",
              " matrix([[ 3.6979208e-07, -8.0283804e-08,  1.5570193e-07, -1.3745561e-07,\n",
              "           2.7977691e-08]], dtype=float32),\n",
              " matrix([[-1.0706896e-06, -3.0423965e-07,  1.9819458e-07,  1.0238835e-07,\n",
              "           2.0111997e-07]], dtype=float32),\n",
              " matrix([[-1.2488593e-07,  1.6867709e-07, -5.5144433e-08,  1.0136844e-07,\n",
              "          -1.2650781e-07]], dtype=float32),\n",
              " matrix([[-4.3166312e-07, -2.6100560e-07, -3.0116030e-07, -2.1583156e-07,\n",
              "           2.1285132e-07]], dtype=float32),\n",
              " matrix([[ 6.2584877e-07,  7.9472862e-08, -1.3907750e-07,  1.5646219e-07,\n",
              "           1.3286869e-07]], dtype=float32),\n",
              " matrix([[ 1.3623919e-07,  1.9981748e-07,  1.4418647e-07, -4.2574747e-08,\n",
              "           1.2375060e-07]], dtype=float32),\n",
              " matrix([[ 6.1101213e-07,  3.0550606e-07,  7.7731164e-09, -2.8899223e-08,\n",
              "           1.6307418e-07]], dtype=float32),\n",
              " matrix([[1.58309933e-06, 2.61068351e-07, 3.21865095e-08, 5.00679000e-08,\n",
              "          1.14813446e-07]], dtype=float32),\n",
              " matrix([[ 7.3304818e-07,  2.6332799e-07,  6.4764453e-07, -2.4731480e-07,\n",
              "          -5.6046158e-08]], dtype=float32),\n",
              " matrix([[ 5.9193576e-07,  6.2482108e-08, -5.3438647e-08,  6.4331907e-08,\n",
              "           2.8851732e-08]], dtype=float32),\n",
              " matrix([[-2.88320138e-07, -2.43963200e-07,  1.30645063e-07,\n",
              "          -4.99015620e-08,  1.10892366e-07]], dtype=float32),\n",
              " matrix([[-1.9239824e-06, -6.3208648e-07, -6.4594803e-07, -1.4171265e-07,\n",
              "           7.9703888e-09]], dtype=float32),\n",
              " matrix([[-3.42007354e-07,  1.64426606e-09,  1.47983945e-08,\n",
              "           1.31541285e-07, -1.09343695e-07]], dtype=float32),\n",
              " matrix([[-2.4610949e-07, -1.3330931e-07, -1.0735245e-07,  3.7172789e-08,\n",
              "           4.2300069e-08]], dtype=float32),\n",
              " matrix([[6.2027596e-07, 3.4115178e-07, 5.8150874e-08, 6.4935143e-08,\n",
              "          6.2027596e-08]], dtype=float32),\n",
              " matrix([[ 3.0275377e-08, -1.4759246e-07, -5.0143591e-08, -8.7041705e-08,\n",
              "          -3.8790326e-08]], dtype=float32),\n",
              " matrix([[ 5.20186006e-07,  3.65755767e-07, -1.92360446e-07,\n",
              "           2.03874976e-07, -1.08372085e-08]], dtype=float32),\n",
              " matrix([[ 1.02223919e-06,  1.00534145e-07, -1.38687938e-07,\n",
              "           3.03866813e-07,  1.34792202e-07]], dtype=float32),\n",
              " matrix([[ 3.0517577e-07, -7.4931556e-08, -9.6048630e-08,  8.1743515e-08,\n",
              "          -7.7826634e-08]], dtype=float32),\n",
              " matrix([[2.0345053e-07, 3.8146972e-08, 5.5631002e-08, 8.2651773e-08,\n",
              "          3.2027563e-07]], dtype=float32),\n",
              " matrix([[6.1223534e-07, 8.8303175e-08, 1.7660636e-08, 3.5321271e-08,\n",
              "          8.3888018e-08]], dtype=float32),\n",
              " matrix([[-4.9565966e-07,  4.8101995e-08, -5.9754030e-10,  2.8846259e-07,\n",
              "          -1.3444656e-09]], dtype=float32),\n",
              " matrix([[-1.6702771e-07, -3.3405541e-07,  3.2327943e-08,  6.0614894e-08,\n",
              "          -2.1636149e-08]], dtype=float32),\n",
              " matrix([[-7.4286208e-07,  5.0193385e-08, -7.4035242e-08, -1.9073487e-07,\n",
              "           1.3301248e-07]], dtype=float32),\n",
              " matrix([[-4.1804901e-07, -1.2410830e-07, -9.3081226e-08,  8.2466698e-08,\n",
              "          -3.3476582e-08]], dtype=float32),\n",
              " matrix([[-1.2962563e-07,  2.0369743e-07, -1.5393044e-07, -5.3239098e-08,\n",
              "          -1.3309775e-08]], dtype=float32),\n",
              " matrix([[ 4.94830999e-07,  4.13858658e-07, -1.34953915e-08,\n",
              "          -1.94558552e-07,  4.61092533e-08]], dtype=float32),\n",
              " matrix([[3.5762787e-07, 1.0679165e-07, 9.3132257e-08, 2.9802322e-08,\n",
              "          6.3329935e-08]], dtype=float32),\n",
              " matrix([[ 7.4174670e-07,  4.9449778e-07, -1.5894572e-07,  8.8303175e-08,\n",
              "          -7.2850121e-08]], dtype=float32),\n",
              " matrix([[ 2.7550593e-07,  2.2517310e-07, -4.2385526e-08,  1.7649597e-07,\n",
              "           5.2981908e-09]], dtype=float32),\n",
              " matrix([[-2.4286115e-07, -3.8206207e-07, -2.3397600e-07, -2.5174631e-07,\n",
              "           5.4791848e-08]], dtype=float32),\n",
              " matrix([[-2.3841858e-08,  8.3446501e-08,  1.3113022e-07,  1.1920929e-07,\n",
              "           8.9779498e-08]], dtype=float32),\n",
              " matrix([[ 2.6822090e-07,  3.1664968e-08, -1.0244548e-07,  2.1560118e-07,\n",
              "           2.0489097e-08]], dtype=float32),\n",
              " matrix([[ 9.6360839e-07, -1.3659398e-08, -2.4276474e-07,  1.7912437e-07,\n",
              "           4.3399632e-07]], dtype=float32),\n",
              " matrix([[-8.8031477e-08, -7.3359566e-08,  7.8861532e-08,  4.9517705e-08,\n",
              "          -1.3388120e-07]], dtype=float32),\n",
              " matrix([[3.67122425e-07, 2.49759296e-07, 3.12265030e-07, 1.47692925e-08,\n",
              "          1.18154340e-07]], dtype=float32),\n",
              " matrix([[ 4.2537991e-07, -6.8609665e-09,  6.8609666e-08,  1.7409702e-07,\n",
              "          -5.0170815e-08]], dtype=float32),\n",
              " matrix([[-5.3268298e-07, -1.4605823e-07, -1.1598742e-07, -7.5714006e-08,\n",
              "           2.5238003e-07]], dtype=float32),\n",
              " matrix([[ 2.2888183e-07,  9.5367433e-08,  4.7683717e-08, -1.1324882e-08,\n",
              "           1.3828277e-07]], dtype=float32),\n",
              " matrix([[-3.4438239e-07, -2.7815500e-07,  4.8014854e-08, -2.8808913e-07,\n",
              "          -1.4901161e-07]], dtype=float32),\n",
              " matrix([[ 3.9462387e-07,  2.5486125e-07,  2.8774656e-07,  2.1169926e-07,\n",
              "          -6.1659975e-08]], dtype=float32),\n",
              " matrix([[1.6920028e-07, 3.8454608e-08, 2.7687318e-07, 2.6918227e-07,\n",
              "          1.9227304e-08]], dtype=float32),\n",
              " matrix([[-6.4304896e-07,  8.1743515e-08, -2.2888183e-07, -2.6055744e-07,\n",
              "          -2.6566642e-08]], dtype=float32),\n",
              " matrix([[-6.0183328e-07,  4.0276538e-07, -1.2036666e-06, -2.4304808e-07,\n",
              "          -1.0416346e-08]], dtype=float32),\n",
              " matrix([[1.4695155e-07, 1.9337175e-07, 6.3669847e-07, 1.8458212e-07,\n",
              "          1.6260806e-07]], dtype=float32),\n",
              " matrix([[-1.9073487e-07, -2.9802322e-07,  7.4505806e-09,  5.9604645e-08,\n",
              "          -8.3446501e-08]], dtype=float32),\n",
              " matrix([[-1.2030662e-06, -8.0204410e-07, -6.6712310e-08, -3.6311448e-07,\n",
              "           7.4817548e-09]], dtype=float32),\n",
              " matrix([[-1.7339534e-07, -1.0003577e-08, -6.6690511e-09,  1.0337029e-07,\n",
              "          -7.0650259e-08]], dtype=float32),\n",
              " matrix([[-3.9268944e-08, -1.2902653e-07,  7.8537887e-08, -4.4037313e-07,\n",
              "          -1.3884376e-07]], dtype=float32),\n",
              " matrix([[ 9.9374472e-07, -3.3659094e-07,  3.8467536e-07,  2.8049245e-08,\n",
              "           1.1820753e-07]], dtype=float32),\n",
              " matrix([[ 5.4868934e-07,  8.4916209e-08, -4.8990120e-08, -1.3676409e-07,\n",
              "          -4.8990120e-08]], dtype=float32),\n",
              " matrix([[-7.0642542e-08, -1.9426698e-08, -5.0332812e-08,  5.1215842e-08,\n",
              "           8.6537113e-08]], dtype=float32),\n",
              " matrix([[ 3.5762787e-07,  8.8179313e-08,  3.1563368e-07, -1.3072382e-07,\n",
              "           5.0122086e-08]], dtype=float32),\n",
              " matrix([[ 1.7937193e-06, -4.8901171e-07,  4.1799342e-07, -2.8133076e-07,\n",
              "          -2.1051854e-07]], dtype=float32),\n",
              " matrix([[ 1.46719131e-07, -1.10039345e-07, -5.73121568e-08,\n",
              "          -4.87153358e-08, -7.10670776e-08]], dtype=float32),\n",
              " matrix([[-6.2453006e-07, -3.4813333e-08, -1.6879191e-07, -1.6417651e-08,\n",
              "          -1.2237413e-07]], dtype=float32),\n",
              " matrix([[ 3.8146973e-07, -5.0012023e-08,  2.7045607e-07, -1.8626451e-07,\n",
              "           8.2701447e-08]], dtype=float32),\n",
              " matrix([[-1.3779325e-07, -7.6148901e-08, -8.8613753e-08, -5.4392071e-08,\n",
              "          -1.6136315e-07]], dtype=float32),\n",
              " matrix([[-2.9024869e-07,  5.1830127e-09, -1.7411683e-07,  2.5267186e-08,\n",
              "           2.9154446e-08]], dtype=float32),\n",
              " matrix([[ 2.1855037e-07, -5.4637592e-08, -2.2103389e-07, -1.7260511e-07,\n",
              "          -7.7299774e-08]], dtype=float32),\n",
              " matrix([[ 6.0110381e-07, -2.3119378e-07,  1.9362479e-07,  1.2887247e-07,\n",
              "          -1.2896278e-07]], dtype=float32),\n",
              " matrix([[-3.4829844e-07,  7.6708588e-08, -3.1098075e-08, -8.5519709e-08,\n",
              "          -4.5092211e-08]], dtype=float32),\n",
              " matrix([[-1.2690022e-07, -4.3069161e-07,  4.5184166e-08, -1.5574116e-07,\n",
              "          -2.0465062e-07]], dtype=float32),\n",
              " matrix([[-2.9550472e-07,  1.3432032e-08,  1.3767833e-07,  3.7497756e-08,\n",
              "           4.5752863e-08]], dtype=float32),\n",
              " matrix([[ 8.2556880e-07,  2.5087328e-07, -3.5584862e-09,  2.2418463e-07,\n",
              "          -6.5720791e-08]], dtype=float32),\n",
              " matrix([[ 5.6259921e-07, -1.7152416e-08,  3.2589590e-08,  1.5522936e-07,\n",
              "           1.9124944e-07]], dtype=float32),\n",
              " matrix([[-3.2356806e-07, -3.4059799e-08, -1.4475414e-07,  2.2990363e-07,\n",
              "          -6.7853499e-08]], dtype=float32),\n",
              " matrix([[ 1.6086072e-07,  4.0215181e-08,  1.8384083e-07, -2.0107591e-07,\n",
              "           1.5798821e-07]], dtype=float32),\n",
              " matrix([[-1.10039345e-07,  3.43872948e-08, -1.73369273e-07,\n",
              "          -1.77094563e-07, -2.04890966e-08]], dtype=float32),\n",
              " matrix([[ 5.8687652e-07,  1.8034225e-07,  8.7114479e-08,  1.8645555e-07,\n",
              "          -4.1264755e-08]], dtype=float32),\n",
              " matrix([[ 6.5468453e-07, -1.2951928e-07, -1.5980488e-07, -3.7373724e-08,\n",
              "           2.0619986e-07]], dtype=float32),\n",
              " matrix([[ 4.7683716e-07, -1.5142801e-07, -3.4635132e-08,  5.6382774e-09,\n",
              "           4.8328088e-09]], dtype=float32),\n",
              " matrix([[ 1.1280018e-06,  1.9547759e-08,  2.5892771e-07, -2.8840956e-08,\n",
              "           6.2809193e-08]], dtype=float32),\n",
              " matrix([[ 1.4356388e-07,  9.5816070e-08,  2.2303674e-07,  2.6277316e-08,\n",
              "          -6.2488738e-08]], dtype=float32),\n",
              " matrix([[-6.4420385e-07, -2.5262895e-07, -1.9736638e-07, -1.1368303e-07,\n",
              "          -5.3683653e-08]], dtype=float32),\n",
              " matrix([[-1.31193289e-07, -4.54130635e-08,  1.00917916e-07,\n",
              "           1.55161302e-07, -4.09979037e-08]], dtype=float32),\n",
              " matrix([[ 1.6530355e-07, -1.2715658e-07,  1.0172526e-07, -3.6875406e-07,\n",
              "           2.7020772e-07]], dtype=float32),\n",
              " matrix([[ 1.6668201e-07,  4.8949653e-07,  7.3424485e-07, -3.1648483e-08,\n",
              "           2.3630868e-07]], dtype=float32),\n",
              " matrix([[ 1.5258789e-07,  1.6348702e-08,  6.2670026e-08,  3.5762786e-09,\n",
              "          -1.6280583e-07]], dtype=float32),\n",
              " matrix([[-6.1360441e-07, -2.8647193e-07,  2.0145445e-07,  1.8666881e-07,\n",
              "          -1.8482060e-08]], dtype=float32),\n",
              " matrix([[ 4.8287308e-08,  2.1729288e-07,  5.2814244e-08,  8.0730345e-08,\n",
              "          -1.9993964e-08]], dtype=float32),\n",
              " matrix([[ 1.8042488e-07,  7.0881200e-08, -7.6519477e-08,  1.2001476e-07,\n",
              "           2.2553110e-08]], dtype=float32),\n",
              " matrix([[ 9.9144359e-07,  2.9743308e-07, -1.4753625e-09,  7.1407541e-08,\n",
              "           3.9716758e-07]], dtype=float32),\n",
              " matrix([[5.0488643e-07, 1.4784290e-07, 2.0803189e-07, 1.5543957e-07,\n",
              "          3.0737297e-07]], dtype=float32),\n",
              " matrix([[ 1.1245639e-06, -2.0051968e-07, -1.5573005e-07, -4.2033335e-08,\n",
              "           5.4884509e-07]], dtype=float32),\n",
              " matrix([[-3.5095215e-07, -1.1086464e-07, -1.2874604e-08, -3.0803682e-07,\n",
              "          -2.7656554e-08]], dtype=float32),\n",
              " matrix([[ 2.9617215e-07,  2.9617215e-08,  2.2398018e-07, -3.7698317e-08,\n",
              "          -2.8136354e-08]], dtype=float32),\n",
              " matrix([[-9.3199992e-07, -4.4703484e-08, -3.0276451e-07,  7.5521797e-08,\n",
              "           1.0498545e-07]], dtype=float32),\n",
              " matrix([[-2.1798270e-07,  1.0081700e-07, -1.9073487e-07,  8.5830692e-08,\n",
              "           1.0626657e-07]], dtype=float32),\n",
              " matrix([[ 1.0056929e-06, -7.3259525e-07,  6.8057665e-07,  7.2500922e-07,\n",
              "           4.1181391e-08]], dtype=float32),\n",
              " matrix([[-4.9046110e-07,  2.3783318e-07,  3.4059797e-09,  2.3841858e-08,\n",
              "          -2.5438410e-08]], dtype=float32),\n",
              " matrix([[ 3.2424927e-07,  2.0027160e-07,  4.3869019e-07, -2.2560359e-07,\n",
              "          -7.1525577e-08]], dtype=float32),\n",
              " matrix([[ 6.4292649e-08,  7.5008096e-08,  1.9555681e-07,  9.1081255e-08,\n",
              "          -1.3461273e-07]], dtype=float32),\n",
              " matrix([[-2.6128063e-07, -2.2535454e-07, -2.4127633e-07, -8.1650198e-09,\n",
              "          -6.8586168e-08]], dtype=float32),\n",
              " matrix([[-1.0451225e-07, -4.5724111e-08, -5.8788142e-08,  8.9457998e-08,\n",
              "          -3.2660079e-09]], dtype=float32),\n",
              " ...]"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39933ab7",
      "metadata": {
        "id": "39933ab7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8853c0e",
      "metadata": {
        "id": "e8853c0e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b7bf02",
      "metadata": {
        "id": "69b7bf02"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d578f78e",
      "metadata": {
        "id": "d578f78e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7fedbc",
      "metadata": {
        "id": "0b7fedbc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1250371e",
      "metadata": {
        "id": "1250371e"
      },
      "source": [
        "# Week 5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92b0a14d",
      "metadata": {
        "id": "92b0a14d"
      },
      "source": [
        "### let's take only examples where the question is asnwerable for this model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e27b44c2",
      "metadata": {
        "id": "e27b44c2"
      },
      "outputs": [],
      "source": [
        "def question_parag_combine(questions, paragraphs):\n",
        "    \"\"\"\n",
        "    This function combines the questions and paragraphs into a single text\n",
        "    Args:\n",
        "        questions: list of questions\n",
        "        paragraphs: list of paragraphs\n",
        "    Returns:\n",
        "        list of combined questions and paragraphs\n",
        "    \"\"\"\n",
        "    training_data = []\n",
        "    for index in range(len(questions)):\n",
        "        training_data += [questions[index] + \"\\n\" + paragraphs[index]]\n",
        "        \n",
        "    return training_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b0b9177a",
      "metadata": {
        "id": "b0b9177a"
      },
      "outputs": [],
      "source": [
        "#model_checkpoint = \"bert-base-cased\"\n",
        "model_checkpoint = \"distilbert-base-uncased\"#t5-base #distilbert-base-uncased, t5 is enc dec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f89da391",
      "metadata": {
        "id": "f89da391"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e71de702",
      "metadata": {
        "id": "e71de702"
      },
      "outputs": [],
      "source": [
        "eng_training_asnwerable = []\n",
        "for i in eng_training:\n",
        "    if eng_training[i]['label'] == 1:\n",
        "        eng_training_asnwerable.append(eng_training[i])\n",
        "        \n",
        "eng_val_asnwerable = []\n",
        "for i in eng_val:\n",
        "    if eng_val[i]['label'] == 1:\n",
        "        eng_val_asnwerable.append(eng_val[i])\n",
        "\n",
        "corpus_questions_eng_not_tokenized = []\n",
        "corpus_context_eng_not_tokenized = []\n",
        "for x in eng_training_asnwerable:\n",
        "    corpus_questions_eng_not_tokenized.append(\" \".join(x['question'])) #only answerable\n",
        "    corpus_context_eng_not_tokenized.append(\" \".join(x['context']))\n",
        "        \n",
        "corpus_questions_VAL_eng_not_t = []\n",
        "corpus_context_VAL_eng_not_t = []\n",
        "for x in eng_val_asnwerable:\n",
        "    corpus_questions_VAL_eng_not_t.append(\" \".join(x['question'])) #only answerable\n",
        "    corpus_context_VAL_eng_not_t.append(\" \".join(x['context']))\n",
        " \n",
        "\n",
        "training_labels_eng = []\n",
        "training_data_eng = question_parag_combine(corpus_questions_eng_not_tokenized, corpus_context_eng_not_tokenized)\n",
        "for i in eng_training:\n",
        "    training_labels_eng.append(eng_training[i]['label'])\n",
        "    \n",
        "    \n",
        "validation_labels_eng = []\n",
        "validation_data_eng = question_parag_combine(corpus_questions_VAL_eng_not_t, corpus_context_VAL_eng_not_t)\n",
        "for i in eng_val:\n",
        "    validation_labels_eng.append(eng_val[i]['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "8119b600",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "421eb18ce5324f9495b12d4ead63dc73",
            "079b3785028f4192b1152945cfc7bf80",
            "6d54fdb21025444e9988b798021a8a81",
            "ff1761b9fc724c559c727fe1e2e66472",
            "fc6ee39b163e4ca58cfcfa4e4df32a97",
            "103984cc86d24e87a0914193799ebc2e",
            "b0d90372214b421db7e0fb8d5d760671",
            "a095227a92b641eb9c11fe3f15e79fcf",
            "a3142e6758c44046ae4e9d11eee43c26",
            "c702917a63f44df19a66da3e3c5a2c99",
            "2078d21c739f4bd5976c290d16dcefd8",
            "10f1a360c84c43b5be2a06a6294432e5",
            "f03c040996be4a21a7c17d9ff7cd565e",
            "15c06b869e134f4bafb0365598b9a7f3",
            "b8114882c81e45a7a1d73273ae92b50e",
            "74f90e752c6244e588df4c59345af1ed",
            "3ab3fe9693824e4e8bdace7b97f4dab0",
            "01cc510b28744da6a14e0106b566e67c",
            "5a8aa2c70b6c492ba97374dd36be9661",
            "8f63f14694ad4ba6af980976edc8278c",
            "5ff564be4d624f6e8264786ddc98f23d",
            "9e82c6ad91b747abbe25023893989dac",
            "d49417b45167408b8ef9d1f6e85fc3af",
            "02112a1e87aa4eb2a1bc1921e9477f50",
            "e3c79f3bfeb9410c8690cdc3ed4be283",
            "d80b02c796cc46d8b366ada0aed8752c",
            "b0e596d20d2741cda49ca1408e705bfa",
            "8b3cb54a43aa4457939e0108ec1e2d8e",
            "019cc76972a94f8281ffe0c611d81e2a",
            "3585d2f4ba354d13b40cdc64702a3564",
            "363bbf4999634e438e10fb9f644e3e49",
            "07d2d1c967ea45ae92095884fd590dd3",
            "fd6a52367aa44412a69ec373d0d76dc4",
            "5dcac5e7bad54c93989e9d3c55253386",
            "0857392e1cbd4b3f8a972ec7c3fa856b",
            "7890ec7c6f2d47769d69aae3a125cd12",
            "222721d3e7dc4502a7806bbf5a842086",
            "dcd1c54d01a045439bb85031fad5d34a",
            "7c05780c3bf145658bc45546f7acadcf",
            "04358df65a4e4d9791e609038d8360c5",
            "e07c00ece2d04982a69584235cb21958",
            "4e2b218035484e7e893277259754b1c1",
            "7b8d632e02154111acca976bd467e011",
            "972c424d42e34aa789af3ed7cfb4808c"
          ]
        },
        "id": "8119b600",
        "outputId": "8fb79d90-b4c1-43fb-f3bd-2847e74e1e9c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "421eb18ce5324f9495b12d4ead63dc73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10f1a360c84c43b5be2a06a6294432e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d49417b45167408b8ef9d1f6e85fc3af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dcac5e7bad54c93989e9d3c55253386"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "729125a9",
      "metadata": {
        "id": "729125a9"
      },
      "outputs": [],
      "source": [
        "def find_index_start_answer_tokenized(context, answer): #tokenized input, find the index of the answer in the tokenized format\n",
        "    start_index = 0\n",
        "    while(not(context[context.index(answer[0], start_index):context.index(answer[0], start_index) + len(answer)] == answer)):\n",
        "        start_index +=1\n",
        "    return context.index(answer[0], start_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "958ed7eb",
      "metadata": {
        "id": "958ed7eb"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "for i in eng_training:\n",
        "    if eng_training[i]['label'] == 1:\n",
        "        answers.append(eng_training[i]['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "956ae2c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "956ae2c8",
        "outputId": "a8e13580-19fa-423d-88a5-8626b21cb270"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3696, 3696)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "len(training_data_eng), len(answers) #usefull they are alligned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0ffee6b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ffee6b9",
        "outputId": "9027550c-42a9-44fa-cdac-0e039ebd9a85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('When was quantum field theory developed ?\\nQuantum field theory naturally began with the study of electromagnetic interactions , as the electromagnetic field was the only known classical field as of the 1920s . [ 8 ] :1',\n",
              " ['1920s'])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "training_data_eng[0], answers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "68cc9dde",
      "metadata": {
        "id": "68cc9dde"
      },
      "outputs": [],
      "source": [
        "corrispondence_IOB_ids = {0:'O', 1:  'B-answ', 2:'I-answ'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "793c534a",
      "metadata": {
        "id": "793c534a"
      },
      "outputs": [],
      "source": [
        "tokenized_simple_data_train = []\n",
        "for i in training_data_eng:\n",
        "    tokenized_simple_data_train.append(word_tokenize(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "48938b1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48938b1a",
        "outputId": "bd198b7e-26af-4f37-c543-eb4e3869fdf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "154"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#format the data, training\n",
        "training_labels_IOB = []\n",
        "count_errors = 0\n",
        "for j in range(len(answers)):\n",
        "    IOB_labels = []\n",
        "    #if len(eng_training[j]['answer'])>=1:\n",
        "    try:\n",
        "        start_asnw = find_index_start_answer_tokenized(tokenized_simple_data_train[j], answers[j])\n",
        "        for i,w in enumerate(tokenized_simple_data_train[j]):\n",
        "            if i <  start_asnw:\n",
        "                IOB_labels.append(0)\n",
        "            elif i == start_asnw:\n",
        "                IOB_labels.append(1)\n",
        "            elif i > start_asnw and i <= start_asnw + (len(answers[j])-1):\n",
        "                IOB_labels.append(2)\n",
        "            else:\n",
        "                IOB_labels.append(0)\n",
        "    except:#errors because of bad format of data or because the tokenized splitted differently to the assigned answers by humans\n",
        "            count_errors +=1\n",
        "    training_labels_IOB.append(IOB_labels)\n",
        "    #else:\n",
        "     #   training_labels_IOB.append(IOB_labels)\n",
        "    \n",
        "count_errors #errors to retrieve answers, so couldn't assign IOB labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8a39b1cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "8a39b1cc",
        "outputId": "a19f05c3-8591-42cf-b6e3-d79437409bf8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"#format the data, training\\ntraining_labels_IOB = []\\ncount_errors = 0\\nfor j in eng_training:\\n    IOB_labels = []\\n    if len(eng_training[j]['answer'])>=1:\\n        try:\\n            start_asnw = find_index_start_answer_tokenized(tokenized_simple_data_train[j], eng_training[j]['answer'])\\n            for i,w in enumerate(tokenized_simple_data_train[j]):\\n                if i <  start_asnw:\\n                    IOB_labels.append(0)\\n                elif i == start_asnw:\\n                    IOB_labels.append(1)\\n                elif i > start_asnw and i <= start_asnw + (len(eng_training[j]['answer'])-1):\\n                    IOB_labels.append(2)\\n                else:\\n                    IOB_labels.append(0)\\n        except:#errors because of bad format of data or because the tokenized splitted differently to the assigned answers by humans\\n            count_errors +=1\\n        training_labels_IOB.append(IOB_labels)\\n    else:\\n        training_labels_IOB.append(IOB_labels)\\n    \\ncount_errors #errors to retrieve answers, so couldn't assign IOB labels\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "'''#format the data, training\n",
        "training_labels_IOB = []\n",
        "count_errors = 0\n",
        "for j in eng_training:\n",
        "    IOB_labels = []\n",
        "    if len(eng_training[j]['answer'])>=1:\n",
        "        try:\n",
        "            start_asnw = find_index_start_answer_tokenized(tokenized_simple_data_train[j], eng_training[j]['answer'])\n",
        "            for i,w in enumerate(tokenized_simple_data_train[j]):\n",
        "                if i <  start_asnw:\n",
        "                    IOB_labels.append(0)\n",
        "                elif i == start_asnw:\n",
        "                    IOB_labels.append(1)\n",
        "                elif i > start_asnw and i <= start_asnw + (len(eng_training[j]['answer'])-1):\n",
        "                    IOB_labels.append(2)\n",
        "                else:\n",
        "                    IOB_labels.append(0)\n",
        "        except:#errors because of bad format of data or because the tokenized splitted differently to the assigned answers by humans\n",
        "            count_errors +=1\n",
        "        training_labels_IOB.append(IOB_labels)\n",
        "    else:\n",
        "        training_labels_IOB.append(IOB_labels)\n",
        "    \n",
        "count_errors #errors to retrieve answers, so couldn't assign IOB labels'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6d97ef85",
      "metadata": {
        "id": "6d97ef85"
      },
      "outputs": [],
      "source": [
        "tokenized_simple_data_val = []\n",
        "for i in validation_data_eng:\n",
        "    tokenized_simple_data_val.append(word_tokenize(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ba9197a5",
      "metadata": {
        "id": "ba9197a5"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "for i in eng_val:\n",
        "    if eng_val[i]['label'] == 1:\n",
        "        answers.append(eng_val[i]['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ff915552",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff915552",
        "outputId": "fa213ce0-a220-4566-fe83-a58cab965ab4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#format the data, validation\n",
        "validation_labels_IOB = []\n",
        "count_errors = 0\n",
        "for j in range(len(answers)):\n",
        "    IOB_labels = []\n",
        "    #if len(eng_training[j]['answer'])>=1:\n",
        "    try:\n",
        "        start_asnw = find_index_start_answer_tokenized(tokenized_simple_data_val[j], answers[j])\n",
        "        for i,w in enumerate(tokenized_simple_data_val[j]):\n",
        "            if i <  start_asnw:\n",
        "                IOB_labels.append(0)\n",
        "            elif i == start_asnw:\n",
        "                IOB_labels.append(1)\n",
        "            elif i > start_asnw and i <= start_asnw + (len(answers[j])-1):\n",
        "                IOB_labels.append(2)\n",
        "            else:\n",
        "                IOB_labels.append(0)\n",
        "    except:#errors because of bad format of data or because the tokenized splitted differently to the assigned answers by humans\n",
        "            count_errors +=1\n",
        "    validation_labels_IOB.append(IOB_labels)\n",
        "    #else:\n",
        "     #   training_labels_IOB.append(IOB_labels)\n",
        "    \n",
        "count_errors #errors to retrieve answers, so couldn't assign IOB labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "40442eea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "40442eea",
        "outputId": "49c5909a-d72e-4d3a-b1fb-438995fbca12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"#VALIDATION\\nvalidation_labels_IOB = []\\ncount_errors = 0\\nfor j in eng_val:\\n    IOB_labels = []\\n    if len(eng_val[j]['answer'])>=1:\\n        try:\\n            start_asnw = find_index_start_answer_tokenized(tokenized_simple_data_val[j], eng_val[j]['answer'])\\n            for i,w in enumerate(tokenized_simple_data_val[j]):\\n                if i <  start_asnw:\\n                    IOB_labels.append(0)\\n                elif i == start_asnw:\\n                    IOB_labels.append(1)\\n                elif i > start_asnw and i <= start_asnw + (len(eng_val[j]['answer'])-1):\\n                    IOB_labels.append(2)\\n                else:\\n                    IOB_labels.append(0)\\n        except:#errors because of bad format of data or because the tokenized splitted differently to the assigned answers by humans\\n            count_errors +=1\\n        validation_labels_IOB.append(IOB_labels) \\n    else:\\n        validation_labels_IOB.append(IOB_labels) \\ncount_errors #errors to retrieve answers, so couldn't assign IOB labels\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "\n",
        "'''#VALIDATION\n",
        "validation_labels_IOB = []\n",
        "count_errors = 0\n",
        "for j in eng_val:\n",
        "    IOB_labels = []\n",
        "    if len(eng_val[j]['answer'])>=1:\n",
        "        try:\n",
        "            start_asnw = find_index_start_answer_tokenized(tokenized_simple_data_val[j], eng_val[j]['answer'])\n",
        "            for i,w in enumerate(tokenized_simple_data_val[j]):\n",
        "                if i <  start_asnw:\n",
        "                    IOB_labels.append(0)\n",
        "                elif i == start_asnw:\n",
        "                    IOB_labels.append(1)\n",
        "                elif i > start_asnw and i <= start_asnw + (len(eng_val[j]['answer'])-1):\n",
        "                    IOB_labels.append(2)\n",
        "                else:\n",
        "                    IOB_labels.append(0)\n",
        "        except:#errors because of bad format of data or because the tokenized splitted differently to the assigned answers by humans\n",
        "            count_errors +=1\n",
        "        validation_labels_IOB.append(IOB_labels) \n",
        "    else:\n",
        "        validation_labels_IOB.append(IOB_labels) \n",
        "count_errors #errors to retrieve answers, so couldn't assign IOB labels'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "52f49485",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52f49485",
        "outputId": "21d0ffac-307e-4714-b1b0-9ebe1813b3c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3696, 3696)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "len(tokenized_simple_data_train), len(training_labels_IOB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "068e7b3c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "068e7b3c",
        "outputId": "5d46da0e-8130-4d83-c005-066714444e52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'When was quantum field theory developed ?\\nQuantum field theory naturally began with the study of electromagnetic interactions , as the electromagnetic field was the only known classical field as of the 1920s . [ 8 ] :1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "training_data_eng[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5824bceb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5824bceb",
        "outputId": "64dd7b74-5ef9-4594-86f6-473992e8cee1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence(feature=ClassLabel(names=['O', 'B-answ', 'I-answ'], id=None), length=-1, id=None)\n"
          ]
        }
      ],
      "source": [
        "#def tokenize_function(examples):\n",
        "#    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, is_split_into_words=True)\n",
        "from datasets import DatasetDict, Dataset\n",
        "import datasets\n",
        "data_set = {}\n",
        "sets = [['train',tokenized_simple_data_train, training_labels_IOB], ['val',tokenized_simple_data_val, validation_labels_IOB]]\n",
        "for meta in sets:\n",
        "    data_set[meta[0]] = {}\n",
        "    data_set[meta[0]]['text'] = []\n",
        "    data_set[meta[0]]['y'] = []\n",
        "    \n",
        "    for ind, text in enumerate(meta[1]):\n",
        "        #print(meta[2][ind])\n",
        "        data_set[meta[0]]['text'].append(text)\n",
        "        data_set[meta[0]]['y'].append(meta[2][ind])\n",
        "\n",
        "        \n",
        "print(datasets.Sequence(datasets.ClassLabel(num_classes=3, names=['O','B-answ','I-answ'])))\n",
        "        \n",
        "data_set = DatasetDict({'train':Dataset.from_dict(data_set['train']),\n",
        "                        'valid':Dataset.from_dict(data_set['val'])\\\n",
        "                       })\n",
        "                       \n",
        "                       \n",
        "                       \n",
        "#tokenized_datasets = data_set.map(tokenize_function, batched=True)\n",
        "#tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "95982aa1",
      "metadata": {
        "id": "95982aa1"
      },
      "outputs": [],
      "source": [
        "#Need to allign input_ids and labels!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "780424a5",
      "metadata": {
        "id": "780424a5"
      },
      "outputs": [],
      "source": [
        "#corrispondence_IOB_ids = {0:'O-answ', 1:  'B-answ', 2:'I-answ'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "03f04c75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03f04c75",
        "outputId": "3b768b53-3f6e-43f8-81f6-5607c29ea3bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(names=['O-answ', 'B-answ', 'I-answ'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "datasets.Sequence(datasets.ClassLabel(num_classes=3, names=['O-answ','B-answ','I-answ']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a78d684a",
      "metadata": {
        "id": "a78d684a"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True,padding='max_length', is_split_into_words=True)#\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"y\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx and len(label)>=1:  # Only label the first token of a given word.\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "1fdbe627",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e9381d31c529447c9efe2e15f62bba2b",
            "153c0dde484c4105abc3b475061d95b4",
            "9024494e2d394860979ee2fd736c94a8",
            "9442411bc35046cb94d4e00f10072c80",
            "af67da9e62994f5cb85cd9f6ffff2b44",
            "7cae9f584b584a838c2808f666579511",
            "9b61f88969564393a419c55a537e5469",
            "440175ea36364aacafedb3bab96905cd",
            "777b48f9d18045979b70cf8cd6718f0f",
            "d50b0a582858400fb137cbe5d933f939",
            "ce20a50f92514436baf66b6270db7928",
            "f602db7f0c9c43c6a562c8ba296a128b",
            "48bc40c9f4d3424eab324eb689fd475d",
            "da3f3559856440c69871e5b79a98b24b",
            "31fbfefe368240f195dccf3071f2aaa7",
            "ae371b6b423d448f93de5f983ec84e76",
            "270345e247c34cdd98a28c67791d0637",
            "999082f771da43aa9620377f0aeb9a0f",
            "2ea8532430254e76861d2b267f83a52c",
            "96822ee05af84219a8e15427d98e2ac2",
            "338bfafea3494b4ebba4f4dd7f8d3cd8",
            "09d6b5e90aa442caae50323a71bf7c0f"
          ]
        },
        "id": "1fdbe627",
        "outputId": "05678a84-14dd-4b73-8b63-3e6bf2fc260f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9381d31c529447c9efe2e15f62bba2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f602db7f0c9c43c6a562c8ba296a128b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_datasets = data_set.map(tokenize_and_align_labels, batched=True) #aligned labels and words_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "04fe471a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04fe471a",
        "outputId": "4474d0c3-ea86-432a-8e1e-09b800260e9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'y': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "tokenized_datasets['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "8cfda4f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cfda4f1",
        "outputId": "e37da905-a4e3-4733-a428-f7f4f6626a03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "tokenized_datasets['train'].features[f'labels'] #questo deve essere una sequence, se è un value mi prende batch size 512 invece che 1\n",
        "#devo riuscire a cambiare questo in ClassLAbel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "c050eee6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c050eee6",
        "outputId": "ffdc0ada-7c0c-4682-9e08-f24ea58b86f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['[CLS]',\n",
              "  'when',\n",
              "  'was',\n",
              "  'guitar',\n",
              "  'hero',\n",
              "  'live',\n",
              "  'first',\n",
              "  'released',\n",
              "  '?',\n",
              "  'guitar',\n",
              "  'hero',\n",
              "  'live',\n",
              "  'is',\n",
              "  'a',\n",
              "  'music',\n",
              "  'video',\n",
              "  'game',\n",
              "  'developed',\n",
              "  'by',\n",
              "  'freestyle',\n",
              "  '##games',\n",
              "  'and',\n",
              "  'published',\n",
              "  'by',\n",
              "  'act',\n",
              "  '##ivision',\n",
              "  '.',\n",
              "  'it',\n",
              "  'was',\n",
              "  'released',\n",
              "  'for',\n",
              "  'playstation',\n",
              "  '3',\n",
              "  ',',\n",
              "  'playstation',\n",
              "  '4',\n",
              "  ',',\n",
              "  'wii',\n",
              "  'u',\n",
              "  ',',\n",
              "  'xbox',\n",
              "  '360',\n",
              "  ',',\n",
              "  'and',\n",
              "  'xbox',\n",
              "  'one',\n",
              "  'in',\n",
              "  'october',\n",
              "  '2015',\n",
              "  'and',\n",
              "  'to',\n",
              "  'ios',\n",
              "  'devices',\n",
              "  'including',\n",
              "  'apple',\n",
              "  'tv',\n",
              "  'in',\n",
              "  'november',\n",
              "  '2015',\n",
              "  '.',\n",
              "  'as',\n",
              "  'with',\n",
              "  'previous',\n",
              "  'games',\n",
              "  'in',\n",
              "  'the',\n",
              "  'series',\n",
              "  ',',\n",
              "  'the',\n",
              "  'goal',\n",
              "  'is',\n",
              "  'to',\n",
              "  'use',\n",
              "  'a',\n",
              "  'special',\n",
              "  'guitar',\n",
              "  'controller',\n",
              "  'to',\n",
              "  'match',\n",
              "  'fr',\n",
              "  '##et',\n",
              "  'patterns',\n",
              "  'displayed',\n",
              "  'on',\n",
              "  'a',\n",
              "  'scrolling',\n",
              "  'note',\n",
              "  'pattern',\n",
              "  'on',\n",
              "  'screen',\n",
              "  'in',\n",
              "  'time',\n",
              "  'with',\n",
              "  'the',\n",
              "  'music',\n",
              "  '.',\n",
              "  '[SEP]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]',\n",
              "  '[PAD]'],\n",
              " [-100,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  -100,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  -100,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  1,\n",
              "  2,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  -100,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  0,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100,\n",
              "  -100])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(tokenized_datasets['train'][6]['input_ids'])\n",
        "tokens,tokenized_datasets['train'][6]['labels']# labels = aligned labels, label = not aligned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "94ae5f4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ae5f4b",
        "outputId": "ce832db1-2910-4cbd-deae-f2a0c9cd3ca2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'y': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "tokenized_datasets['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "70a05574",
      "metadata": {
        "id": "70a05574"
      },
      "outputs": [],
      "source": [
        "tokenized_datasets = tokenized_datasets.remove_columns(['text','y'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "fb234831",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb234831",
        "outputId": "b4ae84d6-e6ad-49ec-fcb9-26dbc6e8a1a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'labels': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "tokenized_datasets['train'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f7124348",
      "metadata": {
        "id": "f7124348"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "33241b75",
      "metadata": {
        "id": "33241b75"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b8f5a352",
      "metadata": {
        "id": "b8f5a352"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "de65d7b6",
      "metadata": {
        "id": "de65d7b6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "723ed34b",
      "metadata": {
        "id": "723ed34b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "58017769",
      "metadata": {
        "id": "58017769"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f07fb26c",
      "metadata": {
        "id": "f07fb26c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "8720609a",
      "metadata": {
        "id": "8720609a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f24f6553",
      "metadata": {
        "id": "f24f6553"
      },
      "source": [
        "# FINE TUNING THE MODEL, USE ONLY FOR FINE-TUNING"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDCO6QmPKART",
        "outputId": "bba076bb-ac34-48fd-ec40-8446640de6c9"
      },
      "id": "IDCO6QmPKART",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=6527f40a1fb93344e2a9d3d6a453b911129a14cdcf06528f3cd5cb7640ca2c5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "d550893d",
      "metadata": {
        "id": "d550893d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "94663508bd3a44e2806ff2620a4d609a",
            "b68d9773daee453ca6342129f2e92f4e",
            "f5b59d1ded41406984b1b1d330ba9b29",
            "4b471fe4905247ddb45150b77fd8d1a3",
            "91028cf3b32f4edaa726d4ddb59a3221",
            "b0264bda644d4c30bcbd46b08b875c00",
            "978d4dc2e96f4677a94a2758d3c3d7c7",
            "d3822c2554294fc3a1bbfba05cf1e060",
            "e7f3cafe373e4ea08dbb9671e6ccdbcd",
            "f5ab25910cbe4aac9041636055455604",
            "0febd22cbe914379be63b0a322b17d44"
          ]
        },
        "outputId": "0ed7b337-7508-4aa0-84af-6d791e6fa4ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94663508bd3a44e2806ff2620a4d609a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric(\"seqeval\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "b3519737",
      "metadata": {
        "id": "b3519737"
      },
      "outputs": [],
      "source": [
        "label_list = ['O', 'B-answ', 'I-answ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "4632fcff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4632fcff",
        "outputId": "e644bce7-5e4b-4e3e-ac2b-e4c8fd44ff0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answ': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
              " 'overall_precision': 1.0,\n",
              " 'overall_recall': 1.0,\n",
              " 'overall_f1': 1.0,\n",
              " 'overall_accuracy': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "labels = [label_list[i] for i in tokenized_datasets['train'][0]['labels'] if i >=0]\n",
        "metric.compute(predictions=[labels], references=[labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "85a64ac4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85a64ac4",
        "outputId": "1d223c84-2da1-43fc-f139-2409284ecd4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'B-answ',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O',\n",
              " 'O']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "10acb98c",
      "metadata": {
        "id": "10acb98c"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "9a6c1054",
      "metadata": {
        "id": "9a6c1054"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "28c64efa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "dbd3d3e415424f21935a4815ca84e4b3",
            "15c65bf012f9446bab5eec83006ae2b7",
            "0df7b19e6ea846f0bd1d615d8f943a81",
            "259a6547a65f433db94612b682b7c4d4",
            "b2aaad6aa95149b69e78618fa015e51c",
            "158c01eb4eb744c3903d2bd4b2310a5c",
            "4426d0b638e249f7b62e3b1e8c1ab360",
            "b5887c3f0a514fd9a7715ded872b7b32",
            "7ba6121ac0124ccfab2561979dfacd82",
            "378d162b940744bca22a5f8d5075cc28",
            "a692ceb0cb9c480ea8c911b2d6cd3d0d"
          ]
        },
        "id": "28c64efa",
        "outputId": "0ea1a732-dae2-462a-9ea9-24d478394d40"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbd3d3e415424f21935a4815ca84e4b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer,AutoModelForSeq2SeqLM\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=3)\n",
        "#model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "475b7679",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "475b7679",
        "outputId": "e145a2d8-33f0-4e18-d92b-fd8718e5e538"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "distilbert.embeddings.word_embeddings.weight\n",
            "distilbert.embeddings.position_embeddings.weight\n",
            "distilbert.embeddings.LayerNorm.weight\n",
            "distilbert.embeddings.LayerNorm.bias\n",
            "distilbert.transformer.layer.0.attention.q_lin.weight\n",
            "distilbert.transformer.layer.0.attention.q_lin.bias\n",
            "distilbert.transformer.layer.0.attention.k_lin.weight\n",
            "distilbert.transformer.layer.0.attention.k_lin.bias\n",
            "distilbert.transformer.layer.0.attention.v_lin.weight\n",
            "distilbert.transformer.layer.0.attention.v_lin.bias\n",
            "distilbert.transformer.layer.0.attention.out_lin.weight\n",
            "distilbert.transformer.layer.0.attention.out_lin.bias\n",
            "distilbert.transformer.layer.0.sa_layer_norm.weight\n",
            "distilbert.transformer.layer.0.sa_layer_norm.bias\n",
            "distilbert.transformer.layer.0.ffn.lin1.weight\n",
            "distilbert.transformer.layer.0.ffn.lin1.bias\n",
            "distilbert.transformer.layer.0.ffn.lin2.weight\n",
            "distilbert.transformer.layer.0.ffn.lin2.bias\n",
            "distilbert.transformer.layer.0.output_layer_norm.weight\n",
            "distilbert.transformer.layer.0.output_layer_norm.bias\n",
            "distilbert.transformer.layer.1.attention.q_lin.weight\n",
            "distilbert.transformer.layer.1.attention.q_lin.bias\n",
            "distilbert.transformer.layer.1.attention.k_lin.weight\n",
            "distilbert.transformer.layer.1.attention.k_lin.bias\n",
            "distilbert.transformer.layer.1.attention.v_lin.weight\n",
            "distilbert.transformer.layer.1.attention.v_lin.bias\n",
            "distilbert.transformer.layer.1.attention.out_lin.weight\n",
            "distilbert.transformer.layer.1.attention.out_lin.bias\n",
            "distilbert.transformer.layer.1.sa_layer_norm.weight\n",
            "distilbert.transformer.layer.1.sa_layer_norm.bias\n",
            "distilbert.transformer.layer.1.ffn.lin1.weight\n",
            "distilbert.transformer.layer.1.ffn.lin1.bias\n",
            "distilbert.transformer.layer.1.ffn.lin2.weight\n",
            "distilbert.transformer.layer.1.ffn.lin2.bias\n",
            "distilbert.transformer.layer.1.output_layer_norm.weight\n",
            "distilbert.transformer.layer.1.output_layer_norm.bias\n",
            "distilbert.transformer.layer.2.attention.q_lin.weight\n",
            "distilbert.transformer.layer.2.attention.q_lin.bias\n",
            "distilbert.transformer.layer.2.attention.k_lin.weight\n",
            "distilbert.transformer.layer.2.attention.k_lin.bias\n",
            "distilbert.transformer.layer.2.attention.v_lin.weight\n",
            "distilbert.transformer.layer.2.attention.v_lin.bias\n",
            "distilbert.transformer.layer.2.attention.out_lin.weight\n",
            "distilbert.transformer.layer.2.attention.out_lin.bias\n",
            "distilbert.transformer.layer.2.sa_layer_norm.weight\n",
            "distilbert.transformer.layer.2.sa_layer_norm.bias\n",
            "distilbert.transformer.layer.2.ffn.lin1.weight\n",
            "distilbert.transformer.layer.2.ffn.lin1.bias\n",
            "distilbert.transformer.layer.2.ffn.lin2.weight\n",
            "distilbert.transformer.layer.2.ffn.lin2.bias\n",
            "distilbert.transformer.layer.2.output_layer_norm.weight\n",
            "distilbert.transformer.layer.2.output_layer_norm.bias\n",
            "distilbert.transformer.layer.3.attention.q_lin.weight\n",
            "distilbert.transformer.layer.3.attention.q_lin.bias\n",
            "distilbert.transformer.layer.3.attention.k_lin.weight\n",
            "distilbert.transformer.layer.3.attention.k_lin.bias\n",
            "distilbert.transformer.layer.3.attention.v_lin.weight\n",
            "distilbert.transformer.layer.3.attention.v_lin.bias\n",
            "distilbert.transformer.layer.3.attention.out_lin.weight\n",
            "distilbert.transformer.layer.3.attention.out_lin.bias\n",
            "distilbert.transformer.layer.3.sa_layer_norm.weight\n",
            "distilbert.transformer.layer.3.sa_layer_norm.bias\n",
            "distilbert.transformer.layer.3.ffn.lin1.weight\n",
            "distilbert.transformer.layer.3.ffn.lin1.bias\n",
            "distilbert.transformer.layer.3.ffn.lin2.weight\n",
            "distilbert.transformer.layer.3.ffn.lin2.bias\n",
            "distilbert.transformer.layer.3.output_layer_norm.weight\n",
            "distilbert.transformer.layer.3.output_layer_norm.bias\n",
            "distilbert.transformer.layer.4.attention.q_lin.weight\n",
            "distilbert.transformer.layer.4.attention.q_lin.bias\n",
            "distilbert.transformer.layer.4.attention.k_lin.weight\n",
            "distilbert.transformer.layer.4.attention.k_lin.bias\n",
            "distilbert.transformer.layer.4.attention.v_lin.weight\n",
            "distilbert.transformer.layer.4.attention.v_lin.bias\n",
            "distilbert.transformer.layer.4.attention.out_lin.weight\n",
            "distilbert.transformer.layer.4.attention.out_lin.bias\n",
            "distilbert.transformer.layer.4.sa_layer_norm.weight\n",
            "distilbert.transformer.layer.4.sa_layer_norm.bias\n",
            "distilbert.transformer.layer.4.ffn.lin1.weight\n",
            "distilbert.transformer.layer.4.ffn.lin1.bias\n",
            "distilbert.transformer.layer.4.ffn.lin2.weight\n",
            "distilbert.transformer.layer.4.ffn.lin2.bias\n",
            "distilbert.transformer.layer.4.output_layer_norm.weight\n",
            "distilbert.transformer.layer.4.output_layer_norm.bias\n",
            "distilbert.transformer.layer.5.attention.q_lin.weight\n",
            "distilbert.transformer.layer.5.attention.q_lin.bias\n",
            "distilbert.transformer.layer.5.attention.k_lin.weight\n",
            "distilbert.transformer.layer.5.attention.k_lin.bias\n",
            "distilbert.transformer.layer.5.attention.v_lin.weight\n",
            "distilbert.transformer.layer.5.attention.v_lin.bias\n",
            "distilbert.transformer.layer.5.attention.out_lin.weight\n",
            "distilbert.transformer.layer.5.attention.out_lin.bias\n",
            "distilbert.transformer.layer.5.sa_layer_norm.weight\n",
            "distilbert.transformer.layer.5.sa_layer_norm.bias\n",
            "distilbert.transformer.layer.5.ffn.lin1.weight\n",
            "distilbert.transformer.layer.5.ffn.lin1.bias\n",
            "distilbert.transformer.layer.5.ffn.lin2.weight\n",
            "distilbert.transformer.layer.5.ffn.lin2.bias\n",
            "distilbert.transformer.layer.5.output_layer_norm.weight\n",
            "distilbert.transformer.layer.5.output_layer_norm.bias\n",
            "classifier.weight\n",
            "classifier.bias\n"
          ]
        }
      ],
      "source": [
        "#layers that will be trained with these settings:\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        print(name) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28613865",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28613865",
        "outputId": "f3635b88-3c01-4616-8f03-ed9a95a0366e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I will be frozen: distilbert.embeddings.word_embeddings.weight\n",
            "I will be frozen: distilbert.embeddings.position_embeddings.weight\n",
            "I will be frozen: distilbert.embeddings.LayerNorm.weight\n",
            "I will be frozen: distilbert.embeddings.LayerNorm.bias\n",
            "I will be frozen: distilbert.transformer.layer.0.attention.q_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.0.attention.q_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.0.attention.k_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.0.attention.k_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.0.attention.v_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.0.attention.v_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.0.attention.out_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.0.attention.out_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.0.sa_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.0.sa_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.0.ffn.lin1.weight\n",
            "I will be frozen: distilbert.transformer.layer.0.ffn.lin1.bias\n",
            "I will be frozen: distilbert.transformer.layer.0.ffn.lin2.weight\n",
            "I will be frozen: distilbert.transformer.layer.0.ffn.lin2.bias\n",
            "I will be frozen: distilbert.transformer.layer.0.output_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.0.output_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.1.attention.q_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.1.attention.q_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.1.attention.k_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.1.attention.k_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.1.attention.v_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.1.attention.v_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.1.attention.out_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.1.attention.out_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.1.sa_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.1.sa_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.1.ffn.lin1.weight\n",
            "I will be frozen: distilbert.transformer.layer.1.ffn.lin1.bias\n",
            "I will be frozen: distilbert.transformer.layer.1.ffn.lin2.weight\n",
            "I will be frozen: distilbert.transformer.layer.1.ffn.lin2.bias\n",
            "I will be frozen: distilbert.transformer.layer.1.output_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.1.output_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.2.attention.q_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.2.attention.q_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.2.attention.k_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.2.attention.k_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.2.attention.v_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.2.attention.v_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.2.attention.out_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.2.attention.out_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.2.sa_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.2.sa_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.2.ffn.lin1.weight\n",
            "I will be frozen: distilbert.transformer.layer.2.ffn.lin1.bias\n",
            "I will be frozen: distilbert.transformer.layer.2.ffn.lin2.weight\n",
            "I will be frozen: distilbert.transformer.layer.2.ffn.lin2.bias\n",
            "I will be frozen: distilbert.transformer.layer.2.output_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.2.output_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.3.attention.q_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.3.attention.q_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.3.attention.k_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.3.attention.k_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.3.attention.v_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.3.attention.v_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.3.attention.out_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.3.attention.out_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.3.sa_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.3.sa_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.3.ffn.lin1.weight\n",
            "I will be frozen: distilbert.transformer.layer.3.ffn.lin1.bias\n",
            "I will be frozen: distilbert.transformer.layer.3.ffn.lin2.weight\n",
            "I will be frozen: distilbert.transformer.layer.3.ffn.lin2.bias\n",
            "I will be frozen: distilbert.transformer.layer.3.output_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.3.output_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.4.attention.q_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.4.attention.q_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.4.attention.k_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.4.attention.k_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.4.attention.v_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.4.attention.v_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.4.attention.out_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.4.attention.out_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.4.sa_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.4.sa_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.4.ffn.lin1.weight\n",
            "I will be frozen: distilbert.transformer.layer.4.ffn.lin1.bias\n",
            "I will be frozen: distilbert.transformer.layer.4.ffn.lin2.weight\n",
            "I will be frozen: distilbert.transformer.layer.4.ffn.lin2.bias\n",
            "I will be frozen: distilbert.transformer.layer.4.output_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.4.output_layer_norm.bias\n",
            "I will be frozen: distilbert.transformer.layer.5.attention.q_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.5.attention.q_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.5.attention.k_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.5.attention.k_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.5.attention.v_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.5.attention.v_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.5.attention.out_lin.weight\n",
            "I will be frozen: distilbert.transformer.layer.5.attention.out_lin.bias\n",
            "I will be frozen: distilbert.transformer.layer.5.sa_layer_norm.weight\n",
            "I will be frozen: distilbert.transformer.layer.5.sa_layer_norm.bias\n"
          ]
        }
      ],
      "source": [
        "for name, param in list(model.named_parameters())[:len(list(model.parameters())) - 8]:#RECOMPUTE CLASSIFICATION AND LAYER 5 OF ATTENTION, #34 if I want to unfreeze also layer 4  \n",
        "    print('I will be frozen: {}'.format(name)) \n",
        "    param.requires_grad = False #do not require gradint computation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff3371b1",
      "metadata": {
        "id": "ff3371b1"
      },
      "source": [
        "## Define weights for unbalanced classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "id": "4ee9b7d3",
      "metadata": {
        "id": "4ee9b7d3"
      },
      "outputs": [],
      "source": [
        "count_0 = 0\n",
        "count_1 = 0\n",
        "count_2 = 0\n",
        "total_classes = 0\n",
        "\n",
        "for i in pd.DataFrame(tokenized_datasets[\"train\"])['labels']:\n",
        "    for j in i:\n",
        "        if j == 0:\n",
        "            count_0 +=1\n",
        "            total_classes +=1\n",
        "        if j == 1:\n",
        "            count_1 +=1\n",
        "            total_classes +=1\n",
        "        if j == 2:\n",
        "            count_2 +=1\n",
        "            total_classes +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "836c7de9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "836c7de9",
        "outputId": "92966c2c-2484-4075-f9a7-e9a88be52db7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9628431118211154, 0.008053541601241597, 0.02910334657764306)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ],
      "source": [
        "count_0/total_classes, count_1/total_classes, count_2/total_classes"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0xKoCH3uOjxa"
      },
      "id": "0xKoCH3uOjxa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WSPnoj64Oj0C"
      },
      "id": "WSPnoj64Oj0C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c8f9a1e1",
      "metadata": {
        "id": "c8f9a1e1"
      },
      "source": [
        "# Trainer for unbalanced datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3b0425",
      "metadata": {
        "id": "6a3b0425"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss (suppose one has 3 labels with different weights)\n",
        "        weight=torch.tensor([1-count_0/total_classes, 1-count_1/total_classes, 1-count_2/total_classes])\n",
        "        weight.to(\"cuda:0\")\n",
        "        loss_fct = nn.CrossEntropyLoss()\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4f207a",
      "metadata": {
        "id": "3e4f207a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c70b9cd2",
      "metadata": {
        "id": "c70b9cd2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5896371d",
      "metadata": {
        "id": "5896371d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314d708c",
      "metadata": {
        "id": "314d708c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50203f27",
      "metadata": {
        "id": "50203f27"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b9b62a8",
      "metadata": {
        "scrolled": true,
        "id": "5b9b62a8",
        "outputId": "1982ac68-9c23-42b4-8cdb-f4afa3d76314"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\fiori\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 3696\n",
            "  Num Epochs = 100\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 46200\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='46200' max='46200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [46200/46200 7:10:15, Epoch 100/100]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.139980</td>\n",
              "      <td>0.064000</td>\n",
              "      <td>0.016736</td>\n",
              "      <td>0.026534</td>\n",
              "      <td>0.961239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.159200</td>\n",
              "      <td>0.130744</td>\n",
              "      <td>0.128440</td>\n",
              "      <td>0.029289</td>\n",
              "      <td>0.047700</td>\n",
              "      <td>0.961982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.117800</td>\n",
              "      <td>0.120143</td>\n",
              "      <td>0.224090</td>\n",
              "      <td>0.334728</td>\n",
              "      <td>0.268456</td>\n",
              "      <td>0.962676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.098100</td>\n",
              "      <td>0.112773</td>\n",
              "      <td>0.303538</td>\n",
              "      <td>0.341004</td>\n",
              "      <td>0.321182</td>\n",
              "      <td>0.966437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.077500</td>\n",
              "      <td>0.115186</td>\n",
              "      <td>0.281493</td>\n",
              "      <td>0.378661</td>\n",
              "      <td>0.322926</td>\n",
              "      <td>0.964855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.065000</td>\n",
              "      <td>0.123022</td>\n",
              "      <td>0.264910</td>\n",
              "      <td>0.399582</td>\n",
              "      <td>0.318599</td>\n",
              "      <td>0.963984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.052000</td>\n",
              "      <td>0.132636</td>\n",
              "      <td>0.288217</td>\n",
              "      <td>0.378661</td>\n",
              "      <td>0.327306</td>\n",
              "      <td>0.965324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.041200</td>\n",
              "      <td>0.149971</td>\n",
              "      <td>0.252525</td>\n",
              "      <td>0.366109</td>\n",
              "      <td>0.298890</td>\n",
              "      <td>0.962063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.034200</td>\n",
              "      <td>0.152141</td>\n",
              "      <td>0.286525</td>\n",
              "      <td>0.422594</td>\n",
              "      <td>0.341505</td>\n",
              "      <td>0.964678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.028900</td>\n",
              "      <td>0.174456</td>\n",
              "      <td>0.355789</td>\n",
              "      <td>0.353556</td>\n",
              "      <td>0.354669</td>\n",
              "      <td>0.967115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>0.169997</td>\n",
              "      <td>0.279762</td>\n",
              "      <td>0.393305</td>\n",
              "      <td>0.326957</td>\n",
              "      <td>0.964823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.021500</td>\n",
              "      <td>0.191702</td>\n",
              "      <td>0.319188</td>\n",
              "      <td>0.361925</td>\n",
              "      <td>0.339216</td>\n",
              "      <td>0.966760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.018800</td>\n",
              "      <td>0.167637</td>\n",
              "      <td>0.263533</td>\n",
              "      <td>0.387029</td>\n",
              "      <td>0.313559</td>\n",
              "      <td>0.963499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.018800</td>\n",
              "      <td>0.188531</td>\n",
              "      <td>0.282171</td>\n",
              "      <td>0.380753</td>\n",
              "      <td>0.324132</td>\n",
              "      <td>0.965227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.015900</td>\n",
              "      <td>0.193053</td>\n",
              "      <td>0.281713</td>\n",
              "      <td>0.357741</td>\n",
              "      <td>0.315207</td>\n",
              "      <td>0.965324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.013600</td>\n",
              "      <td>0.200716</td>\n",
              "      <td>0.304279</td>\n",
              "      <td>0.401674</td>\n",
              "      <td>0.346258</td>\n",
              "      <td>0.965469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.011800</td>\n",
              "      <td>0.213310</td>\n",
              "      <td>0.304207</td>\n",
              "      <td>0.393305</td>\n",
              "      <td>0.343066</td>\n",
              "      <td>0.966018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.010500</td>\n",
              "      <td>0.236989</td>\n",
              "      <td>0.354120</td>\n",
              "      <td>0.332636</td>\n",
              "      <td>0.343042</td>\n",
              "      <td>0.967793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.008900</td>\n",
              "      <td>0.214102</td>\n",
              "      <td>0.293935</td>\n",
              "      <td>0.395397</td>\n",
              "      <td>0.337199</td>\n",
              "      <td>0.965001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.008400</td>\n",
              "      <td>0.225492</td>\n",
              "      <td>0.295008</td>\n",
              "      <td>0.407950</td>\n",
              "      <td>0.342406</td>\n",
              "      <td>0.965194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.008200</td>\n",
              "      <td>0.227741</td>\n",
              "      <td>0.298535</td>\n",
              "      <td>0.341004</td>\n",
              "      <td>0.318359</td>\n",
              "      <td>0.965792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.005900</td>\n",
              "      <td>0.229889</td>\n",
              "      <td>0.308108</td>\n",
              "      <td>0.357741</td>\n",
              "      <td>0.331075</td>\n",
              "      <td>0.966405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>0.234599</td>\n",
              "      <td>0.356557</td>\n",
              "      <td>0.364017</td>\n",
              "      <td>0.360248</td>\n",
              "      <td>0.966567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>0.238703</td>\n",
              "      <td>0.348000</td>\n",
              "      <td>0.364017</td>\n",
              "      <td>0.355828</td>\n",
              "      <td>0.967567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>0.243031</td>\n",
              "      <td>0.305606</td>\n",
              "      <td>0.353556</td>\n",
              "      <td>0.327837</td>\n",
              "      <td>0.966760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.004500</td>\n",
              "      <td>0.251627</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.389121</td>\n",
              "      <td>0.359073</td>\n",
              "      <td>0.966663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.004500</td>\n",
              "      <td>0.243031</td>\n",
              "      <td>0.284444</td>\n",
              "      <td>0.401674</td>\n",
              "      <td>0.333044</td>\n",
              "      <td>0.965178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.245367</td>\n",
              "      <td>0.286645</td>\n",
              "      <td>0.368201</td>\n",
              "      <td>0.322344</td>\n",
              "      <td>0.966567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.004100</td>\n",
              "      <td>0.248028</td>\n",
              "      <td>0.307971</td>\n",
              "      <td>0.355649</td>\n",
              "      <td>0.330097</td>\n",
              "      <td>0.966324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.243291</td>\n",
              "      <td>0.294976</td>\n",
              "      <td>0.380753</td>\n",
              "      <td>0.332420</td>\n",
              "      <td>0.966324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.248919</td>\n",
              "      <td>0.306090</td>\n",
              "      <td>0.399582</td>\n",
              "      <td>0.346642</td>\n",
              "      <td>0.966421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>0.262175</td>\n",
              "      <td>0.349112</td>\n",
              "      <td>0.370293</td>\n",
              "      <td>0.359391</td>\n",
              "      <td>0.967713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>0.263649</td>\n",
              "      <td>0.322330</td>\n",
              "      <td>0.347280</td>\n",
              "      <td>0.334340</td>\n",
              "      <td>0.967616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.002700</td>\n",
              "      <td>0.266272</td>\n",
              "      <td>0.336714</td>\n",
              "      <td>0.347280</td>\n",
              "      <td>0.341916</td>\n",
              "      <td>0.967923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.003200</td>\n",
              "      <td>0.272720</td>\n",
              "      <td>0.326848</td>\n",
              "      <td>0.351464</td>\n",
              "      <td>0.338710</td>\n",
              "      <td>0.967729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.002400</td>\n",
              "      <td>0.263095</td>\n",
              "      <td>0.302980</td>\n",
              "      <td>0.382845</td>\n",
              "      <td>0.338262</td>\n",
              "      <td>0.966405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.276143</td>\n",
              "      <td>0.339731</td>\n",
              "      <td>0.370293</td>\n",
              "      <td>0.354354</td>\n",
              "      <td>0.967858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.256715</td>\n",
              "      <td>0.268256</td>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.313316</td>\n",
              "      <td>0.965130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.283262</td>\n",
              "      <td>0.362140</td>\n",
              "      <td>0.368201</td>\n",
              "      <td>0.365145</td>\n",
              "      <td>0.968133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.277589</td>\n",
              "      <td>0.318339</td>\n",
              "      <td>0.384937</td>\n",
              "      <td>0.348485</td>\n",
              "      <td>0.966647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.278718</td>\n",
              "      <td>0.309028</td>\n",
              "      <td>0.372385</td>\n",
              "      <td>0.337761</td>\n",
              "      <td>0.966599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.283473</td>\n",
              "      <td>0.323475</td>\n",
              "      <td>0.366109</td>\n",
              "      <td>0.343474</td>\n",
              "      <td>0.967228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>0.282308</td>\n",
              "      <td>0.296482</td>\n",
              "      <td>0.370293</td>\n",
              "      <td>0.329302</td>\n",
              "      <td>0.965743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.285819</td>\n",
              "      <td>0.291874</td>\n",
              "      <td>0.368201</td>\n",
              "      <td>0.325624</td>\n",
              "      <td>0.966098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.290972</td>\n",
              "      <td>0.338624</td>\n",
              "      <td>0.401674</td>\n",
              "      <td>0.367464</td>\n",
              "      <td>0.967422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.297925</td>\n",
              "      <td>0.327465</td>\n",
              "      <td>0.389121</td>\n",
              "      <td>0.355641</td>\n",
              "      <td>0.966567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.310902</td>\n",
              "      <td>0.342672</td>\n",
              "      <td>0.332636</td>\n",
              "      <td>0.337580</td>\n",
              "      <td>0.967842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.285854</td>\n",
              "      <td>0.282132</td>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.322581</td>\n",
              "      <td>0.966098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.305609</td>\n",
              "      <td>0.322896</td>\n",
              "      <td>0.345188</td>\n",
              "      <td>0.333670</td>\n",
              "      <td>0.967051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.300986</td>\n",
              "      <td>0.330134</td>\n",
              "      <td>0.359833</td>\n",
              "      <td>0.344344</td>\n",
              "      <td>0.967293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>0.305964</td>\n",
              "      <td>0.347741</td>\n",
              "      <td>0.370293</td>\n",
              "      <td>0.358663</td>\n",
              "      <td>0.967987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.302386</td>\n",
              "      <td>0.320138</td>\n",
              "      <td>0.389121</td>\n",
              "      <td>0.351275</td>\n",
              "      <td>0.966663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.306080</td>\n",
              "      <td>0.313620</td>\n",
              "      <td>0.366109</td>\n",
              "      <td>0.337838</td>\n",
              "      <td>0.966324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.307877</td>\n",
              "      <td>0.326172</td>\n",
              "      <td>0.349372</td>\n",
              "      <td>0.337374</td>\n",
              "      <td>0.967212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.300818</td>\n",
              "      <td>0.310744</td>\n",
              "      <td>0.393305</td>\n",
              "      <td>0.347184</td>\n",
              "      <td>0.966647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.301121</td>\n",
              "      <td>0.313274</td>\n",
              "      <td>0.370293</td>\n",
              "      <td>0.339406</td>\n",
              "      <td>0.967051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.301290</td>\n",
              "      <td>0.304274</td>\n",
              "      <td>0.372385</td>\n",
              "      <td>0.334901</td>\n",
              "      <td>0.966793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.307431</td>\n",
              "      <td>0.339658</td>\n",
              "      <td>0.374477</td>\n",
              "      <td>0.356219</td>\n",
              "      <td>0.968133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.322025</td>\n",
              "      <td>0.337209</td>\n",
              "      <td>0.364017</td>\n",
              "      <td>0.350101</td>\n",
              "      <td>0.967761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.315548</td>\n",
              "      <td>0.334579</td>\n",
              "      <td>0.374477</td>\n",
              "      <td>0.353406</td>\n",
              "      <td>0.967874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.312211</td>\n",
              "      <td>0.329020</td>\n",
              "      <td>0.372385</td>\n",
              "      <td>0.349362</td>\n",
              "      <td>0.967745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.320907</td>\n",
              "      <td>0.314647</td>\n",
              "      <td>0.364017</td>\n",
              "      <td>0.337536</td>\n",
              "      <td>0.966938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.310515</td>\n",
              "      <td>0.330241</td>\n",
              "      <td>0.372385</td>\n",
              "      <td>0.350049</td>\n",
              "      <td>0.967584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.325806</td>\n",
              "      <td>0.347561</td>\n",
              "      <td>0.357741</td>\n",
              "      <td>0.352577</td>\n",
              "      <td>0.968165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.311660</td>\n",
              "      <td>0.331512</td>\n",
              "      <td>0.380753</td>\n",
              "      <td>0.354430</td>\n",
              "      <td>0.967664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.307009</td>\n",
              "      <td>0.313692</td>\n",
              "      <td>0.378661</td>\n",
              "      <td>0.343128</td>\n",
              "      <td>0.967115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.320447</td>\n",
              "      <td>0.339921</td>\n",
              "      <td>0.359833</td>\n",
              "      <td>0.349593</td>\n",
              "      <td>0.967890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.319658</td>\n",
              "      <td>0.327485</td>\n",
              "      <td>0.351464</td>\n",
              "      <td>0.339051</td>\n",
              "      <td>0.967358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.323296</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.359833</td>\n",
              "      <td>0.346076</td>\n",
              "      <td>0.967632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.320881</td>\n",
              "      <td>0.313274</td>\n",
              "      <td>0.370293</td>\n",
              "      <td>0.339406</td>\n",
              "      <td>0.967035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.324487</td>\n",
              "      <td>0.333948</td>\n",
              "      <td>0.378661</td>\n",
              "      <td>0.354902</td>\n",
              "      <td>0.967519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.329189</td>\n",
              "      <td>0.329502</td>\n",
              "      <td>0.359833</td>\n",
              "      <td>0.344000</td>\n",
              "      <td>0.968084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.328245</td>\n",
              "      <td>0.327068</td>\n",
              "      <td>0.364017</td>\n",
              "      <td>0.344554</td>\n",
              "      <td>0.967293</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.335373</td>\n",
              "      <td>0.324723</td>\n",
              "      <td>0.368201</td>\n",
              "      <td>0.345098</td>\n",
              "      <td>0.967438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.329677</td>\n",
              "      <td>0.325967</td>\n",
              "      <td>0.370293</td>\n",
              "      <td>0.346719</td>\n",
              "      <td>0.967890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.332759</td>\n",
              "      <td>0.323529</td>\n",
              "      <td>0.368201</td>\n",
              "      <td>0.344423</td>\n",
              "      <td>0.967551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.338289</td>\n",
              "      <td>0.334686</td>\n",
              "      <td>0.345188</td>\n",
              "      <td>0.339856</td>\n",
              "      <td>0.967761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.325314</td>\n",
              "      <td>0.322878</td>\n",
              "      <td>0.366109</td>\n",
              "      <td>0.343137</td>\n",
              "      <td>0.967067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.338195</td>\n",
              "      <td>0.352000</td>\n",
              "      <td>0.368201</td>\n",
              "      <td>0.359918</td>\n",
              "      <td>0.967890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.329743</td>\n",
              "      <td>0.326679</td>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.349854</td>\n",
              "      <td>0.967341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.337192</td>\n",
              "      <td>0.337255</td>\n",
              "      <td>0.359833</td>\n",
              "      <td>0.348178</td>\n",
              "      <td>0.967422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.334857</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.366109</td>\n",
              "      <td>0.348953</td>\n",
              "      <td>0.967503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.334030</td>\n",
              "      <td>0.338552</td>\n",
              "      <td>0.361925</td>\n",
              "      <td>0.349848</td>\n",
              "      <td>0.968181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.339089</td>\n",
              "      <td>0.337232</td>\n",
              "      <td>0.361925</td>\n",
              "      <td>0.349142</td>\n",
              "      <td>0.967874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.334528</td>\n",
              "      <td>0.332075</td>\n",
              "      <td>0.368201</td>\n",
              "      <td>0.349206</td>\n",
              "      <td>0.967680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.337103</td>\n",
              "      <td>0.326855</td>\n",
              "      <td>0.387029</td>\n",
              "      <td>0.354406</td>\n",
              "      <td>0.967600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.344467</td>\n",
              "      <td>0.334711</td>\n",
              "      <td>0.338912</td>\n",
              "      <td>0.336798</td>\n",
              "      <td>0.968116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.337922</td>\n",
              "      <td>0.331395</td>\n",
              "      <td>0.357741</td>\n",
              "      <td>0.344064</td>\n",
              "      <td>0.967906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.340495</td>\n",
              "      <td>0.328273</td>\n",
              "      <td>0.361925</td>\n",
              "      <td>0.344279</td>\n",
              "      <td>0.968020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.342456</td>\n",
              "      <td>0.343811</td>\n",
              "      <td>0.366109</td>\n",
              "      <td>0.354610</td>\n",
              "      <td>0.967923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.340253</td>\n",
              "      <td>0.334638</td>\n",
              "      <td>0.357741</td>\n",
              "      <td>0.345804</td>\n",
              "      <td>0.967793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.341213</td>\n",
              "      <td>0.337121</td>\n",
              "      <td>0.372385</td>\n",
              "      <td>0.353877</td>\n",
              "      <td>0.967551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.343616</td>\n",
              "      <td>0.340952</td>\n",
              "      <td>0.374477</td>\n",
              "      <td>0.356929</td>\n",
              "      <td>0.967697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.345285</td>\n",
              "      <td>0.332039</td>\n",
              "      <td>0.357741</td>\n",
              "      <td>0.344411</td>\n",
              "      <td>0.967632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.342274</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.370293</td>\n",
              "      <td>0.350842</td>\n",
              "      <td>0.967535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.346958</td>\n",
              "      <td>0.345703</td>\n",
              "      <td>0.370293</td>\n",
              "      <td>0.357576</td>\n",
              "      <td>0.967826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.345447</td>\n",
              "      <td>0.346228</td>\n",
              "      <td>0.374477</td>\n",
              "      <td>0.359799</td>\n",
              "      <td>0.967680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.344284</td>\n",
              "      <td>0.350877</td>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.363269</td>\n",
              "      <td>0.967793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.344485</td>\n",
              "      <td>0.346899</td>\n",
              "      <td>0.374477</td>\n",
              "      <td>0.360161</td>\n",
              "      <td>0.967761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.344330</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.376569</td>\n",
              "      <td>0.362173</td>\n",
              "      <td>0.967810</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-500\n",
            "Configuration saved in ./results\\checkpoint-500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-1000\n",
            "Configuration saved in ./results\\checkpoint-1000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-1000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-1000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-1000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-1500\n",
            "Configuration saved in ./results\\checkpoint-1500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-1500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-1500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-1500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-2000\n",
            "Configuration saved in ./results\\checkpoint-2000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-2000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-2000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-2000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-2500\n",
            "Configuration saved in ./results\\checkpoint-2500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-2500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-2500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-2500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-3000\n",
            "Configuration saved in ./results\\checkpoint-3000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-3000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-3000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-3000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-3500\n",
            "Configuration saved in ./results\\checkpoint-3500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-3500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-3500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-3500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-4000\n",
            "Configuration saved in ./results\\checkpoint-4000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-4000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-4000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-4000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-4500\n",
            "Configuration saved in ./results\\checkpoint-4500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-4500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-4500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-4500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-5000\n",
            "Configuration saved in ./results\\checkpoint-5000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-5000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-5000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-5000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-5500\n",
            "Configuration saved in ./results\\checkpoint-5500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-5500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-5500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-5500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-6000\n",
            "Configuration saved in ./results\\checkpoint-6000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-6000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-6000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-6000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-6500\n",
            "Configuration saved in ./results\\checkpoint-6500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-6500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-6500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-6500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-7000\n",
            "Configuration saved in ./results\\checkpoint-7000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-7000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-7000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-7000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-7500\n",
            "Configuration saved in ./results\\checkpoint-7500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-7500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-7500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-7500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-8000\n",
            "Configuration saved in ./results\\checkpoint-8000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-8000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-8000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-8000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-8500\n",
            "Configuration saved in ./results\\checkpoint-8500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-8500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-8500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-8500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-9000\n",
            "Configuration saved in ./results\\checkpoint-9000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-9000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-9000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-9000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-9500\n",
            "Configuration saved in ./results\\checkpoint-9500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-9500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-9500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-9500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-10000\n",
            "Configuration saved in ./results\\checkpoint-10000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-10000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-10000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-10000\\special_tokens_map.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-10500\n",
            "Configuration saved in ./results\\checkpoint-10500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-10500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-10500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-10500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-11000\n",
            "Configuration saved in ./results\\checkpoint-11000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-11000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-11000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-11000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-11500\n",
            "Configuration saved in ./results\\checkpoint-11500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-11500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-11500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-11500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-12000\n",
            "Configuration saved in ./results\\checkpoint-12000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-12000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-12000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-12000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-12500\n",
            "Configuration saved in ./results\\checkpoint-12500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-12500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-12500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-12500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-13000\n",
            "Configuration saved in ./results\\checkpoint-13000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-13000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-13000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-13000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-13500\n",
            "Configuration saved in ./results\\checkpoint-13500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-13500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-13500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-13500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-14000\n",
            "Configuration saved in ./results\\checkpoint-14000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-14000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-14000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-14000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-14500\n",
            "Configuration saved in ./results\\checkpoint-14500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-14500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-14500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-14500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-15000\n",
            "Configuration saved in ./results\\checkpoint-15000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-15000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-15000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-15000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-15500\n",
            "Configuration saved in ./results\\checkpoint-15500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-15500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-15500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-15500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-16000\n",
            "Configuration saved in ./results\\checkpoint-16000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-16000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-16000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-16000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-16500\n",
            "Configuration saved in ./results\\checkpoint-16500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-16500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-16500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-16500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-17000\n",
            "Configuration saved in ./results\\checkpoint-17000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-17000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-17000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-17000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-17500\n",
            "Configuration saved in ./results\\checkpoint-17500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-17500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-17500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-17500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-18000\n",
            "Configuration saved in ./results\\checkpoint-18000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-18000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-18000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-18000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-18500\n",
            "Configuration saved in ./results\\checkpoint-18500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-18500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-18500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-18500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-19000\n",
            "Configuration saved in ./results\\checkpoint-19000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-19000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-19000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-19000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-19500\n",
            "Configuration saved in ./results\\checkpoint-19500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-19500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-19500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-19500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-20000\n",
            "Configuration saved in ./results\\checkpoint-20000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-20000\\pytorch_model.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "tokenizer config file saved in ./results\\checkpoint-20000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-20000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-20500\n",
            "Configuration saved in ./results\\checkpoint-20500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-20500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-20500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-20500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-21000\n",
            "Configuration saved in ./results\\checkpoint-21000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-21000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-21000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-21000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-21500\n",
            "Configuration saved in ./results\\checkpoint-21500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-21500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-21500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-21500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-22000\n",
            "Configuration saved in ./results\\checkpoint-22000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-22000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-22000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-22000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-22500\n",
            "Configuration saved in ./results\\checkpoint-22500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-22500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-22500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-22500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-23000\n",
            "Configuration saved in ./results\\checkpoint-23000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-23000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-23000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-23000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-23500\n",
            "Configuration saved in ./results\\checkpoint-23500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-23500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-23500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-23500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-24000\n",
            "Configuration saved in ./results\\checkpoint-24000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-24000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-24000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-24000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-24500\n",
            "Configuration saved in ./results\\checkpoint-24500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-24500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-24500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-24500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-25000\n",
            "Configuration saved in ./results\\checkpoint-25000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-25000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-25000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-25000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-25500\n",
            "Configuration saved in ./results\\checkpoint-25500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-25500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-25500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-25500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-26000\n",
            "Configuration saved in ./results\\checkpoint-26000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-26000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-26000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-26000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-26500\n",
            "Configuration saved in ./results\\checkpoint-26500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-26500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-26500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-26500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-27000\n",
            "Configuration saved in ./results\\checkpoint-27000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-27000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-27000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-27000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-27500\n",
            "Configuration saved in ./results\\checkpoint-27500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-27500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-27500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-27500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-28000\n",
            "Configuration saved in ./results\\checkpoint-28000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-28000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-28000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-28000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-28500\n",
            "Configuration saved in ./results\\checkpoint-28500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-28500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-28500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-28500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-29000\n",
            "Configuration saved in ./results\\checkpoint-29000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-29000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-29000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-29000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-29500\n",
            "Configuration saved in ./results\\checkpoint-29500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-29500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-29500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-29500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-30000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in ./results\\checkpoint-30000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-30000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-30000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-30000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-30500\n",
            "Configuration saved in ./results\\checkpoint-30500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-30500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-30500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-30500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-31000\n",
            "Configuration saved in ./results\\checkpoint-31000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-31000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-31000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-31000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-31500\n",
            "Configuration saved in ./results\\checkpoint-31500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-31500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-31500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-31500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-32000\n",
            "Configuration saved in ./results\\checkpoint-32000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-32000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-32000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-32000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-32500\n",
            "Configuration saved in ./results\\checkpoint-32500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-32500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-32500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-32500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-33000\n",
            "Configuration saved in ./results\\checkpoint-33000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-33000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-33000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-33000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-33500\n",
            "Configuration saved in ./results\\checkpoint-33500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-33500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-33500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-33500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-34000\n",
            "Configuration saved in ./results\\checkpoint-34000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-34000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-34000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-34000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-34500\n",
            "Configuration saved in ./results\\checkpoint-34500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-34500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-34500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-34500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-35000\n",
            "Configuration saved in ./results\\checkpoint-35000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-35000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-35000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-35000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-35500\n",
            "Configuration saved in ./results\\checkpoint-35500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-35500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-35500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-35500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-36000\n",
            "Configuration saved in ./results\\checkpoint-36000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-36000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-36000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-36000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-36500\n",
            "Configuration saved in ./results\\checkpoint-36500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-36500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-36500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-36500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-37000\n",
            "Configuration saved in ./results\\checkpoint-37000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-37000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-37000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-37000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-37500\n",
            "Configuration saved in ./results\\checkpoint-37500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-37500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-37500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-37500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-38000\n",
            "Configuration saved in ./results\\checkpoint-38000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-38000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-38000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-38000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-38500\n",
            "Configuration saved in ./results\\checkpoint-38500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-38500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-38500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-38500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-39000\n",
            "Configuration saved in ./results\\checkpoint-39000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-39000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-39000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-39000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-39500\n",
            "Configuration saved in ./results\\checkpoint-39500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-39500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-39500\\tokenizer_config.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens file saved in ./results\\checkpoint-39500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-40000\n",
            "Configuration saved in ./results\\checkpoint-40000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-40000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-40000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-40000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-40500\n",
            "Configuration saved in ./results\\checkpoint-40500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-40500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-40500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-40500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-41000\n",
            "Configuration saved in ./results\\checkpoint-41000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-41000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-41000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-41000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-41500\n",
            "Configuration saved in ./results\\checkpoint-41500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-41500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-41500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-41500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-42000\n",
            "Configuration saved in ./results\\checkpoint-42000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-42000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-42000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-42000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-42500\n",
            "Configuration saved in ./results\\checkpoint-42500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-42500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-42500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-42500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-43000\n",
            "Configuration saved in ./results\\checkpoint-43000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-43000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-43000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-43000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-43500\n",
            "Configuration saved in ./results\\checkpoint-43500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-43500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-43500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-43500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-44000\n",
            "Configuration saved in ./results\\checkpoint-44000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-44000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-44000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-44000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-44500\n",
            "Configuration saved in ./results\\checkpoint-44500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-44500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-44500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-44500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-45000\n",
            "Configuration saved in ./results\\checkpoint-45000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-45000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-45000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-45000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-45500\n",
            "Configuration saved in ./results\\checkpoint-45500\\config.json\n",
            "Model weights saved in ./results\\checkpoint-45500\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-45500\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-45500\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results\\checkpoint-46000\n",
            "Configuration saved in ./results\\checkpoint-46000\\config.json\n",
            "Model weights saved in ./results\\checkpoint-46000\\pytorch_model.bin\n",
            "tokenizer config file saved in ./results\\checkpoint-46000\\tokenizer_config.json\n",
            "Special tokens file saved in ./results\\checkpoint-46000\\special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 495\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=46200, training_loss=0.010003667248501664, metrics={'train_runtime': 25817.5585, 'train_samples_per_second': 14.316, 'train_steps_per_second': 1.789, 'total_flos': 4.829025890304e+16, 'train_loss': 0.010003667248501664, 'epoch': 100.0})"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=100,#10 is enough\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer( #CustomTrainer = custom loss, Trainer = default\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"valid\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a07891",
      "metadata": {
        "id": "e1a07891"
      },
      "outputs": [],
      "source": [
        "# NO log = requires at least 500 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eb5d428",
      "metadata": {
        "id": "7eb5d428"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "376c150c",
      "metadata": {
        "id": "376c150c",
        "outputId": "6938fa2b-1085-4598-a693-2b272e3cd6b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\npredictions, labels, _ = trainer.predict(tokenized_datasets[\"valid\"])\\npredictions = np.argmax(predictions, axis=2)\\n\\n# Remove ignored index (special tokens)\\ntrue_predictions = [\\n    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\\n    for prediction, label in zip(predictions, labels)\\n]\\ntrue_labels = [\\n    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\\n    for prediction, label in zip(predictions, labels)\\n]\\n\\nresults = metric.compute(predictions=true_predictions, references=true_labels)\\nresults'"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "predictions, labels, _ = trainer.predict(tokenized_datasets[\"valid\"])\n",
        "predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "# Remove ignored index (special tokens)\n",
        "true_predictions = [\n",
        "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "true_labels = [\n",
        "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "\n",
        "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "results'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a1922c",
      "metadata": {
        "id": "77a1922c",
        "outputId": "82c11327-33db-453d-8752-258aa05417ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to t5\n",
            "Configuration saved in t5\\config.json\n",
            "Model weights saved in t5\\pytorch_model.bin\n",
            "tokenizer config file saved in t5\\tokenizer_config.json\n",
            "Special tokens file saved in t5\\special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "#SAVE MODEL\n",
        "output_dir = \"distilBERT_fine_tuned_english\"\n",
        "trainer.save_model(output_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ce2be2",
      "metadata": {
        "id": "22ce2be2",
        "outputId": "b0d9b917-b811-470d-bff0-e68578ad03e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file C:/Users/fiori/OneDrive/Documenti/Magistrale/Erasmus_lezioni/NLP/distilBERT_fine_tuned_english/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"C:/Users/fiori/OneDrive/Documenti/Magistrale/Erasmus_lezioni/NLP/distilBERT_fine_tuned_english/\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.22.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file C:/Users/fiori/OneDrive/Documenti/Magistrale/Erasmus_lezioni/NLP/distilBERT_fine_tuned_english/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DistilBertForTokenClassification.\n",
            "\n",
            "All the weights of DistilBertForTokenClassification were initialized from the model checkpoint at C:/Users/fiori/OneDrive/Documenti/Magistrale/Erasmus_lezioni/NLP/distilBERT_fine_tuned_english/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForTokenClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "#LOAD MODEL\n",
        "import_dir = \"C:/Users/fiori/OneDrive/Documenti/Magistrale/Erasmus_lezioni/NLP/distilBERT_fine_tuned_english/\"\n",
        "model = AutoModelForTokenClassification.from_pretrained(import_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "674bf1af",
      "metadata": {
        "id": "674bf1af"
      },
      "source": [
        "### Recap: \n",
        "###### UNFROZE SOME PARAMETERS (in order to change weights), GAVE MORE IMPORTANCE TO THE UNBALANCED CLASS (custom trainer), AND ONLY USED SAMPLES WITH ANSWERS!(doesn't count much but helps) in any case the examples without answers would have been ignored because everything would haven been put to -100 so it's better to just have asnwers samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "074b5950",
      "metadata": {
        "id": "074b5950"
      },
      "source": [
        "#  (from lab 5 re adaptation)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-crf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgMzjG846Jah",
        "outputId": "effbe99a-d037-4151-e5c9-7ee4ad227c8d"
      },
      "id": "lgMzjG846Jah",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "5bba328f",
      "metadata": {
        "id": "5bba328f"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "from math import log\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import torch\n",
        "import random\n",
        "from math import log\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torchcrf import CRF\n",
        "from torch.optim.lr_scheduler import ExponentialLR, CyclicLR\n",
        "from typing import List, Tuple, AnyStr\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "from datasets import load_dataset, load_metric\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch.nn.functional as F\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "46919143",
      "metadata": {
        "id": "46919143"
      },
      "outputs": [],
      "source": [
        "datasets = data_set.rename_columns({\"text\" : \"tokens\", \"y\" :\"ner_tags\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "11e0520d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11e0520d",
        "outputId": "c8c14bd6-9663-44a9-8505-4507a511ab91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-21 09:35:45--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M   151KB/s    in 49m 44s \n",
            "\n",
            "2022-10-21 10:25:31 (223 KB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "7511d715",
      "metadata": {
        "id": "7511d715"
      },
      "outputs": [],
      "source": [
        "label_list = ['O', 'B-answ', 'I-answ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "e53afc15",
      "metadata": {
        "id": "e53afc15"
      },
      "outputs": [],
      "source": [
        "# Reduce down to our vocabulary and word embeddings\n",
        "def load_vectors(fname, vocabulary):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    tag_names = label_list#datasets[\"train\"].features[f\"ner_tags\"].feature.names\n",
        "    final_vocab = tag_names + ['[PAD]', '[UNK]', '[BOS]', '[EOS]']\n",
        "    final_vectors = [np.random.normal(size=(300,)) for _ in range(len(final_vocab))]\n",
        "    for j,line in enumerate(fin):\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        if tokens[0] in vocabulary or len(final_vocab) < 30000:\n",
        "            final_vocab.append(tokens[0])\n",
        "            final_vectors.append(np.array(list(map(float, tokens[1:]))))\n",
        "    return final_vocab, np.vstack(final_vectors)\n",
        "\n",
        "class FasttextTokenizer:\n",
        "    def __init__(self, vocabulary):\n",
        "        self.vocab = {}\n",
        "        for j,l in enumerate(vocabulary):\n",
        "            self.vocab[l.strip()] = j\n",
        "\n",
        "    def encode(self, text):\n",
        "        # Text is assumed to be tokenized\n",
        "        return [self.vocab[t] if t in self.vocab else self.vocab['[UNK]'] for t in text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "670a3f49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "670a3f49",
        "outputId": "13b5b616-89c8-4aa6-c73d-dde4fa89d99b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of vocabulary:  49102\n"
          ]
        }
      ],
      "source": [
        "vocabulary = (set([t for s in datasets['train'] for t in s['tokens']]) | set([t for s in datasets['valid'] for t in s['tokens']]))\n",
        "vocabulary, pretrained_embeddings = load_vectors('wiki-news-300d-1M.vec', vocabulary)\n",
        "print('size of vocabulary: ', len(vocabulary))\n",
        "tokenizer = FasttextTokenizer(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "ca63f8cf",
      "metadata": {
        "id": "ca63f8cf"
      },
      "outputs": [],
      "source": [
        "def collate_batch_bilstm(input_data: Tuple) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    input_ids = [tokenizer.encode(i['tokens']) for i in input_data]\n",
        "    seq_lens = [len(i) for i in input_ids]\n",
        "    labels = [i['ner_tags'] for i in input_data]\n",
        "\n",
        "    max_length = max([len(i) for i in input_ids])\n",
        "\n",
        "    input_ids = [(i + [0] * (max_length - len(i))) for i in input_ids]\n",
        "    labels = [(i + [0] * (max_length - len(i))) for i in labels] # 0 is the id of the O tag\n",
        "\n",
        "    assert (all(len(i) == max_length for i in input_ids))\n",
        "    assert (all(len(i) == max_length for i in labels))\n",
        "    return torch.tensor(input_ids), torch.tensor(seq_lens), torch.tensor(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "a6de0192",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6de0192",
        "outputId": "c7feda91-fae9-4140-9a9f-c53f35b7b2df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  372,    20,    14,   126,    12,  1033,    61,  7591,  7753,  1696,\n",
              "             44, 37329,   599,  7222,    10,  9072,  7591,  7753,   925,  5966,\n",
              "             10,  1303,    33, 48278,    28,  3997,     9, 30247,    22,   209,\n",
              "           1807,    31,   440,     7,    26,    89,  1397,    33,     8, 23505,\n",
              "            118,  1619,    12,  2271,  5813, 21915,   119,    25,  7591,     7,\n",
              "          44659,     7,    10, 38910,  5813,    10,  6516,  1095,   599,     9]]),\n",
              " tensor([60]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2,\n",
              "          2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "dev_dl = DataLoader(datasets['valid'], batch_size=1, shuffle=False, collate_fn=collate_batch_bilstm, num_workers=0)\n",
        "next(iter(dev_dl))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "b7c32d74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7c32d74",
        "outputId": "1d65d8a9-2813-4b89-e3da-41886f27e6f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': ['What', 'is', 'a', 'way', 'to', 'increase', 'your', 'wound', 'healing', 'speed', '?', 'Wound', 'care', 'encourages', 'and', 'speeds', 'wound', 'healing', 'via', 'cleaning', 'and', 'protection', 'from', 'reinjury', 'or', 'infection', '.', 'Depending', 'on', 'each', 'patient', \"'s\", 'needs', ',', 'it', 'can', 'range', 'from', 'the', 'simplest', 'first', 'aid', 'to', 'entire', 'nursing', 'specialties', 'such', 'as', 'wound', ',', 'ostomy', ',', 'and', 'continence', 'nursing', 'and', 'burn', 'center', 'care', '.'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
            "(tensor([[  372,    20,    14,   126,    12,  1033,    61,  7591,  7753,  1696,\n",
            "            44, 37329,   599,  7222,    10,  9072,  7591,  7753,   925,  5966,\n",
            "            10,  1303,    33, 48278,    28,  3997,     9, 30247,    22,   209,\n",
            "          1807,    31,   440,     7,    26,    89,  1397,    33,     8, 23505,\n",
            "           118,  1619,    12,  2271,  5813, 21915,   119,    25,  7591,     7,\n",
            "         44659,     7,    10, 38910,  5813,    10,  6516,  1095,   599,     9]]), tensor([60]), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2,\n",
            "         2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))\n"
          ]
        }
      ],
      "source": [
        "print(datasets['valid'][0])\n",
        "print(collate_batch_bilstm([datasets['valid'][0]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BI-LSTM"
      ],
      "metadata": {
        "id": "UifNg5ik5uJR"
      },
      "id": "UifNg5ik5uJR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic BiLSTM-CRF network\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            pretrained_embeddings: torch.tensor,\n",
        "            lstm_dim: int,\n",
        "            dropout_prob: float = 0.1,\n",
        "            n_classes: int = 2\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializer for basic BiLSTM network\n",
        "        :param pretrained_embeddings: A tensor containing the pretrained BPE embeddings\n",
        "        :param lstm_dim: The dimensionality of the BiLSTM network\n",
        "        :param dropout_prob: Dropout probability\n",
        "        :param n_classes: The number of output classes\n",
        "        \"\"\"\n",
        "\n",
        "        # First thing is to call the superclass initializer\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "\n",
        "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
        "        # The components are an embedding layer, a 2 layer BiLSTM, and a feed-forward output layer\n",
        "        self.model = nn.ModuleDict({\n",
        "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
        "            'bilstm': nn.LSTM(\n",
        "                pretrained_embeddings.shape[1],\n",
        "                lstm_dim,\n",
        "                2,\n",
        "                batch_first=True,\n",
        "                dropout=dropout_prob,\n",
        "                bidirectional=True),\n",
        "            'ff': nn.Linear(2*lstm_dim, n_classes),\n",
        "            'CRF': CRF(n_classes, batch_first=True)\n",
        "        })\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # Initialize the weights of the model\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        all_params = list(self.model['bilstm'].named_parameters()) + \\\n",
        "                     list(self.model['ff'].named_parameters())\n",
        "        for n,p in all_params:\n",
        "            if 'weight' in n:\n",
        "                nn.init.xavier_normal_(p)\n",
        "            elif 'bias' in n:\n",
        "                nn.init.zeros_(p)\n",
        "\n",
        "    def forward(self, inputs, input_lens, labels = None):\n",
        "        \"\"\"\n",
        "        Defines how tensors flow through the model\n",
        "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
        "        :param input_lens: (b) The length of each input sequence\n",
        "        :param labels: (b) The label of each sample\n",
        "        :return: (loss, logits) if `labels` is not None, otherwise just (logits,)\n",
        "        \"\"\"\n",
        "\n",
        "        # Get embeddings (b x sl x edim)\n",
        "        embeds = self.model['embeddings'](inputs)\n",
        "\n",
        "        # Pack padded: This is necessary for padded batches input to an RNN\n",
        "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
        "            embeds,\n",
        "            input_lens.cpu(),\n",
        "            batch_first=True,\n",
        "            enforce_sorted=False\n",
        "        )\n",
        "\n",
        "        # Pass the packed sequence through the BiLSTM\n",
        "        lstm_out, hidden = self.model['bilstm'](lstm_in)\n",
        "\n",
        "        # Unpack the packed sequence --> (b x sl x 2*lstm_dim)\n",
        "        lstm_out,_ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
        "\n",
        "        # Get emissions (b x seq_len x n_classes)\n",
        "        emissions = self.model['ff'](lstm_out)\n",
        "        outputs = (emissions,)\n",
        "        if labels is not None:\n",
        "            mask = (inputs != 0)\n",
        "            # log-likelihood from the CRF\n",
        "            log_likelihood = self.model['CRF'](emissions, labels, mask=mask, reduction='token_mean')\n",
        "            outputs = (-log_likelihood,) + outputs\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def decode(self, emissions, mask):\n",
        "        \"\"\"\n",
        "        Given a set of emissions and a mask, decode the sequence\n",
        "        \"\"\"\n",
        "        return self.model['CRF'].decode(emissions, mask=mask)"
      ],
      "metadata": {
        "id": "5EvWEuXd5wLx"
      },
      "id": "5EvWEuXd5wLx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(\n",
        "    model: nn.Module, \n",
        "    train_dl: DataLoader, \n",
        "    valid_dl: DataLoader, \n",
        "    optimizer: torch.optim.Optimizer, \n",
        "    n_epochs: int, \n",
        "    device: torch.device,\n",
        "    scheduler=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    The main training loop which will optimize a given model on a given dataset\n",
        "    :param model: The model being optimized\n",
        "    :param train_dl: The training dataset\n",
        "    :param valid_dl: A validation dataset\n",
        "    :param optimizer: The optimizer used to update the model parameters\n",
        "    :param n_epochs: Number of epochs to train for\n",
        "    :param device: The device to train on\n",
        "    :return: (model, losses) The best model and the losses per iteration\n",
        "    \"\"\"\n",
        "\n",
        "    # Keep track of the loss and best accuracy\n",
        "    losses = []\n",
        "    learning_rates = []\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    # Iterate through epochs\n",
        "    for ep in range(n_epochs):\n",
        "\n",
        "        loss_epoch = []\n",
        "\n",
        "        #Iterate through each batch in the dataloader\n",
        "        for batch in tqdm(train_dl):\n",
        "            # VERY IMPORTANT: Make sure the model is in training mode, which turns on \n",
        "            # things like dropout and layer normalization\n",
        "            model.train()\n",
        "\n",
        "            # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n",
        "            # keeps track of these dynamically in its computation graph so you need to explicitly\n",
        "            # zero them out\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Place each tensor on the GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids = batch[0]\n",
        "            seq_lens = batch[1]\n",
        "            labels = batch[2]\n",
        "\n",
        "            # Pass the inputs through the model, get the current loss and logits\n",
        "            loss, logits = model(input_ids, seq_lens, labels=labels)\n",
        "            losses.append(loss.item())\n",
        "            loss_epoch.append(loss.item())\n",
        "\n",
        "            # Calculate all of the gradients and weight updates for the model\n",
        "            loss.backward()\n",
        "\n",
        "            # Optional: clip gradients\n",
        "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Finally, update the weights of the model\n",
        "            optimizer.step()\n",
        "            if scheduler != None:\n",
        "                scheduler.step()\n",
        "                learning_rates.append(scheduler.get_last_lr()[0])\n",
        "\n",
        "        #gc.collect()\n",
        "\n",
        "        # Perform inline evaluation at the end of the epoch\n",
        "        f1 = evaluate(model, valid_dl)\n",
        "        print(f'Validation F1: {f1}, train loss: {sum(loss_epoch) / len(loss_epoch)}')\n",
        "\n",
        "        # Keep track of the best model based on the accuracy\n",
        "        if f1 > best_f1:\n",
        "            torch.save(model.state_dict(), 'best_model')\n",
        "            best_f1 = f1\n",
        "            #gc.collect()\n",
        "\n",
        "    return losses, learning_rates"
      ],
      "metadata": {
        "id": "WLs9ay5_5xNB"
      },
      "id": "WLs9ay5_5xNB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model: nn.Module, valid_dl: DataLoader):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the given dataset\n",
        "    :param model: The model under evaluation\n",
        "    :param valid_dl: A `DataLoader` reading validation data\n",
        "    :return: The accuracy of the model on the dataset\n",
        "    \"\"\"\n",
        "    # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like \n",
        "    # layer normalization and dropout\n",
        "    model.eval()\n",
        "    labels_all = []\n",
        "    logits_all = []\n",
        "    tags_all = []\n",
        "\n",
        "    # ALSO IMPORTANT: Don't accumulate gradients during this process\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(valid_dl, desc='Evaluation'):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids = batch[0]\n",
        "            seq_lens = batch[1]\n",
        "            labels = batch[2]\n",
        "\n",
        "            logits = model(input_ids, seq_lens, labels=labels)[-1]\n",
        "            mask = (input_ids != 0)\n",
        "            labels_all.extend([l for seq,samp in zip(list(labels.detach().cpu().numpy()), input_ids) for l,i in zip(seq,samp) if i != 0])\n",
        "            logits_all.extend(list(logits.detach().cpu().numpy()))\n",
        "\n",
        "            tags = model.decode(logits, mask)\n",
        "            tags_all.extend([t for seq in tags for t in seq])\n",
        "\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, tags_all, average='macro')\n",
        "    print(confusion_matrix(labels_all, tags_all))\n",
        "    return F1"
      ],
      "metadata": {
        "id": "kcTYX_Mi5xPn"
      },
      "id": "kcTYX_Mi5xPn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_dim = 256\n",
        "dropout_prob = 0.1\n",
        "batch_size = 8\n",
        "lr = 1e-2\n",
        "n_epochs = 15\n",
        "n_workers = 0\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "# Create the model\n",
        "model = BiLSTM_CRF(\n",
        "    pretrained_embeddings=torch.FloatTensor(pretrained_embeddings), \n",
        "    lstm_dim=lstm_dim, \n",
        "    dropout_prob=dropout_prob, \n",
        "    n_classes=len(label_list)\n",
        "  ).to(device)"
      ],
      "metadata": {
        "id": "kPsWri-95xS1"
      },
      "id": "kPsWri-95xS1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(datasets['train'], batch_size=batch_size, shuffle=True, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "valid_dl = DataLoader(datasets['valid'], batch_size=len(datasets['valid']), collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "scheduler = CyclicLR(optimizer, base_lr=0., max_lr=lr, step_size_up=1, step_size_down=len(train_dl)*n_epochs, cycle_momentum=False)\n",
        "\n",
        "# Train\n",
        "losses, learning_rates = train(model, train_dl, valid_dl, optimizer, n_epochs, device, scheduler)\n",
        "model.load_state_dict(torch.load('best_model'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pbw9gNZA5xVE",
        "outputId": "ad82c128-bf7f-4759-93f3-8f1b80a0cd81"
      },
      "id": "Pbw9gNZA5xVE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:37<00:00,  4.72it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61885     1     2]\n",
            " [  472     6     0]\n",
            " [ 1984     0    13]]\n",
            "Validation F1: 0.3393947550705789, train loss: 0.10575308462854846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:35<00:00,  4.85it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.29s/it]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61888     0     0]\n",
            " [  478     0     0]\n",
            " [ 1997     0     0]]\n",
            "Validation F1: 0.32679873162720824, train loss: 0.04708289933185299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:37<00:00,  4.72it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61497   115   276]\n",
            " [  368   106     4]\n",
            " [ 1819     5   173]]\n",
            "Validation F1: 0.47394359965384664, train loss: 0.0370161822106028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:36<00:00,  4.77it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.78s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61682    66   140]\n",
            " [  369   101     8]\n",
            " [ 1793     4   200]]\n",
            "Validation F1: 0.4876633523760845, train loss: 0.03042753121222962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:37<00:00,  4.76it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.22s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61512   101   275]\n",
            " [  339   128    11]\n",
            " [ 1670    10   317]]\n",
            "Validation F1: 0.5272905385688317, train loss: 0.024530940819168828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:37<00:00,  4.72it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.42s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61796    51    41]\n",
            " [  382    92     4]\n",
            " [ 1880     4   113]]\n",
            "Validation F1: 0.46019394662432145, train loss: 0.017715494260312867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:36<00:00,  4.77it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61552   115   221]\n",
            " [  334   124    20]\n",
            " [ 1632    11   354]]\n",
            "Validation F1: 0.5318170367749335, train loss: 0.012739762858370746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:37<00:00,  4.72it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61350   165   373]\n",
            " [  328   133    17]\n",
            " [ 1649    12   336]]\n",
            "Validation F1: 0.5214215437155304, train loss: 0.0089521106366306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:37<00:00,  4.73it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61445   120   323]\n",
            " [  336   123    19]\n",
            " [ 1647     7   343]]\n",
            "Validation F1: 0.5247774322728677, train loss: 0.00618334507497352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:37<00:00,  4.72it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61248   148   492]\n",
            " [  323   130    25]\n",
            " [ 1521    12   464]]\n",
            "Validation F1: 0.5434283408560056, train loss: 0.004410085100310177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:36<00:00,  4.77it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61613   108   167]\n",
            " [  340   127    11]\n",
            " [ 1736     9   252]]\n",
            "Validation F1: 0.5135809184276064, train loss: 0.0031070635068553873\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:39<00:00,  4.66it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61712    95    81]\n",
            " [  352   123     3]\n",
            " [ 1785    10   202]]\n",
            "Validation F1: 0.5023355088717627, train loss: 0.0021830771801397567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:37<00:00,  4.73it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61310   123   455]\n",
            " [  336   119    23]\n",
            " [ 1615     7   375]]\n",
            "Validation F1: 0.5234409157849808, train loss: 0.0017830669816823533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:36<00:00,  4.77it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.34s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61349   150   389]\n",
            " [  321   136    21]\n",
            " [ 1601    19   377]]\n",
            "Validation F1: 0.5328507364260587, train loss: 0.0013299105194558162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [01:39<00:00,  4.64it/s]\n",
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61266   132   490]\n",
            " [  330   120    28]\n",
            " [ 1503    15   479]]\n",
            "Validation F1: 0.5408262960424609, train loss: 0.0013062111120234476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dl = DataLoader(datasets['valid'], batch_size=len(datasets['valid']), collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "\n",
        "evaluate(model, test_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8ELd6885xXr",
        "outputId": "1a7f261f-c595-459c-d879-114a8fa0fd9e"
      },
      "id": "m8ELd6885xXr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|██████████| 1/1 [00:08<00:00,  8.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61248   148   492]\n",
            " [  323   130    25]\n",
            " [ 1521    12   464]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5434283408560056"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b_per_id = 1# B-Answ\n",
        "transitions = model.model[\"CRF\"].transitions[b_per_id].detach().to(\"cpu\")\n",
        "transitions = torch.softmax(transitions, 0).numpy()\n",
        "for idx, tag in enumerate(label_list):\n",
        "    print(f\"{tag}: {transitions[idx]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9hA9Tjq5xaT",
        "outputId": "a6a9a9fb-14ae-47de-dba5-b0b646c2e8e6"
      },
      "id": "k9hA9Tjq5xaT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O: 0.020979195833206177\n",
            "B-answ: 0.07828322798013687\n",
            "I-answ: 0.9007375836372375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dan5qiUX5xdA"
      },
      "id": "Dan5qiUX5xdA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-N9fiXJt5xfP"
      },
      "id": "-N9fiXJt5xfP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ENC-DEC, beam search"
      ],
      "metadata": {
        "id": "ecI8F93j5pSg"
      },
      "id": "ecI8F93j5pSg"
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "b7c9d00d",
      "metadata": {
        "id": "b7c9d00d"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    RNN Encoder model.\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "            pretrained_embeddings: torch.tensor, \n",
        "            lstm_dim: int,\n",
        "            dropout_prob: float = 0.1):\n",
        "        \"\"\"\n",
        "        Initializer for EncoderRNN network\n",
        "        :param pretrained_embeddings: A tensor containing the pretrained embeddings\n",
        "        :param lstm_dim: The dimensionality of the LSTM network\n",
        "        :param dropout_prob: Dropout probability\n",
        "        \"\"\"\n",
        "        # First thing is to call the superclass initializer\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
        "        # The components are an embedding layer, and an LSTM layer.\n",
        "        self.model = nn.ModuleDict({\n",
        "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
        "            'lstm': nn.LSTM(pretrained_embeddings.shape[1], lstm_dim, 2, batch_first=True, bidirectional=True),\n",
        "        })\n",
        "        # Initialize the weights of the model\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        all_params = list(self.model['lstm'].named_parameters())\n",
        "        for n, p in all_params:\n",
        "            if 'weight' in n:\n",
        "                nn.init.xavier_normal_(p)\n",
        "            elif 'bias' in n:\n",
        "                nn.init.zeros_(p)\n",
        "\n",
        "    def forward(self, inputs, input_lens):\n",
        "        \"\"\"\n",
        "        Defines how tensors flow through the model\n",
        "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
        "        :param input_lens: (b) The length of each input sequence\n",
        "        :return: (lstm output state, lstm hidden state) \n",
        "        \"\"\"\n",
        "        embeds = self.model['embeddings'](inputs)\n",
        "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
        "                    embeds,\n",
        "                    input_lens.cpu(),\n",
        "                    batch_first=True,\n",
        "                    enforce_sorted=False\n",
        "                )\n",
        "        lstm_out, hidden_states = self.model['lstm'](lstm_in)\n",
        "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
        "        return lstm_out, hidden_states\n",
        "\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    RNN Decoder model.\n",
        "    \"\"\"\n",
        "    def __init__(self, pretrained_embeddings: torch.tensor, \n",
        "            lstm_dim: int,\n",
        "            dropout_prob: float = 0.1,\n",
        "            n_classes: int = 2):\n",
        "        \"\"\"\n",
        "        Initializer for DecoderRNN network\n",
        "        :param pretrained_embeddings: A tensor containing the pretrained embeddings\n",
        "        :param lstm_dim: The dimensionality of the LSTM network\n",
        "        :param dropout_prob: Dropout probability\n",
        "        :param n_classes: Number of prediction classes\n",
        "        \"\"\"\n",
        "        # First thing is to call the superclass initializer\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
        "        # The components are an embedding layer, a LSTM layer, and a feed-forward output layer\n",
        "        self.model = nn.ModuleDict({\n",
        "            'embeddings': nn.Embedding.from_pretrained(pretrained_embeddings, padding_idx=pretrained_embeddings.shape[0] - 1),\n",
        "            'lstm': nn.LSTM(pretrained_embeddings.shape[1], lstm_dim, 2, bidirectional=True, batch_first=True),\n",
        "            'nn': nn.Linear(lstm_dim*2, n_classes),\n",
        "        })\n",
        "        # Initialize the weights of the model\n",
        "        self._init_weights()      \n",
        "\n",
        "    def forward(self, inputs, hidden, input_lens):\n",
        "        \"\"\"\n",
        "        Defines how tensors flow through the model\n",
        "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
        "        :param hidden: (b) The hidden state of the previous step\n",
        "        :param input_lens: (b) The length of each input sequence\n",
        "        :return: (output predictions, lstm hidden states) the hidden states will be used as input at the next step\n",
        "        \"\"\"\n",
        "        embeds = self.model['embeddings'](inputs)\n",
        "\n",
        "        lstm_in = nn.utils.rnn.pack_padded_sequence(\n",
        "                    embeds,\n",
        "                    input_lens.cpu(),\n",
        "                    batch_first=True,\n",
        "                    enforce_sorted=False\n",
        "                )\n",
        "        lstm_out, hidden_states = self.model['lstm'](lstm_in, hidden)\n",
        "        lstm_out, _ = nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=True)\n",
        "        output = self.model['nn'](lstm_out)\n",
        "        return output, hidden_states\n",
        "\n",
        "    def _init_weights(self):\n",
        "        all_params = list(self.model['lstm'].named_parameters()) + list(self.model['nn'].named_parameters())\n",
        "        for n, p in all_params:\n",
        "            if 'weight' in n:\n",
        "                nn.init.xavier_normal_(p)\n",
        "            elif 'bias' in n:\n",
        "                nn.init.zeros_(p)\n",
        "\n",
        "# Define the model\n",
        "class Seq2Seq(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic Seq2Seq network\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            pretrained_embeddings: torch.tensor,\n",
        "            lstm_dim: int,\n",
        "            dropout_prob: float = 0.1,\n",
        "            n_classes: int = 2\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializer for basic Seq2Seq network\n",
        "        :param pretrained_embeddings: A tensor containing the pretrained embeddings\n",
        "        :param lstm_dim: The dimensionality of the LSTM network\n",
        "        :param dropout_prob: Dropout probability\n",
        "        :param n_classes: The number of output classes\n",
        "        \"\"\"\n",
        "\n",
        "        # First thing is to call the superclass initializer\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        # We'll define the network in a ModuleDict, which consists of an encoder and a decoder\n",
        "        self.model = nn.ModuleDict({\n",
        "            'encoder': EncoderRNN(pretrained_embeddings, lstm_dim, dropout_prob),\n",
        "            'decoder': DecoderRNN( pretrained_embeddings, lstm_dim, dropout_prob, n_classes),\n",
        "        })\n",
        "        #weighted loss\n",
        "        self.loss = nn.CrossEntropyLoss(weight=torch.tensor([1-count_0/total_classes, 1-count_1/total_classes, 1-count_2/total_classes]).to(device))#0.9,30.28\n",
        "\n",
        "\n",
        "    def forward(self, inputs, input_lens, labels=None):\n",
        "        \"\"\"\n",
        "        Defines how tensors flow through the model. \n",
        "        For the Seq2Seq model this includes 1) encoding the whole input text, \n",
        "        and running *target_length* decoding steps to predict the tag of each token.\n",
        "\n",
        "        :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
        "        :param input_lens: (b) The length of each input sequence\n",
        "        :param labels: (b) The label of each sample\n",
        "        :return: (loss, logits) if `labels` is not None, otherwise just (logits,)\n",
        "        \"\"\"\n",
        "\n",
        "        # Get embeddings (b x sl x embedding dim)\n",
        "        encoder_output, encoder_hidden = self.model['encoder'](inputs, input_lens)\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_input = torch.tensor([tokenizer.encode(['[BOS]'])]*inputs.shape[0], device=device)\n",
        "        target_length = labels.size(1)\n",
        "\n",
        "        loss = None\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = self.model['decoder'](\n",
        "                decoder_input, decoder_hidden, torch.tensor([1]*inputs.shape[0]))\n",
        "\n",
        "            if loss == None:   \n",
        "                loss = self.loss(decoder_output.squeeze(1), labels[:, di])\n",
        "            else:\n",
        "                loss += self.loss(decoder_output.squeeze(1), labels[:, di])\n",
        "            # Teacher forcing: Feed the target as the next input\n",
        "            decoder_input = labels[:, di].unsqueeze(-1) \n",
        "\n",
        "        return loss / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "id": "c0dcf8e0",
      "metadata": {
        "id": "c0dcf8e0"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    model: nn.Module, \n",
        "    train_dl: DataLoader, \n",
        "    valid_dl: DataLoader, \n",
        "    optimizer: torch.optim.Optimizer, \n",
        "    n_epochs: int, \n",
        "    device: torch.device,\n",
        "):\n",
        "    \"\"\"\n",
        "    The main training loop which will optimize a given model on a given dataset\n",
        "    :param model: The model being optimized\n",
        "    :param train_dl: The training dataset\n",
        "    :param valid_dl: A validation dataset\n",
        "    :param optimizer: The optimizer used to update the model parameters\n",
        "    :param n_epochs: Number of epochs to train for\n",
        "    :param device: The device to train on\n",
        "    :return: (model, losses) The best model and the losses per iteration\n",
        "    \"\"\"\n",
        "\n",
        "    # Keep track of the loss and best accuracy\n",
        "    losses = []\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    # Iterate through epochs\n",
        "    for ep in range(n_epochs):\n",
        "\n",
        "        loss_epoch = []\n",
        "\n",
        "        #Iterate through each batch in the dataloader\n",
        "        for batch in tqdm(train_dl):\n",
        "            # VERY IMPORTANT: Make sure the model is in training mode, which turns on \n",
        "            # things like dropout and layer normalization\n",
        "            model.train()\n",
        "\n",
        "            # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n",
        "            # keeps track of these dynamically in its computation graph so you need to explicitly\n",
        "            # zero them out\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Place each tensor on the GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids = batch[0]\n",
        "            labels = batch[2]\n",
        "            input_lens = batch[1]\n",
        "\n",
        "            # Pass the inputs through the model, get the current loss and logits\n",
        "            loss = model(input_ids, labels=labels, input_lens=input_lens)\n",
        "            losses.append(loss.item())\n",
        "            #print(\"loss item:\")\n",
        "            #print(loss.item())\n",
        "            loss_epoch.append(loss.item())\n",
        "\n",
        "            # Calculate all of the gradients and weight updates for the model\n",
        "            loss.backward()\n",
        "\n",
        "            # Optional: clip gradients\n",
        "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Finally, update the weights of the model\n",
        "            optimizer.step()\n",
        "\n",
        "        # Perform inline evaluation at the end of the epoch\n",
        "        f1 = evaluate(model, valid_dl)\n",
        "        print(f'Validation F1: {f1}, train loss: {sum(loss_epoch) / len(loss_epoch)}')\n",
        "\n",
        "        # Keep track of the best model based on the accuracy\n",
        "        if f1 > best_f1:\n",
        "            torch.save(model.state_dict(), 'best_model')\n",
        "            best_f1 = f1\n",
        "\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "id": "d388897c",
      "metadata": {
        "id": "d388897c"
      },
      "outputs": [],
      "source": [
        "softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "def decode(model, inputs, input_lens, labels=None, beam_size=2):\n",
        "    \"\"\"\n",
        "    Decoding/predicting the labels for an input text by running beam search.\n",
        "\n",
        "    :param inputs: (b x sl) The IDs into the vocabulary of the input samples\n",
        "    :param input_lens: (b) The length of each input sequence\n",
        "    :param labels: (b) The label of each sample\n",
        "    :param beam_size: the size of the beam \n",
        "    :return: predicted sequence of labels\n",
        "    \"\"\"\n",
        "\n",
        "    assert inputs.shape[0] == 1\n",
        "    # first, encode the input text\n",
        "    encoder_output, encoder_hidden = model.model['encoder'](inputs, input_lens)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # the decoder starts generating after the Begining of Sentence (BOS) token\n",
        "    decoder_input = torch.tensor([tokenizer.encode(['[BOS]',]),], device=device)\n",
        "    target_length = labels.shape[1]\n",
        "    \n",
        "    # we will use heapq to keep top best sequences so far sorted in heap_queue \n",
        "    # these will be sorted by the first item in the tuple\n",
        "    heap_queue = []\n",
        "    heap_queue.append((torch.tensor(0), tokenizer.encode(['[BOS]']), decoder_input, decoder_hidden))\n",
        "\n",
        "    # Beam Decoding\n",
        "    for _ in range(target_length):\n",
        "        # print(\"next len\")\n",
        "        new_items = []\n",
        "        # for each item on the beam\n",
        "        for j in range(len(heap_queue)): \n",
        "            # 1. remove from heap\n",
        "            score, tokens, decoder_input, decoder_hidden = heapq.heappop(heap_queue)\n",
        "            # 2. decode one more step\n",
        "            decoder_output, decoder_hidden = model.model['decoder'](\n",
        "                decoder_input, decoder_hidden, torch.tensor([1]))\n",
        "            decoder_output = softmax(decoder_output)\n",
        "            # 3. get top-k predictions\n",
        "            best_idx = torch.argsort(decoder_output[0], descending=True)[0]\n",
        "            # print(decoder_output)\n",
        "            # print(best_idx)\n",
        "            for i in range(beam_size):\n",
        "                decoder_input = torch.tensor([[best_idx[i]]], device=device)\n",
        "                \n",
        "                new_items.append((score + decoder_output[0,0, best_idx[i]],\n",
        "                                  tokens + [best_idx[i].item()], \n",
        "                                  decoder_input, \n",
        "                                  decoder_hidden))\n",
        "        # add new sequences to the heap\n",
        "        for item in new_items:\n",
        "          # print(item)\n",
        "            heapq.heappush(heap_queue, item)\n",
        "        # remove sequences with lowest score (items are sorted in descending order)\n",
        "        while len(heap_queue) > beam_size:\n",
        "            heapq.heappop(heap_queue)\n",
        "          \n",
        "    final_sequence = heapq.nlargest(1, heap_queue)[0]\n",
        "    assert labels.shape[1] == len(final_sequence[1][1:])\n",
        "    return final_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "6508e361",
      "metadata": {
        "id": "6508e361"
      },
      "outputs": [],
      "source": [
        "def evaluate(model: nn.Module, valid_dl: DataLoader, beam_size:int = 1):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the given dataset\n",
        "    :param model: The model under evaluation\n",
        "    :param valid_dl: A `DataLoader` reading validation data\n",
        "    :return: The accuracy of the model on the dataset\n",
        "    \"\"\"\n",
        "    # VERY IMPORTANT: Put your model in \"eval\" mode -- this disables things like \n",
        "    # layer normalization and dropout\n",
        "    model.eval()\n",
        "    labels_all = []\n",
        "    logits_all = []\n",
        "    tags_all = []\n",
        "\n",
        "    # ALSO IMPORTANT: Don't accumulate gradients during this process\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(valid_dl, desc='Evaluation'):\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids = batch[0]\n",
        "            input_lens = batch[1]\n",
        "            labels = batch[2]\n",
        "\n",
        "            best_seq = decode(model, input_ids, input_lens, labels=labels, beam_size=beam_size)\n",
        "            mask = (input_ids != 0)\n",
        "            labels_all.extend([l for seq,samp in zip(list(labels.detach().cpu().numpy()), input_ids) for l,i in zip(seq,samp) if i != 0])\n",
        "            tags_all += best_seq[1][1:]\n",
        "            # print(best_seq[1][1:], labels)\n",
        "    P, R, F1, _ = precision_recall_fscore_support(labels_all, tags_all, average='macro')\n",
        "    print(confusion_matrix(labels_all, tags_all))\n",
        "    return F1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "id": "01200c5c",
      "metadata": {
        "id": "01200c5c"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "id": "2678eaaa",
      "metadata": {
        "id": "2678eaaa"
      },
      "outputs": [],
      "source": [
        "lstm_dim = 200\n",
        "dropout_prob = 0.1\n",
        "batch_size = 64\n",
        "lr = 1e-3\n",
        "n_epochs = 15\n",
        "n_workers = 0\n",
        "\n",
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "# Create the model\n",
        "model = Seq2Seq(\n",
        "    pretrained_embeddings=torch.FloatTensor(pretrained_embeddings), \n",
        "    lstm_dim=lstm_dim, \n",
        "    dropout_prob=dropout_prob, \n",
        "    n_classes=len(label_list)\n",
        "  ).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a739db29",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a739db29",
        "outputId": "5665fe2d-a291-464c-9596-69f34af72e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58/58 [01:26<00:00,  1.50s/it]\n",
            "Evaluation: 100%|██████████| 495/495 [01:02<00:00,  7.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 4619   466 56803]\n",
            " [   36    14   428]\n",
            " [   16    15  1966]]\n",
            "Validation F1: 0.07727526548790849, train loss: 0.15309507553947382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58/58 [01:17<00:00,  1.33s/it]\n",
            "Evaluation: 100%|██████████| 495/495 [01:04<00:00,  7.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[60506     3  1379]\n",
            " [  475     0     3]\n",
            " [ 1997     0     0]]\n",
            "Validation F1: 0.32304497087544515, train loss: 0.06307490164381933\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58/58 [01:18<00:00,  1.36s/it]\n",
            "Evaluation: 100%|██████████| 495/495 [01:03<00:00,  7.74it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61888     0     0]\n",
            " [  478     0     0]\n",
            " [ 1997     0     0]]\n",
            "Validation F1: 0.32679873162720824, train loss: 0.059407547100222315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58/58 [01:16<00:00,  1.33s/it]\n",
            "Evaluation: 100%|██████████| 495/495 [01:03<00:00,  7.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61879     1     8]\n",
            " [  477     0     1]\n",
            " [ 1996     0     1]]\n",
            "Validation F1: 0.3271118496542204, train loss: 0.06010429288967159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58/58 [01:17<00:00,  1.33s/it]\n",
            "Evaluation: 100%|██████████| 495/495 [01:04<00:00,  7.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[56173   123  5592]\n",
            " [  394     4    80]\n",
            " [ 1562    13   422]]\n",
            "Validation F1: 0.35111415775272947, train loss: 0.05992004056942874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58/58 [01:18<00:00,  1.35s/it]\n",
            "Evaluation: 100%|██████████| 495/495 [01:03<00:00,  7.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61190    24   674]\n",
            " [  456     2    20]\n",
            " [ 1928     0    69]]\n",
            "Validation F1: 0.34445710031385374, train loss: 0.057459068580948076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 58/58 [01:18<00:00,  1.35s/it]\n",
            "Evaluation:  45%|████▌     | 225/495 [00:29<00:32,  8.26it/s]"
          ]
        }
      ],
      "source": [
        "train_dl = DataLoader(datasets['train'], batch_size=batch_size, shuffle=True, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "valid_dl = DataLoader(datasets['valid'], batch_size=1, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Train\n",
        "losses = train(model, train_dl, valid_dl, optimizer, n_epochs, device)\n",
        "model.load_state_dict(torch.load('best_model')), # with weighted loss the predictions change, not stuck on O"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  pass"
      ],
      "metadata": {
        "id": "UlY-Tj_slohC"
      },
      "id": "UlY-Tj_slohC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f874fc0",
      "metadata": {
        "id": "2f874fc0"
      },
      "outputs": [],
      "source": [
        "test_dl = DataLoader(datasets['valid'], batch_size=1, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "evaluate(model, test_dl, beam_size=3)#with beam = 1 we have 35%, = greedy search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dl = DataLoader(datasets['valid'], batch_size=1, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "evaluate(model, test_dl, beam_size=2)#with beam = 1 we have 35%, = greedy search"
      ],
      "metadata": {
        "id": "dGu2mkrZpzZD"
      },
      "id": "dGu2mkrZpzZD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dl = DataLoader(datasets['valid'], batch_size=1, collate_fn=collate_batch_bilstm, num_workers=n_workers)\n",
        "evaluate(model, test_dl, beam_size=1)#with beam = 1 we have 35%, = greedy search"
      ],
      "metadata": {
        "id": "lrPHcJN5hqZT"
      },
      "id": "lrPHcJN5hqZT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VHx27B_jHf8j"
      },
      "id": "VHx27B_jHf8j",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8b566f53",
        "308fbfe2",
        "86b7f9b2",
        "4fa41cd2",
        "cd589a20",
        "fb45dc31",
        "e61f8e79",
        "80262d96",
        "e7288cdc",
        "a6c2ace1",
        "b8b29397",
        "65fe9f7c",
        "8fc0d360",
        "bc950665",
        "76123b01",
        "5b3e1516",
        "6b70fa9b",
        "9f4b3526",
        "d1a1d740",
        "319bbf0d",
        "468538c6",
        "133ba7a9",
        "3267a917",
        "954d80cc",
        "a5479b7a",
        "4f3a922c",
        "3241bcdd",
        "758d1d53",
        "2856b117",
        "82d811f1",
        "e9da4a87",
        "674bf1af"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "421eb18ce5324f9495b12d4ead63dc73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_079b3785028f4192b1152945cfc7bf80",
              "IPY_MODEL_6d54fdb21025444e9988b798021a8a81",
              "IPY_MODEL_ff1761b9fc724c559c727fe1e2e66472"
            ],
            "layout": "IPY_MODEL_fc6ee39b163e4ca58cfcfa4e4df32a97"
          }
        },
        "079b3785028f4192b1152945cfc7bf80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_103984cc86d24e87a0914193799ebc2e",
            "placeholder": "​",
            "style": "IPY_MODEL_b0d90372214b421db7e0fb8d5d760671",
            "value": "Downloading: 100%"
          }
        },
        "6d54fdb21025444e9988b798021a8a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a095227a92b641eb9c11fe3f15e79fcf",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3142e6758c44046ae4e9d11eee43c26",
            "value": 28
          }
        },
        "ff1761b9fc724c559c727fe1e2e66472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c702917a63f44df19a66da3e3c5a2c99",
            "placeholder": "​",
            "style": "IPY_MODEL_2078d21c739f4bd5976c290d16dcefd8",
            "value": " 28.0/28.0 [00:00&lt;00:00, 827B/s]"
          }
        },
        "fc6ee39b163e4ca58cfcfa4e4df32a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "103984cc86d24e87a0914193799ebc2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0d90372214b421db7e0fb8d5d760671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a095227a92b641eb9c11fe3f15e79fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3142e6758c44046ae4e9d11eee43c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c702917a63f44df19a66da3e3c5a2c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2078d21c739f4bd5976c290d16dcefd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10f1a360c84c43b5be2a06a6294432e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f03c040996be4a21a7c17d9ff7cd565e",
              "IPY_MODEL_15c06b869e134f4bafb0365598b9a7f3",
              "IPY_MODEL_b8114882c81e45a7a1d73273ae92b50e"
            ],
            "layout": "IPY_MODEL_74f90e752c6244e588df4c59345af1ed"
          }
        },
        "f03c040996be4a21a7c17d9ff7cd565e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ab3fe9693824e4e8bdace7b97f4dab0",
            "placeholder": "​",
            "style": "IPY_MODEL_01cc510b28744da6a14e0106b566e67c",
            "value": "Downloading: 100%"
          }
        },
        "15c06b869e134f4bafb0365598b9a7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a8aa2c70b6c492ba97374dd36be9661",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f63f14694ad4ba6af980976edc8278c",
            "value": 483
          }
        },
        "b8114882c81e45a7a1d73273ae92b50e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff564be4d624f6e8264786ddc98f23d",
            "placeholder": "​",
            "style": "IPY_MODEL_9e82c6ad91b747abbe25023893989dac",
            "value": " 483/483 [00:00&lt;00:00, 16.5kB/s]"
          }
        },
        "74f90e752c6244e588df4c59345af1ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ab3fe9693824e4e8bdace7b97f4dab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01cc510b28744da6a14e0106b566e67c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a8aa2c70b6c492ba97374dd36be9661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f63f14694ad4ba6af980976edc8278c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ff564be4d624f6e8264786ddc98f23d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e82c6ad91b747abbe25023893989dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d49417b45167408b8ef9d1f6e85fc3af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_02112a1e87aa4eb2a1bc1921e9477f50",
              "IPY_MODEL_e3c79f3bfeb9410c8690cdc3ed4be283",
              "IPY_MODEL_d80b02c796cc46d8b366ada0aed8752c"
            ],
            "layout": "IPY_MODEL_b0e596d20d2741cda49ca1408e705bfa"
          }
        },
        "02112a1e87aa4eb2a1bc1921e9477f50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b3cb54a43aa4457939e0108ec1e2d8e",
            "placeholder": "​",
            "style": "IPY_MODEL_019cc76972a94f8281ffe0c611d81e2a",
            "value": "Downloading: 100%"
          }
        },
        "e3c79f3bfeb9410c8690cdc3ed4be283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3585d2f4ba354d13b40cdc64702a3564",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_363bbf4999634e438e10fb9f644e3e49",
            "value": 231508
          }
        },
        "d80b02c796cc46d8b366ada0aed8752c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07d2d1c967ea45ae92095884fd590dd3",
            "placeholder": "​",
            "style": "IPY_MODEL_fd6a52367aa44412a69ec373d0d76dc4",
            "value": " 232k/232k [00:00&lt;00:00, 183kB/s]"
          }
        },
        "b0e596d20d2741cda49ca1408e705bfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b3cb54a43aa4457939e0108ec1e2d8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019cc76972a94f8281ffe0c611d81e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3585d2f4ba354d13b40cdc64702a3564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363bbf4999634e438e10fb9f644e3e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07d2d1c967ea45ae92095884fd590dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd6a52367aa44412a69ec373d0d76dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dcac5e7bad54c93989e9d3c55253386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0857392e1cbd4b3f8a972ec7c3fa856b",
              "IPY_MODEL_7890ec7c6f2d47769d69aae3a125cd12",
              "IPY_MODEL_222721d3e7dc4502a7806bbf5a842086"
            ],
            "layout": "IPY_MODEL_dcd1c54d01a045439bb85031fad5d34a"
          }
        },
        "0857392e1cbd4b3f8a972ec7c3fa856b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c05780c3bf145658bc45546f7acadcf",
            "placeholder": "​",
            "style": "IPY_MODEL_04358df65a4e4d9791e609038d8360c5",
            "value": "Downloading: 100%"
          }
        },
        "7890ec7c6f2d47769d69aae3a125cd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e07c00ece2d04982a69584235cb21958",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e2b218035484e7e893277259754b1c1",
            "value": 466062
          }
        },
        "222721d3e7dc4502a7806bbf5a842086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8d632e02154111acca976bd467e011",
            "placeholder": "​",
            "style": "IPY_MODEL_972c424d42e34aa789af3ed7cfb4808c",
            "value": " 466k/466k [00:01&lt;00:00, 511kB/s]"
          }
        },
        "dcd1c54d01a045439bb85031fad5d34a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c05780c3bf145658bc45546f7acadcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04358df65a4e4d9791e609038d8360c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e07c00ece2d04982a69584235cb21958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e2b218035484e7e893277259754b1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b8d632e02154111acca976bd467e011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "972c424d42e34aa789af3ed7cfb4808c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9381d31c529447c9efe2e15f62bba2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_153c0dde484c4105abc3b475061d95b4",
              "IPY_MODEL_9024494e2d394860979ee2fd736c94a8",
              "IPY_MODEL_9442411bc35046cb94d4e00f10072c80"
            ],
            "layout": "IPY_MODEL_af67da9e62994f5cb85cd9f6ffff2b44"
          }
        },
        "153c0dde484c4105abc3b475061d95b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cae9f584b584a838c2808f666579511",
            "placeholder": "​",
            "style": "IPY_MODEL_9b61f88969564393a419c55a537e5469",
            "value": " 75%"
          }
        },
        "9024494e2d394860979ee2fd736c94a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_440175ea36364aacafedb3bab96905cd",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_777b48f9d18045979b70cf8cd6718f0f",
            "value": 3
          }
        },
        "9442411bc35046cb94d4e00f10072c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d50b0a582858400fb137cbe5d933f939",
            "placeholder": "​",
            "style": "IPY_MODEL_ce20a50f92514436baf66b6270db7928",
            "value": " 3/4 [00:03&lt;00:01,  1.00s/ba]"
          }
        },
        "af67da9e62994f5cb85cd9f6ffff2b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cae9f584b584a838c2808f666579511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b61f88969564393a419c55a537e5469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "440175ea36364aacafedb3bab96905cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "777b48f9d18045979b70cf8cd6718f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d50b0a582858400fb137cbe5d933f939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce20a50f92514436baf66b6270db7928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f602db7f0c9c43c6a562c8ba296a128b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48bc40c9f4d3424eab324eb689fd475d",
              "IPY_MODEL_da3f3559856440c69871e5b79a98b24b",
              "IPY_MODEL_31fbfefe368240f195dccf3071f2aaa7"
            ],
            "layout": "IPY_MODEL_ae371b6b423d448f93de5f983ec84e76"
          }
        },
        "48bc40c9f4d3424eab324eb689fd475d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_270345e247c34cdd98a28c67791d0637",
            "placeholder": "​",
            "style": "IPY_MODEL_999082f771da43aa9620377f0aeb9a0f",
            "value": "  0%"
          }
        },
        "da3f3559856440c69871e5b79a98b24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ea8532430254e76861d2b267f83a52c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96822ee05af84219a8e15427d98e2ac2",
            "value": 0
          }
        },
        "31fbfefe368240f195dccf3071f2aaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_338bfafea3494b4ebba4f4dd7f8d3cd8",
            "placeholder": "​",
            "style": "IPY_MODEL_09d6b5e90aa442caae50323a71bf7c0f",
            "value": " 0/1 [00:00&lt;?, ?ba/s]"
          }
        },
        "ae371b6b423d448f93de5f983ec84e76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "270345e247c34cdd98a28c67791d0637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "999082f771da43aa9620377f0aeb9a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ea8532430254e76861d2b267f83a52c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96822ee05af84219a8e15427d98e2ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "338bfafea3494b4ebba4f4dd7f8d3cd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09d6b5e90aa442caae50323a71bf7c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94663508bd3a44e2806ff2620a4d609a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b68d9773daee453ca6342129f2e92f4e",
              "IPY_MODEL_f5b59d1ded41406984b1b1d330ba9b29",
              "IPY_MODEL_4b471fe4905247ddb45150b77fd8d1a3"
            ],
            "layout": "IPY_MODEL_91028cf3b32f4edaa726d4ddb59a3221"
          }
        },
        "b68d9773daee453ca6342129f2e92f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0264bda644d4c30bcbd46b08b875c00",
            "placeholder": "​",
            "style": "IPY_MODEL_978d4dc2e96f4677a94a2758d3c3d7c7",
            "value": "Downloading builder script: "
          }
        },
        "f5b59d1ded41406984b1b1d330ba9b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3822c2554294fc3a1bbfba05cf1e060",
            "max": 2472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7f3cafe373e4ea08dbb9671e6ccdbcd",
            "value": 2472
          }
        },
        "4b471fe4905247ddb45150b77fd8d1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5ab25910cbe4aac9041636055455604",
            "placeholder": "​",
            "style": "IPY_MODEL_0febd22cbe914379be63b0a322b17d44",
            "value": " 6.33k/? [00:00&lt;00:00, 185kB/s]"
          }
        },
        "91028cf3b32f4edaa726d4ddb59a3221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0264bda644d4c30bcbd46b08b875c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "978d4dc2e96f4677a94a2758d3c3d7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3822c2554294fc3a1bbfba05cf1e060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f3cafe373e4ea08dbb9671e6ccdbcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5ab25910cbe4aac9041636055455604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0febd22cbe914379be63b0a322b17d44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbd3d3e415424f21935a4815ca84e4b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15c65bf012f9446bab5eec83006ae2b7",
              "IPY_MODEL_0df7b19e6ea846f0bd1d615d8f943a81",
              "IPY_MODEL_259a6547a65f433db94612b682b7c4d4"
            ],
            "layout": "IPY_MODEL_b2aaad6aa95149b69e78618fa015e51c"
          }
        },
        "15c65bf012f9446bab5eec83006ae2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_158c01eb4eb744c3903d2bd4b2310a5c",
            "placeholder": "​",
            "style": "IPY_MODEL_4426d0b638e249f7b62e3b1e8c1ab360",
            "value": "Downloading: 100%"
          }
        },
        "0df7b19e6ea846f0bd1d615d8f943a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5887c3f0a514fd9a7715ded872b7b32",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ba6121ac0124ccfab2561979dfacd82",
            "value": 267967963
          }
        },
        "259a6547a65f433db94612b682b7c4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_378d162b940744bca22a5f8d5075cc28",
            "placeholder": "​",
            "style": "IPY_MODEL_a692ceb0cb9c480ea8c911b2d6cd3d0d",
            "value": " 268M/268M [00:15&lt;00:00, 21.3MB/s]"
          }
        },
        "b2aaad6aa95149b69e78618fa015e51c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "158c01eb4eb744c3903d2bd4b2310a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4426d0b638e249f7b62e3b1e8c1ab360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5887c3f0a514fd9a7715ded872b7b32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba6121ac0124ccfab2561979dfacd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "378d162b940744bca22a5f8d5075cc28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a692ceb0cb9c480ea8c911b2d6cd3d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}