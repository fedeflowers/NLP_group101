{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e77650b3",
   "metadata": {},
   "source": [
    "# 1st task, dataset exploration and binary calssification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc72f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration copenlu--nlp_course_tydiqa-cceecfb5416d988a\n",
      "Reusing dataset parquet (C:\\Users\\fiori\\.cache\\huggingface\\datasets\\copenlu___parquet\\copenlu--nlp_course_tydiqa-cceecfb5416d988a\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 23.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"copenlu/answerable_tydiqa\")\n",
    "train_set = dataset[\"train\"]\n",
    "validation_set = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4236bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(train_set)#.sample(frac=1) #RESHUFFLING\n",
    "vs = pd.DataFrame(validation_set)#.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166d770d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_title</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_plaintext</th>\n",
       "      <th>document_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milloin Charles Fort syntyi?</td>\n",
       "      <td>Charles Fort</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [18], 'answer_text': ['6. elo...</td>\n",
       "      <td>Charles Hoy Fort (6. elokuuta (joidenkin lähte...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Charles%20Fort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“ダン” ダニエル・ジャドソン・キャラハンの出身はどこ</td>\n",
       "      <td>ダニエル・J・キャラハン</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [35], 'answer_text': ['カリフォルニ...</td>\n",
       "      <td>“ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?</td>\n",
       "      <td>వేప</td>\n",
       "      <td>telugu</td>\n",
       "      <td>{'answer_start': [12], 'answer_text': ['Azadir...</td>\n",
       "      <td>వేప (లాటిన్ Azadirachta indica, syn. Melia aza...</td>\n",
       "      <td>https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?</td>\n",
       "      <td>চেঙ্গিজ খান</td>\n",
       "      <td>bengali</td>\n",
       "      <td>{'answer_start': [414], 'answer_text': ['বোরজি...</td>\n",
       "      <td>চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...</td>\n",
       "      <td>https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?</td>\n",
       "      <td>రెయ్యలగడ్ద</td>\n",
       "      <td>telugu</td>\n",
       "      <td>{'answer_start': [259], 'answer_text': ['27 హె...</td>\n",
       "      <td>రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...</td>\n",
       "      <td>https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116062</th>\n",
       "      <td>Kapan Kaisar Tang Gaozu mulai menjabat ?</td>\n",
       "      <td>Kaisar Tang Gaozu</td>\n",
       "      <td>indonesian</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>Hingga tahun 626, situasi makin memanas, Li Sh...</td>\n",
       "      <td>https://id.wikipedia.org/wiki/Kaisar%20Tang%20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116063</th>\n",
       "      <td>من ابتكر المثلجات؟</td>\n",
       "      <td>مثلجات</td>\n",
       "      <td>arabic</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>وأشار هؤلاء الإخصائيون إلى أن “صداع الآيس كريم...</td>\n",
       "      <td>https://ar.wikipedia.org/wiki/%D9%85%D8%AB%D9%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116064</th>\n",
       "      <td>বাংলা ব্যাকরণ মতে বিশেষণ কয় প্রকার ?</td>\n",
       "      <td>বিশেষণ</td>\n",
       "      <td>bengali</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>উপমান: যার সাথে তুলনা করা হয়।\\nউপমেয়: যাকে ত...</td>\n",
       "      <td>https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116065</th>\n",
       "      <td>ブラームスの出身はどこ？</td>\n",
       "      <td>ヨハネス・ブラームス</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>\\nベートーヴェンと同様に自然を愛好し、よくウィーン周辺の森を散策した。その際にキャンディを...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%83%A8%E3%83%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116066</th>\n",
       "      <td>What is the population of Mahwah, NJ?</td>\n",
       "      <td>Mahwah, New Jersey</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>The previous mayor, Bill Laforet faced a recal...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mahwah%2C%20New%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116067 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   question_text      document_title  \\\n",
       "0                   Milloin Charles Fort syntyi?        Charles Fort   \n",
       "1                    “ダン” ダニエル・ジャドソン・キャラハンの出身はどこ        ダニエル・J・キャラハン   \n",
       "2         వేప చెట్టు యొక్క శాస్త్రీయ నామం ఏమిటి?                 వేప   \n",
       "3             চেঙ্গিস খান কোন বংশের রাজা ছিলেন ?         চেঙ্গিজ খান   \n",
       "4               రెయ్యలగడ్ద గ్రామ విస్తీర్ణత ఎంత?          రెయ్యలగడ్ద   \n",
       "...                                          ...                 ...   \n",
       "116062  Kapan Kaisar Tang Gaozu mulai menjabat ?   Kaisar Tang Gaozu   \n",
       "116063                        من ابتكر المثلجات؟              مثلجات   \n",
       "116064      বাংলা ব্যাকরণ মতে বিশেষণ কয় প্রকার ?              বিশেষণ   \n",
       "116065                              ブラームスの出身はどこ？          ヨハネス・ブラームス   \n",
       "116066     What is the population of Mahwah, NJ?  Mahwah, New Jersey   \n",
       "\n",
       "          language                                        annotations  \\\n",
       "0          finnish  {'answer_start': [18], 'answer_text': ['6. elo...   \n",
       "1         japanese  {'answer_start': [35], 'answer_text': ['カリフォルニ...   \n",
       "2           telugu  {'answer_start': [12], 'answer_text': ['Azadir...   \n",
       "3          bengali  {'answer_start': [414], 'answer_text': ['বোরজি...   \n",
       "4           telugu  {'answer_start': [259], 'answer_text': ['27 హె...   \n",
       "...            ...                                                ...   \n",
       "116062  indonesian        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "116063      arabic        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "116064     bengali        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "116065    japanese        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "116066     english        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "\n",
       "                                       document_plaintext  \\\n",
       "0       Charles Hoy Fort (6. elokuuta (joidenkin lähte...   \n",
       "1       “ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...   \n",
       "2       వేప (లాటిన్ Azadirachta indica, syn. Melia aza...   \n",
       "3       চেঙ্গিজ খান (মঙ্গোলীয়: Чингис Хаан  আ-ধ্ব-ব: ...   \n",
       "4       రెయ్యలగడ్ద, విశాఖపట్నం జిల్లా, గంగరాజు మాడుగుల...   \n",
       "...                                                   ...   \n",
       "116062  Hingga tahun 626, situasi makin memanas, Li Sh...   \n",
       "116063  وأشار هؤلاء الإخصائيون إلى أن “صداع الآيس كريم...   \n",
       "116064  উপমান: যার সাথে তুলনা করা হয়।\\nউপমেয়: যাকে ত...   \n",
       "116065  \\nベートーヴェンと同様に自然を愛好し、よくウィーン周辺の森を散策した。その際にキャンディを...   \n",
       "116066  The previous mayor, Bill Laforet faced a recal...   \n",
       "\n",
       "                                             document_url  \n",
       "0            https://fi.wikipedia.org/wiki/Charles%20Fort  \n",
       "1       https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...  \n",
       "2       https://te.wikipedia.org/wiki/%E0%B0%B5%E0%B1%...  \n",
       "3       https://bn.wikipedia.org/wiki/%E0%A6%9A%E0%A7%...  \n",
       "4       https://te.wikipedia.org/wiki/%E0%B0%B0%E0%B1%...  \n",
       "...                                                   ...  \n",
       "116062  https://id.wikipedia.org/wiki/Kaisar%20Tang%20...  \n",
       "116063  https://ar.wikipedia.org/wiki/%D9%85%D8%AB%D9%...  \n",
       "116064  https://bn.wikipedia.org/wiki/%E0%A6%AC%E0%A6%...  \n",
       "116065  https://ja.wikipedia.org/wiki/%E3%83%A8%E3%83%...  \n",
       "116066  https://en.wikipedia.org/wiki/Mahwah%2C%20New%...  \n",
       "\n",
       "[116067 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c561824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = []\n",
    "new_vs = []\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i,2] == 'japanese' or df.iloc[i,2] == 'finnish' or df.iloc[i,2] == 'english':\n",
    "        new_df.append(df.iloc[i, :])\n",
    "for i in range(len(vs)):\n",
    "    if vs.iloc[i,2] == 'japanese' or vs.iloc[i,2] == 'finnish' or vs.iloc[i,2] == 'english':\n",
    "        new_vs.append(vs.iloc[i, :])\n",
    "df = pd.DataFrame(new_df) #only with english, japanese or finnish text\n",
    "vs = pd.DataFrame(new_vs) #only with english, japanese or finnish text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5595f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_title</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_plaintext</th>\n",
       "      <th>document_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milloin Charles Fort syntyi?</td>\n",
       "      <td>Charles Fort</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [18], 'answer_text': ['6. elo...</td>\n",
       "      <td>Charles Hoy Fort (6. elokuuta (joidenkin lähte...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Charles%20Fort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“ダン” ダニエル・ジャドソン・キャラハンの出身はどこ</td>\n",
       "      <td>ダニエル・J・キャラハン</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [35], 'answer_text': ['カリフォルニ...</td>\n",
       "      <td>“ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mitä on altruismi?</td>\n",
       "      <td>Altruismi</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [44], 'answer_text': ['epäits...</td>\n",
       "      <td>\\n\\n\\nAltruismi ([1],  ”toinen”[2]) tarkoittaa...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Altruismi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mikä oli Wilhelm Wagner viimeinen sävellys?</td>\n",
       "      <td>Richard Wagner</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [597], 'answer_text': ['Parsi...</td>\n",
       "      <td>Wagnerin mestariteoksia ovat hänen myöhäiskaud...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Richard%20Wagner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Missä Harz sijaitsee?</td>\n",
       "      <td>Harz</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [25], 'answer_text': ['Pohjoi...</td>\n",
       "      <td>\\n\\nHarz on horstivuoristo Pohjois-Saksassa[1]...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Harz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116055</th>\n",
       "      <td>Who developed the first thermonuclear weapon?</td>\n",
       "      <td>History of nuclear weapons</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>In the end, President Truman made the final de...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/History%20of%20n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116059</th>\n",
       "      <td>ギュスターヴ・シャルパンティエはいつ生まれた？</td>\n",
       "      <td>ギュスターヴ・シャルパンティエ</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>ただし、第一次世界大戦時に負傷兵のための音楽会を主宰し、自作の指揮も行うなど隠棲することはな...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%82%AE%E3%83%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116060</th>\n",
       "      <td>彭 徳懐はいつ生まれた？</td>\n",
       "      <td>彭徳懐故居</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>彭徳懐故居（ほうとくかいこきょ）は、中華人民共和国の政治家で軍人（中華人民共和国元帥）だった...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E5%BD%AD%E5%BE%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116065</th>\n",
       "      <td>ブラームスの出身はどこ？</td>\n",
       "      <td>ヨハネス・ブラームス</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>\\nベートーヴェンと同様に自然を愛好し、よくウィーン周辺の森を散策した。その際にキャンディを...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%83%A8%E3%83%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116066</th>\n",
       "      <td>What is the population of Mahwah, NJ?</td>\n",
       "      <td>Mahwah, New Jersey</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>The previous mayor, Bill Laforet faced a recal...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Mahwah%2C%20New%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29868 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        question_text  \\\n",
       "0                        Milloin Charles Fort syntyi?   \n",
       "1                         “ダン” ダニエル・ジャドソン・キャラハンの出身はどこ   \n",
       "10                                 Mitä on altruismi?   \n",
       "12        Mikä oli Wilhelm Wagner viimeinen sävellys?   \n",
       "13                              Missä Harz sijaitsee?   \n",
       "...                                               ...   \n",
       "116055  Who developed the first thermonuclear weapon?   \n",
       "116059                        ギュスターヴ・シャルパンティエはいつ生まれた？   \n",
       "116060                                   彭 徳懐はいつ生まれた？   \n",
       "116065                                   ブラームスの出身はどこ？   \n",
       "116066          What is the population of Mahwah, NJ?   \n",
       "\n",
       "                    document_title  language  \\\n",
       "0                     Charles Fort   finnish   \n",
       "1                     ダニエル・J・キャラハン  japanese   \n",
       "10                       Altruismi   finnish   \n",
       "12                  Richard Wagner   finnish   \n",
       "13                            Harz   finnish   \n",
       "...                            ...       ...   \n",
       "116055  History of nuclear weapons   english   \n",
       "116059             ギュスターヴ・シャルパンティエ  japanese   \n",
       "116060                       彭徳懐故居  japanese   \n",
       "116065                  ヨハネス・ブラームス  japanese   \n",
       "116066          Mahwah, New Jersey   english   \n",
       "\n",
       "                                              annotations  \\\n",
       "0       {'answer_start': [18], 'answer_text': ['6. elo...   \n",
       "1       {'answer_start': [35], 'answer_text': ['カリフォルニ...   \n",
       "10      {'answer_start': [44], 'answer_text': ['epäits...   \n",
       "12      {'answer_start': [597], 'answer_text': ['Parsi...   \n",
       "13      {'answer_start': [25], 'answer_text': ['Pohjoi...   \n",
       "...                                                   ...   \n",
       "116055        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "116059        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "116060        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "116065        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "116066        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "\n",
       "                                       document_plaintext  \\\n",
       "0       Charles Hoy Fort (6. elokuuta (joidenkin lähte...   \n",
       "1       “ダン”こと、ダニエル・ジャドソン・キャラハンは1890年7月26日、カリフォルニア州サンフ...   \n",
       "10      \\n\\n\\nAltruismi ([1],  ”toinen”[2]) tarkoittaa...   \n",
       "12      Wagnerin mestariteoksia ovat hänen myöhäiskaud...   \n",
       "13      \\n\\nHarz on horstivuoristo Pohjois-Saksassa[1]...   \n",
       "...                                                   ...   \n",
       "116055  In the end, President Truman made the final de...   \n",
       "116059  ただし、第一次世界大戦時に負傷兵のための音楽会を主宰し、自作の指揮も行うなど隠棲することはな...   \n",
       "116060  彭徳懐故居（ほうとくかいこきょ）は、中華人民共和国の政治家で軍人（中華人民共和国元帥）だった...   \n",
       "116065  \\nベートーヴェンと同様に自然を愛好し、よくウィーン周辺の森を散策した。その際にキャンディを...   \n",
       "116066  The previous mayor, Bill Laforet faced a recal...   \n",
       "\n",
       "                                             document_url  \n",
       "0            https://fi.wikipedia.org/wiki/Charles%20Fort  \n",
       "1       https://ja.wikipedia.org/wiki/%E3%83%80%E3%83%...  \n",
       "10                https://fi.wikipedia.org/wiki/Altruismi  \n",
       "12         https://fi.wikipedia.org/wiki/Richard%20Wagner  \n",
       "13                     https://fi.wikipedia.org/wiki/Harz  \n",
       "...                                                   ...  \n",
       "116055  https://en.wikipedia.org/wiki/History%20of%20n...  \n",
       "116059  https://ja.wikipedia.org/wiki/%E3%82%AE%E3%83%...  \n",
       "116060  https://ja.wikipedia.org/wiki/%E5%BD%AD%E5%BE%...  \n",
       "116065  https://ja.wikipedia.org/wiki/%E3%83%A8%E3%83%...  \n",
       "116066  https://en.wikipedia.org/wiki/Mahwah%2C%20New%...  \n",
       "\n",
       "[29868 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "288ee902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer as tok_jap #japanese tokenizer\n",
    "tok_jap = tok_jap()\n",
    "from nltk.tokenize import word_tokenize #english tokenizer\n",
    "#[token for token in t.tokenize(df.iloc[1,4], wakati=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54d9b906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 29868/29868 [02:21<00:00, 210.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tokenized_answers = {} #dictionary, key = number of iteration in the dataframe, value = answer_text, or '' if it's not answerable\n",
    "tokenized_questions = {} #same as before but with questions\n",
    "tokenized_documents = {} #same but with documents\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    if df.iloc[i,2] == 'japanese': #check the language\n",
    "        tokenized_answers[i] = [token for token in tok_jap.tokenize(df.iloc[i,3]['answer_text'][0], wakati=True)]\n",
    "        tokenized_questions[i] = [token for token in tok_jap.tokenize(df.iloc[i,0], wakati=True)]\n",
    "        tokenized_documents[i] = [token for token in tok_jap.tokenize(df.iloc[i,4], wakati=True)]\n",
    "    if df.iloc[i,2] == 'english':\n",
    "        tokenized_answers[i] = word_tokenize(df.iloc[i,3]['answer_text'][0])\n",
    "        tokenized_questions[i] = word_tokenize(df.iloc[i,0])\n",
    "        tokenized_documents[i] = word_tokenize(df.iloc[i,4])\n",
    "    if df.iloc[i,2] == 'finnish': #I used the same tokenizer, maybe we can find another one that is better for finnish\n",
    "        tokenized_answers[i] = word_tokenize(df.iloc[i,3]['answer_text'][0])\n",
    "        tokenized_questions[i] = word_tokenize(df.iloc[i,0])\n",
    "        tokenized_documents[i] = word_tokenize(df.iloc[i,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9ef9381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3712/3712 [00:16<00:00, 229.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tokenized_answers_validation = {} #dictionary, key = number of iteration in the dataframe, value = answer_text, or '' if it's not answerable\n",
    "tokenized_questions_validation = {} #same as before but with questions\n",
    "tokenized_documents_validation = {} #same but with documents\n",
    "\n",
    "for i in tqdm(range(len(vs))):\n",
    "    if vs.iloc[i,2] == 'japanese': #check the language\n",
    "        tokenized_answers_validation[i] = [token for token in tok_jap.tokenize(vs.iloc[i,3]['answer_text'][0], wakati=True)]\n",
    "        tokenized_questions_validation[i] = [token for token in tok_jap.tokenize(vs.iloc[i,0], wakati=True)]\n",
    "        tokenized_documents_validation[i] = [token for token in tok_jap.tokenize(vs.iloc[i,4], wakati=True)]\n",
    "    if vs.iloc[i,2] == 'english':\n",
    "        tokenized_answers_validation[i] = word_tokenize(vs.iloc[i,3]['answer_text'][0])\n",
    "        tokenized_questions_validation[i] = word_tokenize(vs.iloc[i,0])\n",
    "        tokenized_documents_validation[i] = word_tokenize(vs.iloc[i,4])\n",
    "    if vs.iloc[i,2] == 'finnish': #I used the same tokenizer, maybe we can find another one that is better for finnish\n",
    "        tokenized_answers_validation[i] = word_tokenize(vs.iloc[i,3]['answer_text'][0])\n",
    "        tokenized_questions_validation[i] = word_tokenize(vs.iloc[i,0])\n",
    "        tokenized_documents_validation[i] = word_tokenize(vs.iloc[i,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a9203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>document_title</th>\n",
       "      <th>language</th>\n",
       "      <th>annotations</th>\n",
       "      <th>document_plaintext</th>\n",
       "      <th>document_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>化学兵器禁止条約はどこで採択された？</td>\n",
       "      <td>化学兵器禁止条約</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [11], 'answer_text': ['パリ']}</td>\n",
       "      <td>1993年1月13日にパリにおいて署名がなされ、1997年4月29日に発効した[1]。実効的...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E5%8C%96%E5%AD%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>オリヴィア・デ・ハヴィランドが生まれたのはいつ</td>\n",
       "      <td>オリヴィア・デ・ハヴィランド</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [46], 'answer_text': ['1916年7...</td>\n",
       "      <td>\\nオリヴィア・デ・ハヴィランド（Dame Olivia De Havilland, DBE...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kauanko lasia on valmistettu?</td>\n",
       "      <td>Lasi</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [160], 'answer_text': ['noin ...</td>\n",
       "      <td>Vanhin tunnettu lasilaatu on alkali­kalkki­las...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Lasi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mikä on Ponzi-huijaus?</td>\n",
       "      <td>Ponzi-huijaus</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [39], 'answer_text': ['pyrami...</td>\n",
       "      <td>Ponzi-huijaus eli Ponzi-järjestelmä on pyramid...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Ponzi-huijaus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mikä oli Napoleonin sotien lopputulos?</td>\n",
       "      <td>Napoleonin sodat</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [15], 'answer_text': ['Ranska...</td>\n",
       "      <td>Sotien jälkeen Ranska alistettiin kovilla rauh...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Napoleonin%20sodat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13305</th>\n",
       "      <td>What is the most common first word by babies?</td>\n",
       "      <td>Vocabulary development</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>Social pragmatic theories, also in contrast to...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Vocabulary%20dev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13307</th>\n",
       "      <td>Kuinka kauan valtiopäivät kestää?</td>\n",
       "      <td>Suomen valtiopäivät</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>\\nEnnen vuotta 1906 kokoontuivat säätyvaltiopä...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Suomen%20valtiop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13315</th>\n",
       "      <td>アイスランド共和国の首都はどこですか？</td>\n",
       "      <td>アイスランド</td>\n",
       "      <td>japanese</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>こうした危機を乗り切るため、アイスランド中央銀行は8日にロシアから40億ユーロの緊急融資を受...</td>\n",
       "      <td>https://ja.wikipedia.org/wiki/%E3%82%A2%E3%82%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13317</th>\n",
       "      <td>Milloin käytiin Persianlahden sota?</td>\n",
       "      <td>Persianlahden sota</td>\n",
       "      <td>finnish</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>Ilmaiskuilla oli erityisen tuhoisa vaikutus Ir...</td>\n",
       "      <td>https://fi.wikipedia.org/wiki/Persianlahden%20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13319</th>\n",
       "      <td>When did the Bundaberg Central State School be...</td>\n",
       "      <td>Bundaberg Central State School</td>\n",
       "      <td>english</td>\n",
       "      <td>{'answer_start': [-1], 'answer_text': ['']}</td>\n",
       "      <td>By the 1880s the school site had become valuab...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Bundaberg%20Cent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3712 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question_text  \\\n",
       "3                                     化学兵器禁止条約はどこで採択された？   \n",
       "9                                オリヴィア・デ・ハヴィランドが生まれたのはいつ   \n",
       "11                         Kauanko lasia on valmistettu?   \n",
       "14                                Mikä on Ponzi-huijaus?   \n",
       "20                Mikä oli Napoleonin sotien lopputulos?   \n",
       "...                                                  ...   \n",
       "13305      What is the most common first word by babies?   \n",
       "13307                  Kuinka kauan valtiopäivät kestää?   \n",
       "13315                                アイスランド共和国の首都はどこですか？   \n",
       "13317                Milloin käytiin Persianlahden sota?   \n",
       "13319  When did the Bundaberg Central State School be...   \n",
       "\n",
       "                       document_title  language  \\\n",
       "3                            化学兵器禁止条約  japanese   \n",
       "9                      オリヴィア・デ・ハヴィランド  japanese   \n",
       "11                               Lasi   finnish   \n",
       "14                      Ponzi-huijaus   finnish   \n",
       "20                   Napoleonin sodat   finnish   \n",
       "...                               ...       ...   \n",
       "13305          Vocabulary development   english   \n",
       "13307             Suomen valtiopäivät   finnish   \n",
       "13315                          アイスランド  japanese   \n",
       "13317              Persianlahden sota   finnish   \n",
       "13319  Bundaberg Central State School   english   \n",
       "\n",
       "                                             annotations  \\\n",
       "3          {'answer_start': [11], 'answer_text': ['パリ']}   \n",
       "9      {'answer_start': [46], 'answer_text': ['1916年7...   \n",
       "11     {'answer_start': [160], 'answer_text': ['noin ...   \n",
       "14     {'answer_start': [39], 'answer_text': ['pyrami...   \n",
       "20     {'answer_start': [15], 'answer_text': ['Ranska...   \n",
       "...                                                  ...   \n",
       "13305        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "13307        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "13315        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "13317        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "13319        {'answer_start': [-1], 'answer_text': ['']}   \n",
       "\n",
       "                                      document_plaintext  \\\n",
       "3      1993年1月13日にパリにおいて署名がなされ、1997年4月29日に発効した[1]。実効的...   \n",
       "9      \\nオリヴィア・デ・ハヴィランド（Dame Olivia De Havilland, DBE...   \n",
       "11     Vanhin tunnettu lasilaatu on alkali­kalkki­las...   \n",
       "14     Ponzi-huijaus eli Ponzi-järjestelmä on pyramid...   \n",
       "20     Sotien jälkeen Ranska alistettiin kovilla rauh...   \n",
       "...                                                  ...   \n",
       "13305  Social pragmatic theories, also in contrast to...   \n",
       "13307  \\nEnnen vuotta 1906 kokoontuivat säätyvaltiopä...   \n",
       "13315  こうした危機を乗り切るため、アイスランド中央銀行は8日にロシアから40億ユーロの緊急融資を受...   \n",
       "13317  Ilmaiskuilla oli erityisen tuhoisa vaikutus Ir...   \n",
       "13319  By the 1880s the school site had become valuab...   \n",
       "\n",
       "                                            document_url  \n",
       "3      https://ja.wikipedia.org/wiki/%E5%8C%96%E5%AD%...  \n",
       "9      https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%...  \n",
       "11                    https://fi.wikipedia.org/wiki/Lasi  \n",
       "14           https://fi.wikipedia.org/wiki/Ponzi-huijaus  \n",
       "20      https://fi.wikipedia.org/wiki/Napoleonin%20sodat  \n",
       "...                                                  ...  \n",
       "13305  https://en.wikipedia.org/wiki/Vocabulary%20dev...  \n",
       "13307  https://fi.wikipedia.org/wiki/Suomen%20valtiop...  \n",
       "13315  https://ja.wikipedia.org/wiki/%E3%82%A2%E3%82%...  \n",
       "13317  https://fi.wikipedia.org/wiki/Persianlahden%20...  \n",
       "13319  https://en.wikipedia.org/wiki/Bundaberg%20Cent...  \n",
       "\n",
       "[3712 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194d9f8",
   "metadata": {},
   "source": [
    "# Creating trainset and validation set for the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b554f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#need only question and document, I don't really need the tokenization done before:\n",
    "jap_training = {} \n",
    "finn_training = {}\n",
    "eng_training = {}\n",
    "\n",
    "j = 0\n",
    "f = 0\n",
    "e = 0\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    sample_dict = {}\n",
    "    sample_dict['question'] = tokenized_questions[i]\n",
    "    sample_dict['context'] = tokenized_documents[i]\n",
    "   \n",
    "    #sample_dict['question'] = df.iloc[i,0]\n",
    "    #sample_dict['document'] = df.iloc[i,4]\n",
    "    \n",
    "    if tokenized_answers[i] == [] :\n",
    "        sample_dict['label'] = 0 #not answerable question\n",
    "    else:\n",
    "        sample_dict['label'] = 1\n",
    "        \n",
    "    if df.iloc[i,2] == 'japanese':\n",
    "        jap_training[j] = sample_dict\n",
    "        j += 1\n",
    "        continue\n",
    "    elif df.iloc[i,2] == 'english':\n",
    "        eng_training[e] = sample_dict\n",
    "        e += 1\n",
    "        continue\n",
    "    elif df.iloc[i,2] == 'finnish':\n",
    "        finn_training[f] = sample_dict\n",
    "        f += 1\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7562423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation set\n",
    "import nltk\n",
    "\n",
    "jap_val = {} \n",
    "finn_val = {}\n",
    "eng_val = {}\n",
    "\n",
    "j = 0\n",
    "f = 0\n",
    "e = 0\n",
    "\n",
    "\n",
    "for i in range(len(vs)):\n",
    "    sample_dict = {}\n",
    "    sample_dict['question'] = tokenized_questions_validation[i]\n",
    "    sample_dict['context'] = tokenized_documents_validation[i]\n",
    "    \n",
    "    if tokenized_answers_validation[i] == [] :\n",
    "        sample_dict['label'] = 0 #not answerable question\n",
    "    else:\n",
    "        sample_dict['label'] = 1\n",
    "        \n",
    "    if vs.iloc[i,2] == 'japanese':\n",
    "        jap_val[j] = sample_dict\n",
    "        j += 1\n",
    "        continue\n",
    "    elif vs.iloc[i,2] == 'english':\n",
    "        eng_val[e] = sample_dict\n",
    "        e += 1\n",
    "        continue\n",
    "    elif vs.iloc[i,2] == 'finnish':\n",
    "        finn_val[f] = sample_dict\n",
    "        f += 1\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3583e",
   "metadata": {},
   "source": [
    "## Create corpus for tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0da71b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus to create a vocabulary with all possible words\n",
    "\n",
    "corpus_questions_eng = []\n",
    "corpus_questions_finn = []\n",
    "corpus_questions_jap = []\n",
    "corpus_context_eng = []\n",
    "corpus_context_finn = []\n",
    "corpus_context_jap = []\n",
    "\n",
    "for x in eng_training:\n",
    "    corpus_questions_eng.append(eng_training[x]['question'])\n",
    "    corpus_context_eng.append(eng_training[x]['context'])\n",
    "for x in finn_training:\n",
    "    corpus_questions_finn.append(finn_training[x]['question'])\n",
    "    corpus_context_finn.append(finn_training[x]['context'])\n",
    "for x in jap_training:\n",
    "    corpus_questions_jap.append(jap_training[x]['question'])\n",
    "    corpus_context_jap.append(jap_training[x]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8ac13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_questions_VAL_eng = []\n",
    "corpus_context_VAL_eng = []\n",
    "corpus_questions_VAL_finn = []\n",
    "corpus_context_VAL_finn = []\n",
    "corpus_questions_VAL_jap = []\n",
    "corpus_context_VAL_jap = []\n",
    "\n",
    "for x in eng_val:\n",
    "    corpus_questions_VAL_eng.append(eng_val[x]['question'])  \n",
    "    corpus_context_VAL_eng.append(eng_val[x]['context']) \n",
    "for x in finn_val:\n",
    "    corpus_questions_VAL_finn.append(finn_val[x]['question'])  \n",
    "    corpus_context_VAL_finn.append(finn_val[x]['context']) \n",
    "for x in jap_val:\n",
    "    corpus_questions_VAL_jap.append(jap_val[x]['question'])  \n",
    "    corpus_context_VAL_jap.append(jap_val[x]['context']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec0d4fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words_dict_eng = {}\n",
    "bag_of_words_dict_finn = {}\n",
    "bag_of_words_dict_jap = {}\n",
    "\n",
    "for sent in corpus_questions_eng:\n",
    "    for word in sent:\n",
    "        if word not in bag_of_words_dict_eng:\n",
    "            bag_of_words_dict_eng[word] = 1\n",
    "        else:\n",
    "            bag_of_words_dict_eng[word] +=1\n",
    "            \n",
    "for question in corpus_questions_finn:\n",
    "    for word in question:\n",
    "        if word not in bag_of_words_dict_finn:\n",
    "            bag_of_words_dict_finn[word] = 1\n",
    "        else:\n",
    "            bag_of_words_dict_finn[word] +=1\n",
    "            \n",
    "for question in corpus_questions_jap:\n",
    "    for word in question:\n",
    "        if word not in bag_of_words_dict_jap:\n",
    "            bag_of_words_dict_jap[word] = 1\n",
    "        else:\n",
    "            bag_of_words_dict_jap[word] +=1\n",
    "            \n",
    "#list_words = bag_of_words_dict_eng.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed1de7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbag_of_words_dict_eng = {}\\nfor question in corpus_questions:\\n    for word in question:\\n        if word not in bag_of_words_dict_eng:\\n            bag_of_words_dict_eng[word] = 1\\n        else:\\n            bag_of_words_dict_eng[word] +=1\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VALIDATIO SET, the vocabulary should be the same as the training set\n",
    "#I have to use the same vocabulary as the training, even for the validation set, that's why the commented part of code it's not useful\n",
    "'''\n",
    "bag_of_words_dict_eng = {}\n",
    "for question in corpus_questions:\n",
    "    for word in question:\n",
    "        if word not in bag_of_words_dict_eng:\n",
    "            bag_of_words_dict_eng[word] = 1\n",
    "        else:\n",
    "            bag_of_words_dict_eng[word] +=1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b566f53",
   "metadata": {},
   "source": [
    "### Top 10 words in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af81be00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'the', 'When', 'was', 'What', 'is', 'of', 'How', 'in', 'did']\n"
     ]
    }
   ],
   "source": [
    "sorted_words_question = dict(sorted(bag_of_words_dict_eng.items(), key=lambda item:item[1], \n",
    "reverse=True))\n",
    "print(list(sorted_words_question)[:10]) #top 10 words in english questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308fbfe2",
   "metadata": {},
   "source": [
    "### Top 10 words in finnish questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f76aa8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['?', 'on', 'Milloin', 'Mikä', 'Missä', 'Kuka', 'oli', 'Mitä', 'syntyi', 'kuoli']\n"
     ]
    }
   ],
   "source": [
    "sorted_words_question = dict(sorted(bag_of_words_dict_finn.items(), key=lambda item:item[1], \n",
    "reverse=True))\n",
    "print(list(sorted_words_question)[:10]) #top 10 words in english questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b7f9b2",
   "metadata": {},
   "source": [
    "### Top 10 words in japanese questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58fde165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['は', 'の', '？', 'た', 'い', 'つ', '何', 'し', 'どこ', 'が']\n"
     ]
    }
   ],
   "source": [
    "sorted_words_question = dict(sorted(bag_of_words_dict_jap.items(), key=lambda item:item[1], \n",
    "reverse=True))\n",
    "print(list(sorted_words_question)[:10]) #top 10 words in english questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa41cd2",
   "metadata": {},
   "source": [
    "# TfIdf vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd589a20",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90d14ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_questions_eng_not_tokenized = [\" \".join(x) for x in corpus_questions_eng]\n",
    "corpus_context_eng_not_tokenized = [\" \".join(x) for x in corpus_context_eng]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2184ff",
   "metadata": {},
   "source": [
    "##### use tfidf for questions and then for context, concatenate the 2 and try to predict, for validation set use the same model of tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e549d070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<7389x4603 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 50118 stored elements in Compressed Sparse Row format>,\n",
       " <7389x50037 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 455794 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer_questions = TfidfVectorizer()\n",
    "q = tfidf_vectorizer_questions.fit_transform(corpus_questions_eng_not_tokenized)\n",
    "\n",
    "tfidf_vectorizer_context = TfidfVectorizer() #new model\n",
    "c = tfidf_vectorizer_context.fit_transform(corpus_context_eng_not_tokenized) \n",
    "q,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be05b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate sparse matrices\n",
    "from scipy.sparse import hstack\n",
    "X = hstack([q,c]) #questions and contexts tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "006e950c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7389x54640 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 505912 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1baaa9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#why not use fit_transform also on validation set:\n",
    "#https://stats.stackexchange.com/questions/154660/tfidfvectorizer-should-it-be-used-on-train-only-or-traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4aac13d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat process for validation set:\n",
    "corpus_questions_VAL_eng_not_t = [\" \".join(x) for x in corpus_questions_VAL_eng] # not tokenized\n",
    "corpus_context_VAL_eng_not_t = [\" \".join(x) for x in corpus_context_VAL_eng]\n",
    "q = tfidf_vectorizer_questions.transform(corpus_questions_VAL_eng_not_t) #ignores unknown words\n",
    "c = tfidf_vectorizer_context.transform(corpus_context_VAL_eng_not_t) #ignores unknown words\n",
    "\n",
    "X_VAL = hstack([q,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9de2389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<990x54640 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 63594 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "367f0c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [] #-1 not answ, 1 is answ.\n",
    "Y_VAL = []\n",
    "for i in eng_training:\n",
    "    y.append(eng_training[i]['label'])\n",
    "    \n",
    "for i in eng_val:\n",
    "    Y_VAL.append(eng_val[i]['label'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "741fe620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set accuracy\n",
      "89.21369603464609\n",
      "vald_set accuracy\n",
      "72.42424242424242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X, y)\n",
    "y_pred = LR.predict(X)\n",
    "#training accuracy score\n",
    "print(\"train_set accuracy\")\n",
    "print(accuracy_score(y, y_pred)*100)\n",
    "\n",
    "#accuracy score on val_set\n",
    "y_pred = LR.predict(X_VAL)\n",
    "print(\"vald_set accuracy\")\n",
    "print(accuracy_score(Y_VAL, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59329d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_eng = X\n",
    "features_val_eng = X_VAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45dc31",
   "metadata": {},
   "source": [
    "# Finnish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c17406dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set accuracy\n",
      "91.69403693161084\n",
      "vald_set accuracy\n",
      "71.23368920521945\n"
     ]
    }
   ],
   "source": [
    "#same as english\n",
    "corpus_questions_finn_not_tokenized = [\" \".join(x) for x in corpus_questions_finn]\n",
    "corpus_context_finn_not_tokenized = [\" \".join(x) for x in corpus_context_finn]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer_questions = TfidfVectorizer()\n",
    "q = tfidf_vectorizer_questions.fit_transform(corpus_questions_finn_not_tokenized)\n",
    "\n",
    "tfidf_vectorizer_context = TfidfVectorizer() #new model\n",
    "c = tfidf_vectorizer_context.fit_transform(corpus_context_finn_not_tokenized) \n",
    "\n",
    "#concatenate sparse matrices\n",
    "from scipy.sparse import hstack\n",
    "X = hstack([q,c]) #questions and contexts tfidfs\n",
    "\n",
    "corpus_questions_VAL_finn_not_t = [\" \".join(x) for x in corpus_questions_VAL_finn] # not tokenized\n",
    "corpus_context_VAL_finn_not_t = [\" \".join(x) for x in corpus_context_VAL_finn]\n",
    "q = tfidf_vectorizer_questions.transform(corpus_questions_VAL_finn_not_t) #ignores unknown words\n",
    "c = tfidf_vectorizer_context.transform(corpus_context_VAL_finn_not_t) #ignores unknown words\n",
    "\n",
    "X_VAL = hstack([q,c])\n",
    "\n",
    "y = [] #-1 not answ, 1 is answ.\n",
    "Y_VAL = []\n",
    "for i in finn_training:\n",
    "    y.append(finn_training[i]['label'])\n",
    "    \n",
    "for i in finn_val:\n",
    "    Y_VAL.append(finn_val[i]['label'])\n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X, y)\n",
    "y_pred = LR.predict(X)\n",
    "#training accuracy score\n",
    "print(\"train_set accuracy\")\n",
    "print(accuracy_score(y, y_pred)*100)\n",
    "\n",
    "#accuracy score on val_set\n",
    "y_pred = LR.predict(X_VAL)\n",
    "print(\"vald_set accuracy\")\n",
    "print(accuracy_score(Y_VAL, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61f8e79",
   "metadata": {},
   "source": [
    "# Japanese\n",
    "##### overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bef4230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set accuracy\n",
      "98.32535885167464\n",
      "vald_set accuracy\n",
      "57.91505791505791\n"
     ]
    }
   ],
   "source": [
    "#same as english\n",
    "corpus_questions_jap_not_tokenized = [\"\".join(x) for x in corpus_questions_jap] # no space in japanese\n",
    "corpus_context_jap_not_tokenized = [\"\".join(x) for x in corpus_context_jap]\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer_questions = TfidfVectorizer()\n",
    "q = tfidf_vectorizer_questions.fit_transform(corpus_questions_jap_not_tokenized)\n",
    "\n",
    "tfidf_vectorizer_context = TfidfVectorizer()\n",
    "c = tfidf_vectorizer_context.fit_transform(corpus_context_jap_not_tokenized) \n",
    "\n",
    "#concatenate sparse matrices\n",
    "from scipy.sparse import hstack\n",
    "X = hstack([q,c]) #questions and contexts tfidfs\n",
    "\n",
    "corpus_questions_VAL_jap_not_t = [\" \".join(x) for x in corpus_questions_VAL_jap] # not tokenized\n",
    "corpus_context_VAL_jap_not_t = [\" \".join(x) for x in corpus_context_VAL_jap]\n",
    "q = tfidf_vectorizer_questions.transform(corpus_questions_VAL_jap_not_t) #ignores unknown words\n",
    "c = tfidf_vectorizer_context.transform(corpus_context_VAL_jap_not_t) #ignores unknown words\n",
    "\n",
    "X_VAL = hstack([q,c])\n",
    "\n",
    "y = [] #-1 not answ, 1 is answ.\n",
    "Y_VAL = []\n",
    "for i in jap_training:\n",
    "    y.append(jap_training[i]['label'])\n",
    "    \n",
    "for i in jap_val:\n",
    "    Y_VAL.append(jap_val[i]['label'])\n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X, y)\n",
    "y_pred = LR.predict(X)\n",
    "#training accuracy score\n",
    "print(\"train_set accuracy\")\n",
    "print(accuracy_score(y, y_pred)*100)\n",
    "\n",
    "#accuracy score on val_set\n",
    "y_pred = LR.predict(X_VAL)\n",
    "print(\"vald_set accuracy\")\n",
    "print(accuracy_score(Y_VAL, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80262d96",
   "metadata": {},
   "source": [
    "#### maybe the problem is due to the tokenizer used in tfidf model, but I wasn't able to use janome..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7288cdc",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c2ace1",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff873240",
   "metadata": {},
   "source": [
    "##### CBOW (Continuous Bag of Words): CBOW model predicts the current word given context words within a specific window. The input layer contains the context words and the output layer contains the current word. The hidden layer contains the number of dimensions in which we want to represent the current word present at the output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cfbbe307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b29397",
   "metadata": {},
   "source": [
    "#### The model is trained on single words but I will get an avg of all the words rep for each sentence in order to obtain a sentence representation and not a single word one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fe9f7c",
   "metadata": {},
   "source": [
    "# English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d884de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_count= ignore words with less than min_count value\n",
    "#window = window used for CBOW model\n",
    "import gensim\n",
    "vector_size = 500\n",
    "continous_rep_eng_questions = gensim.models.Word2Vec(corpus_questions_eng, min_count = 1,\n",
    "                              vector_size = vector_size, window = 5, epochs=5) \n",
    "continous_rep_eng_context = gensim.models.Word2Vec(corpus_context_eng, min_count = 1,\n",
    "                              vector_size = vector_size, window = 5, epochs=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d1b7cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combination of representations of input level\n",
    "for i in eng_training:\n",
    "    sent = eng_training[i]['question']\n",
    "    n = len(sent)\n",
    "    average_vector = np.zeros(vector_size)\n",
    "    for word in sent:\n",
    "        average_vector += continous_rep_eng_questions.wv[word]\n",
    "    average_vector = average_vector / n\n",
    "    eng_training[i]['CBOW_question'] = average_vector\n",
    "\n",
    "for i in eng_training:\n",
    "    sent = eng_training[i]['context']\n",
    "    n = len(sent)\n",
    "    average_vector = np.zeros(vector_size)\n",
    "    for word in sent:\n",
    "        average_vector += continous_rep_eng_context.wv[word]\n",
    "    average_vector = average_vector / n\n",
    "    eng_training[i]['CBOW_context'] = average_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "783716b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in eng_val:\n",
    "    count_not_in_vocab = 0\n",
    "    sent = eng_val[i]['question']\n",
    "    n = len(sent)\n",
    "    average_vector = np.zeros(vector_size)\n",
    "    for word in sent:\n",
    "        try:\n",
    "            average_vector += continous_rep_eng_questions.wv[word]\n",
    "        except:\n",
    "            count_not_in_vocab += 1\n",
    "            #print(\"word not in vocabulary\")\n",
    "    average_vector = average_vector / (n - count_not_in_vocab)\n",
    "    eng_val[i]['CBOW_question'] = average_vector\n",
    "    \n",
    "for i in eng_val:\n",
    "    count_not_in_vocab = 0\n",
    "    sent = eng_val[i]['context']\n",
    "    n = len(sent)\n",
    "    average_vector = np.zeros(vector_size)\n",
    "    for word in sent:\n",
    "        try:\n",
    "            average_vector += continous_rep_eng_context.wv[word]\n",
    "        except:\n",
    "            count_not_in_vocab += 1\n",
    "            #print(\"word not in vocabulary\")\n",
    "    if n - count_not_in_vocab >0:\n",
    "        average_vector = average_vector / (n - count_not_in_vocab)\n",
    "    else:\n",
    "        average_vector = average_vector/1\n",
    "    eng_val[i]['CBOW_context'] = average_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a658f254",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = [] #0 not answ, 1 is answ.\n",
    "X_VAL = []\n",
    "Y_VAL = []\n",
    "for i in eng_training:\n",
    "    X.append(list(np.concatenate((eng_training[i]['CBOW_question'],eng_training[i]['CBOW_context']),axis = None)))\n",
    "    y.append(eng_training[i]['label'])\n",
    "    \n",
    "for i in eng_val:\n",
    "    X_VAL.append(list(np.concatenate((eng_val[i]['CBOW_question'],eng_val[i]['CBOW_context']),axis = None)))\n",
    "    Y_VAL.append(eng_val[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84de6469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7389x54640 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 505912 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6fbc2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "CBOW_rep = csr_matrix(np.array(X))\n",
    "#lots of elements because it's not sparse... but in this way I can stack it to the previous rep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e8023b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack([features_eng,CBOW_rep]) #features_eng = features of prev. representations, CBOW_rep current rep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2db18453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7389x55640 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 7894912 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # +200 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a38e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "CBOW_rep_val = csr_matrix(np.array(X_VAL))\n",
    "X_VAL = hstack([features_val_eng,CBOW_rep_val]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc90e727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set accuracy\n",
      "86.11449451887941\n",
      "vald_set accuracy\n",
      "72.02020202020202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "LR = LogisticRegression(max_iter=1000)\n",
    "\n",
    "LR.fit(X, y)\n",
    "y_pred = LR.predict(X)\n",
    "print(\"train_set accuracy\")\n",
    "print(accuracy_score(y, y_pred)*100)\n",
    "\n",
    "#accuracy score on val_set\n",
    "y_pred = LR.predict(X_VAL)\n",
    "print(\"vald_set accuracy\")\n",
    "print(accuracy_score(Y_VAL, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc0d360",
   "metadata": {},
   "source": [
    "## just CBOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51ab549e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = [] #0 not answ, 1 is answ.\n",
    "X_VAL = []\n",
    "Y_VAL = []\n",
    "for i in eng_training:\n",
    "    X.append(list(np.concatenate((eng_training[i]['CBOW_question'],eng_training[i]['CBOW_context']),axis = None)))\n",
    "    y.append(eng_training[i]['label'])\n",
    "    \n",
    "for i in eng_val:\n",
    "    X_VAL.append(list(np.concatenate((eng_val[i]['CBOW_question'],eng_val[i]['CBOW_context']),axis = None)))\n",
    "    Y_VAL.append(eng_val[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33cc67d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set accuracy\n",
      "69.73880092028692\n",
      "vald_set accuracy\n",
      "66.46464646464646\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "LR = LogisticRegression(random_state=0, max_iter=1000)\n",
    "#training decision tree\n",
    "LR.fit(X, y)\n",
    "y_pred = LR.predict(X)\n",
    "print(\"train_set accuracy\")\n",
    "print(accuracy_score(y, y_pred)*100)\n",
    "\n",
    "#accuracy score on val_set\n",
    "y_pred = LR.predict(X_VAL)\n",
    "print(\"vald_set accuracy\")\n",
    "print(accuracy_score(Y_VAL, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc950665",
   "metadata": {},
   "source": [
    "# Repeat cbow for finn and jap. ? or one classifier is enough to show?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e1516",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b70fa9b",
   "metadata": {},
   "source": [
    "### utility functions from lab3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1287e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_parag_combine(questions, paragraphs):\n",
    "    \"\"\"\n",
    "    This function combines the questions and paragraphs into a single text\n",
    "    Args:\n",
    "        questions: list of questions\n",
    "        paragraphs: list of paragraphs\n",
    "    Returns:\n",
    "        list of combined questions and paragraphs\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    for index in range(len(questions)):\n",
    "        training_data += [questions[index] + \"\\n\" + paragraphs[index]]\n",
    "        \n",
    "    return training_data\n",
    "\n",
    "def get_data_with_cond(data_set, cond, vectorizer):\n",
    "    \"\"\"\n",
    "    This function returns the data with the given condition (can be used to get data for a particular language).\n",
    "    vectorizer is used to vectorize the data: it can be a CountVectorizer or a TfidfVectorizer, etc.\n",
    "    If vectorizer is None, then the combined data is returned as is.\n",
    "    Args:\n",
    "        data_set: pandas dataframe\n",
    "        cond: condition to be applied\n",
    "        vectorizer: vectorizer to be used\n",
    "    Returns:\n",
    "        data with the given condition\n",
    "    \"\"\"\n",
    "\n",
    "    d_q = data_set[cond]['question_text'].tolist()\n",
    "    d_p = data_set[cond]['document_plaintext'].tolist()\n",
    "    data = question_parag_combine(d_q,d_p)\n",
    "\n",
    "    print(len(d_q))\n",
    "    if vectorizer is None:\n",
    "        return data \n",
    "    \n",
    "    X = vectorizer.transform(data)\n",
    "    y = data_set[cond]['answerable'].tolist()\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "#example use \n",
    "# cond_eng = validation_set['language'] == 'english'\n",
    "# X_eng, y_eng = get_data_with_cond(validation_set, cond_eng, vectorizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b3526",
   "metadata": {},
   "source": [
    "#### Re-formatting data for the transformers use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14bd25c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels_eng = []\n",
    "training_data_eng = question_parag_combine(corpus_questions_eng_not_tokenized, corpus_context_eng_not_tokenized)\n",
    "for i in eng_training:\n",
    "    training_labels_eng.append(eng_training[i]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e2d41ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_labels_eng = []\n",
    "validation_data_eng = question_parag_combine(corpus_questions_VAL_eng_not_t, corpus_context_VAL_eng_not_t)\n",
    "for i in eng_val:\n",
    "    validation_labels_eng.append(eng_val[i]['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a1d740",
   "metadata": {},
   "source": [
    "## lab3 tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a1dbb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  3.82ba/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.77ba/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "data_set = {}\n",
    "sets = [['train',training_data_eng, training_labels_eng], ['val',validation_data_eng, validation_labels_eng]]\n",
    "for meta in sets:\n",
    "    data_set[meta[0]] = {}\n",
    "    data_set[meta[0]]['text'] = []\n",
    "    data_set[meta[0]]['label'] = []\n",
    "    \n",
    "    for ind, text in enumerate(meta[1]):\n",
    "        data_set[meta[0]]['text'].append(text)\n",
    "        data_set[meta[0]]['label'].append(meta[2][ind])\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "data_set = DatasetDict({'train':Dataset.from_dict(data_set['train']),\n",
    "                        'valid':Dataset.from_dict(data_set['val'])\\\n",
    "                       })\n",
    "\n",
    "# training_data = tokenize_data(training_data)\n",
    "#  validation_data = tokenize_data(validation_data)\n",
    "tokenized_datasets = data_set.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "736001bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 7389\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 990\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bbf0d",
   "metadata": {},
   "source": [
    "### English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2a7d417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f88989e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "#layers that will be trained with these settings:\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        print(name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12abf551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be frozen: bert.embeddings.word_embeddings.weight\n",
      "I will be frozen: bert.embeddings.position_embeddings.weight\n",
      "I will be frozen: bert.embeddings.token_type_embeddings.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.8.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.8.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.9.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.9.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.10.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.10.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.10.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.10.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.10.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.10.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.11.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.11.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.11.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.11.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.11.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.11.output.LayerNorm.bias\n",
      "I will be frozen: bert.pooler.dense.weight\n",
      "I will be frozen: bert.pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "# I want to train only the last layer:\n",
    "for name, param in list(model.named_parameters())[:len(list(model.parameters())) - 2]: \n",
    "    print('I will be frozen: {}'.format(name)) \n",
    "    param.requires_grad = False #do not require gradint computation\n",
    "    \n",
    "#basically freeze everything except calssification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7276374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "metric = load_metric('f1')\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\", num_train_epochs=1, \\\n",
    "                                  do_train = True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64ca320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['valid'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02f944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142786c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "468538c6",
   "metadata": {},
   "source": [
    "## ONLY for training, do not run this cell, load the model from local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4371470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 7389\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 924\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='924' max='924' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [924/924 4:13:36, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.687900</td>\n",
       "      <td>0.673974</td>\n",
       "      <td>0.628466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer\\checkpoint-500\n",
      "Configuration saved in test_trainer\\checkpoint-500\\config.json\n",
      "Model weights saved in test_trainer\\checkpoint-500\\pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 990\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=924, training_loss=0.6879307800557191, metrics={'train_runtime': 15231.5799, 'train_samples_per_second': 0.485, 'train_steps_per_second': 0.061, 'total_flos': 1944127588055040.0, 'train_loss': 0.6879307800557191, 'epoch': 1.0})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "20e0bff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to BERT_fine_tuned_english\n",
      "Configuration saved in BERT_fine_tuned_english\\config.json\n",
      "Model weights saved in BERT_fine_tuned_english\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "#SAVE MODEL\n",
    "output_dir = \"BERT_fine_tuned_english\"\n",
    "trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cfba14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file BERT_fine_tuned_english\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"BERT_fine_tuned_english\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file BERT_fine_tuned_english\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BERT_fine_tuned_english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#LOAD MODEL\n",
    "output_dir = \"BERT_fine_tuned_english\"\n",
    "m = AutoModelForSequenceClassification.from_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d80cc",
   "metadata": {},
   "source": [
    "# SAMPLING FROM THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5479b7a",
   "metadata": {},
   "source": [
    "### BERT (pre-trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5a9c40c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\pytorch_model.bin\n",
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertLMHeadModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertLMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "prompt = [\"Today I would like to buy\"]\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True).input_ids\n",
    "\n",
    "outputs = model.generate(input_ids, do_sample=False, max_length=50)\n",
    "sentence_BERT = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c4f869d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today I would like to buy..........................................']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3a922c",
   "metadata": {},
   "source": [
    "### GPT2 (pre-trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b01fa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\merges.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "prompt = \"Today I would like to buy\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# generate up to 30 tokens\n",
    "outputs = model.generate(input_ids, do_sample=False, max_length=30)\n",
    "sentence_GPT2 = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57b01057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today I would like to buy a new car. I am a big fan of the BMW i3 and I am looking forward to the new car.']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a73280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3241bcdd",
   "metadata": {},
   "source": [
    "# PERPLEXITY, Given a model and an input text sequence, perplexity measures how likely the model is to generate the input text sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d1d53",
   "metadata": {},
   "source": [
    "### gpt2 (on validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a59bc511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\vocab.json\n",
      "loading file merges.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\merges.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--gpt2\\snapshots\\909a290700bd99135e67c64eefc166960b67cfd2\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Using pad_token, but it is not set yet.\n",
      "Assigning <|endoftext|> to the pad_token key of the tokenizer\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [01:00<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perplexities', 'mean_perplexity']\n",
      "112.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "\n",
    "results = perplexity.compute(model_id='gpt2', predictions=validation_data_eng)\n",
    "print(list(results.keys()))\n",
    "print(round(results[\"mean_perplexity\"], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2856b117",
   "metadata": {},
   "source": [
    "### BERT (on validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba77ea32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\pytorch_model.bin\n",
      "If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertLMHeadModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertLMHeadModel for predictions without further training.\n",
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 62/62 [00:43<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "perplexity = load(\"perplexity\", module_type=\"metric\")\n",
    "results = perplexity.compute(predictions=validation_data_eng, model_id='bert-base-cased', add_start_token=False) \n",
    "#perplexity based on the base model, aka the tokenizer used before the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a94421db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3918316.53"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(results[\"mean_perplexity\"], 2) #a lower perplexity indicates a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d811f1",
   "metadata": {},
   "source": [
    "# LAST HIDDEN STATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9da4a87",
   "metadata": {},
   "source": [
    "## TOO MUCH MEMORY NEEDED, use pooled representation? is PCA ok?\n",
    "## used PCA to reduce dimensionality in order to have enough memory to store the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "948b6227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 7389/7389 [34:12<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tensors_train_eng = []\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "for k in tqdm(training_data_eng):#element by element\n",
    "    i = tokenizer(k, return_tensors=\"pt\", padding = True, truncation=True)\n",
    "    o = m(**i, output_hidden_states=True)\n",
    "    tensor_reduced = pca.fit_transform(o.hidden_states[-1][0].detach().numpy())\n",
    "    tensors_train_eng.append(tensor_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6a9b4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#more compression\n",
    "X = []\n",
    "for i in tensors_train_eng:\n",
    "    X.append(np.array(np.mean(np.asmatrix(i), axis=0))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77344866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\vocab.txt\n",
      "loading file tokenizer.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\fiori/.cache\\huggingface\\hub\\models--bert-base-cased\\snapshots\\a8d257ba9925ef39f3036bfc338acf5283c512d9\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 990/990 [04:47<00:00,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "tensors_val_eng = []\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "for k in tqdm(validation_data_eng):#element by element\n",
    "    i = tokenizer(k, return_tensors=\"pt\", padding = True, truncation=True)\n",
    "    o = m(**i, output_hidden_states=True)\n",
    "    tensor_reduced = pca.fit_transform(o.hidden_states[-1][0].detach().numpy())\n",
    "    tensors_val_eng.append(tensor_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c72cb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#more compression\n",
    "X_VAL = []\n",
    "for i in tensors_val_eng:\n",
    "    X_VAL.append(np.array(np.mean(np.asmatrix(i), axis=0))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dbb16305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set accuracy\n",
      "50.02030044660982\n",
      "vald_set accuracy\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X, training_labels_eng)\n",
    "y_pred = LR.predict(X)\n",
    "#training accuracy score\n",
    "print(\"train_set accuracy\")\n",
    "print(accuracy_score(y, y_pred)*100)\n",
    "\n",
    "#accuracy score on val_set\n",
    "y_pred = LR.predict(X_VAL)\n",
    "print(\"vald_set accuracy\")\n",
    "print(accuracy_score(validation_labels_eng, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "155cabcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[matrix([[-3.2564489e-07,  0.0000000e+00, -1.6136867e-07, -4.3613156e-08,\n",
       "           1.4392342e-07]], dtype=float32),\n",
       " matrix([[3.3609666e-07, 1.4704230e-07, 8.6124771e-08, 2.3316707e-07,\n",
       "          4.2012083e-08]], dtype=float32),\n",
       " matrix([[-1.03801284e-07, -5.19006420e-08,  1.03801284e-07,\n",
       "          -3.24379030e-08,  3.85200103e-08]], dtype=float32),\n",
       " matrix([[-6.1307634e-07, -1.1353266e-08, -1.2488593e-07, -1.2346676e-07,\n",
       "          -5.0734904e-08]], dtype=float32),\n",
       " matrix([[ 1.4128508e-07,  1.6483260e-07, -6.7699105e-08,  3.8626890e-08,\n",
       "           2.0456903e-07]], dtype=float32),\n",
       " matrix([[ 6.9247687e-07,  1.8450865e-07,  1.4274742e-07,  1.2148718e-08,\n",
       "          -1.3743237e-07]], dtype=float32),\n",
       " matrix([[-8.1478970e-07, -1.4814358e-07,  1.2962563e-07, -1.5624518e-07,\n",
       "           3.9784652e-08]], dtype=float32),\n",
       " matrix([[-5.8843733e-07,  3.0436414e-08, -5.0727356e-09, -1.8769123e-07,\n",
       "           1.3315932e-07]], dtype=float32),\n",
       " matrix([[-6.90591719e-07, -4.16547408e-07, -1.78128829e-07,\n",
       "          -9.04346322e-08,  1.14113774e-07]], dtype=float32),\n",
       " matrix([[-4.82582209e-07,  9.26385439e-08,  5.74502579e-09,\n",
       "          -1.01256084e-07, -1.79532069e-08]], dtype=float32),\n",
       " matrix([[-1.7339534e-07, -2.8537983e-07,  7.2248056e-09, -3.2511625e-08,\n",
       "           9.6631773e-08]], dtype=float32),\n",
       " matrix([[ 3.0825836e-07,  2.5045992e-07, -8.6697668e-08, -4.7262269e-08,\n",
       "           2.5286820e-08]], dtype=float32),\n",
       " matrix([[ 5.9604645e-08,  8.8303175e-08, -8.8303175e-08, -7.8369069e-08,\n",
       "           2.4835268e-08]], dtype=float32),\n",
       " matrix([[ 1.77427779e-07,  2.88320138e-07,  2.80003206e-07,\n",
       "          -1.12278514e-07, -4.15846344e-08]], dtype=float32),\n",
       " matrix([[ 3.1292439e-07,  3.5390258e-08, -3.1199306e-08,  2.9662624e-07,\n",
       "          -3.1664968e-08]], dtype=float32),\n",
       " matrix([[-4.4672112e-07, -6.6255268e-07, -3.1119899e-07, -3.2123768e-07,\n",
       "           1.2893426e-07]], dtype=float32),\n",
       " matrix([[-3.92458560e-07, -2.31550558e-07,  7.45671258e-08,\n",
       "          -2.65890691e-07, -1.09397824e-07]], dtype=float32),\n",
       " matrix([[-4.7683716e-07, -1.5894572e-07,  1.3789783e-07, -1.3044725e-07,\n",
       "          -1.7583370e-07]], dtype=float32),\n",
       " matrix([[4.82582209e-07, 6.24771559e-08, 1.12791021e-07, 1.50806926e-07,\n",
       "          1.02333274e-07]], dtype=float32),\n",
       " matrix([[-7.1663391e-07,  1.4194863e-07, -2.7562841e-09, -1.4608305e-07,\n",
       "          -3.2407871e-07]], dtype=float32),\n",
       " matrix([[-1.1464937e-06, -6.5662823e-07, -4.1690680e-07, -4.8465415e-07,\n",
       "          -8.0775692e-08]], dtype=float32),\n",
       " matrix([[ 8.0577831e-07,  5.2401089e-07, -2.2664881e-07,  3.8248970e-07,\n",
       "           1.4279615e-07]], dtype=float32),\n",
       " matrix([[ 2.11927627e-07,  1.05963814e-07,  1.36239194e-07,\n",
       "          -5.67663285e-08,  9.46105505e-09]], dtype=float32),\n",
       " matrix([[-1.2507203e-07, -7.8170022e-09, -6.9131616e-08, -2.3451008e-08,\n",
       "          -9.7712531e-09]], dtype=float32),\n",
       " matrix([[-7.8733575e-07, -4.3248022e-07, -3.8535097e-07, -1.4082464e-07,\n",
       "           1.4416007e-07]], dtype=float32),\n",
       " matrix([[2.0699908e-07, 1.9221343e-07, 9.6106717e-08, 6.8845672e-08,\n",
       "          1.2937443e-07]], dtype=float32),\n",
       " matrix([[ 9.7101383e-07,  3.9013948e-08,  3.0560926e-07, -3.5464763e-07,\n",
       "           6.4210461e-08]], dtype=float32),\n",
       " matrix([[4.2701836e-07, 5.3377295e-08, 7.1169723e-08, 6.0049459e-08,\n",
       "          1.9215825e-07]], dtype=float32),\n",
       " matrix([[1.5676838e-07, 1.9269447e-07, 3.5926089e-08, 6.7769662e-08,\n",
       "          5.6759646e-08]], dtype=float32),\n",
       " matrix([[-3.1789146e-08, -1.5894572e-07, -1.2185839e-07,  1.3245477e-07,\n",
       "          -7.3512396e-08]], dtype=float32),\n",
       " matrix([[ 7.1704832e-08,  6.4534355e-08,  1.3130948e-07,  7.1704838e-09,\n",
       "          -7.2601146e-08]], dtype=float32),\n",
       " matrix([[-2.0290942e-08, -1.0145472e-07,  1.2428202e-07,  1.0462517e-07,\n",
       "          -3.4875058e-08]], dtype=float32),\n",
       " matrix([[ 2.6769806e-07, -1.0038677e-07,  5.4376166e-08, -1.8822519e-08,\n",
       "           1.2130069e-07]], dtype=float32),\n",
       " matrix([[-2.98023224e-07,  7.45058060e-09,  2.04890966e-08,\n",
       "          -2.79396772e-08,  1.17346644e-07]], dtype=float32),\n",
       " matrix([[-1.5258789e-07,  3.0517580e-08, -6.9618224e-08, -1.0395050e-07,\n",
       "           3.8862229e-08]], dtype=float32),\n",
       " matrix([[-1.2761539e-06, -8.1013161e-07,  3.6328109e-07, -6.6953834e-07,\n",
       "          -4.5041449e-07]], dtype=float32),\n",
       " matrix([[ 1.0459654e-06, -1.1985020e-07, -1.8201848e-07, -2.8200047e-08,\n",
       "           1.3971841e-07]], dtype=float32),\n",
       " matrix([[5.8939531e-07, 3.1925578e-07, 2.1155812e-07, 2.4660463e-07,\n",
       "          1.4734883e-07]], dtype=float32),\n",
       " matrix([[ 7.5759175e-07,  4.5455505e-07, -2.5401604e-07,  2.6738531e-08,\n",
       "           4.6346790e-07]], dtype=float32),\n",
       " matrix([[-3.3171281e-07, -1.6499257e-07, -1.0020491e-07,  1.0366025e-08,\n",
       "          -1.3950942e-07]], dtype=float32),\n",
       " matrix([[ 7.41746703e-07,  1.03020376e-07, -7.35859800e-08,\n",
       "          -2.47248892e-07, -1.21416875e-07]], dtype=float32),\n",
       " matrix([[ 6.05507537e-08, -4.54130635e-08, -1.07382974e-07,\n",
       "          -3.78442202e-08,  1.55161302e-07]], dtype=float32),\n",
       " matrix([[ 3.0116030e-07, -1.3552214e-07, -5.0193385e-08,  1.4054147e-07,\n",
       "           9.5367433e-08]], dtype=float32),\n",
       " matrix([[-2.5920380e-07, -1.7117232e-07, -1.9807082e-07,  1.4427381e-07,\n",
       "          -5.2421520e-08]], dtype=float32),\n",
       " matrix([[ 1.0561351e-06, -1.3989850e-07,  3.2708664e-07,  2.0196616e-08,\n",
       "           2.2782767e-07]], dtype=float32),\n",
       " matrix([[-5.8715656e-08,  1.8423253e-07,  2.6009300e-07,  7.5860456e-08,\n",
       "          -7.3151156e-08]], dtype=float32),\n",
       " matrix([[-3.7923891e-07, -3.0116030e-07, -2.8164067e-07, -2.1053337e-07,\n",
       "           8.6444160e-08]], dtype=float32),\n",
       " matrix([[-4.59044713e-07, -1.71696968e-07, -4.91071091e-07,\n",
       "          -2.65107218e-07, -1.12092316e-07]], dtype=float32),\n",
       " matrix([[-8.5669046e-07, -1.7780368e-07, -3.4257516e-07,  6.1423094e-08,\n",
       "           2.1496504e-07]], dtype=float32),\n",
       " matrix([[-2.2496934e-06,  1.6709679e-07, -7.4378448e-08, -1.4671913e-07,\n",
       "          -1.6811566e-07]], dtype=float32),\n",
       " matrix([[ 4.6992648e-07,  2.8074652e-07, -1.2007312e-07,  1.0366025e-08,\n",
       "           1.3216682e-07]], dtype=float32),\n",
       " matrix([[1.0250377e-06, 1.3461730e-07, 1.4840340e-07, 6.2037486e-08,\n",
       "          3.7587418e-07]], dtype=float32),\n",
       " matrix([[-9.7455768e-08,  1.6358646e-07,  5.7429293e-08,  6.4390420e-08,\n",
       "          -8.1793232e-08]], dtype=float32),\n",
       " matrix([[-2.7247839e-07, -2.4977186e-07, -1.7597561e-07, -1.4191582e-07,\n",
       "           2.0152046e-07]], dtype=float32),\n",
       " matrix([[-2.4360159e-07, -1.9177146e-07,  6.9970667e-08, -9.3294226e-08,\n",
       "           2.1128875e-07]], dtype=float32),\n",
       " matrix([[-1.2407025e-06, -2.0832691e-07, -3.9350638e-07, -1.8749422e-07,\n",
       "          -3.1234569e-07]], dtype=float32),\n",
       " matrix([[ 2.68220901e-07,  2.08616257e-07, -8.38190317e-09,\n",
       "          -2.27242708e-07,  1.09896064e-07]], dtype=float32),\n",
       " matrix([[ 4.5610509e-08,  8.2928198e-09, -1.3268512e-07, -4.2500702e-08,\n",
       "          -6.6342558e-08]], dtype=float32),\n",
       " matrix([[-8.7074613e-07, -4.7683716e-07,  4.5351358e-09, -1.5549038e-07,\n",
       "           3.1098075e-08]], dtype=float32),\n",
       " matrix([[ 2.1305490e-07, -4.0581885e-08,  2.2827312e-08,  4.3435300e-08,\n",
       "          -8.8772873e-09]], dtype=float32),\n",
       " matrix([[-3.2367129e-07, -1.0403720e-07, -3.3812088e-07,  2.2396897e-08,\n",
       "           6.7551930e-08]], dtype=float32),\n",
       " matrix([[ 3.4679065e-08,  2.6587284e-07,  2.9047104e-07, -7.8027895e-08,\n",
       "           1.6183564e-07]], dtype=float32),\n",
       " matrix([[ 2.8108295e-07,  3.2625699e-08, -6.2428022e-08,  8.3716095e-08,\n",
       "           2.3841858e-08]], dtype=float32),\n",
       " matrix([[-2.8750475e-07, -7.0123114e-08,  2.8049245e-08, -1.3060429e-07,\n",
       "          -3.4886247e-07]], dtype=float32),\n",
       " matrix([[ 1.8673343e-07,  1.1670839e-07, -4.3348834e-08, -8.5030400e-08,\n",
       "          -2.9593915e-08]], dtype=float32),\n",
       " matrix([[ 3.9268943e-07,  3.9444249e-08,  1.2271545e-07,  0.0000000e+00,\n",
       "          -2.0730145e-07]], dtype=float32),\n",
       " matrix([[ 3.3992353e-07, -2.8326960e-08,  9.2062621e-08,  7.4358269e-08,\n",
       "           1.8943655e-07]], dtype=float32),\n",
       " matrix([[ 1.1051926e-06,  3.1640596e-07,  1.4531243e-07, -2.4482469e-07,\n",
       "           2.4853256e-07]], dtype=float32),\n",
       " matrix([[7.0642540e-07, 6.1812223e-08, 4.0619463e-07, 3.7749609e-07,\n",
       "          2.2075794e-08]], dtype=float32),\n",
       " matrix([[-1.0389623e-06, -5.9604645e-08, -1.9383624e-07,  9.2072213e-08,\n",
       "          -2.1176609e-07]], dtype=float32),\n",
       " matrix([[-3.45139284e-07, -1.22615276e-07, -2.40689246e-07,\n",
       "          -1.24885929e-07,  1.13248824e-07]], dtype=float32),\n",
       " matrix([[-4.2217994e-07, -1.0707633e-07,  3.5809904e-08, -7.6331638e-08,\n",
       "           1.3428715e-07]], dtype=float32),\n",
       " matrix([[-1.0981704e-06,  1.8784495e-07, -2.8537983e-07, -1.4548388e-07,\n",
       "           1.2643409e-07]], dtype=float32),\n",
       " matrix([[3.1305396e-07, 5.8049739e-08, 9.1221018e-08, 2.3634537e-07,\n",
       "          2.4463819e-07]], dtype=float32),\n",
       " matrix([[ 8.2611280e-07, -1.2452435e-07,  6.8336536e-09,  8.2763137e-08,\n",
       "           2.4563187e-07]], dtype=float32),\n",
       " matrix([[-5.9665780e-07, -2.0051614e-07, -1.8584423e-07, -4.6461057e-08,\n",
       "          -1.7911960e-07]], dtype=float32),\n",
       " matrix([[-9.1867707e-07,  9.1867712e-08, -1.9139107e-07, -7.6009592e-08,\n",
       "          -1.2659152e-07]], dtype=float32),\n",
       " matrix([[ 5.2018601e-07,  5.9002577e-08,  1.5375289e-07,  1.4509817e-07,\n",
       "          -6.4722215e-08]], dtype=float32),\n",
       " matrix([[-3.9567340e-07, -9.1309246e-08, -1.1667292e-07,  6.9750115e-08,\n",
       "          -1.3315932e-07]], dtype=float32),\n",
       " matrix([[-4.9802992e-07, -3.1789145e-07,  9.8016528e-08, -3.4968059e-07,\n",
       "           7.1525577e-08]], dtype=float32),\n",
       " matrix([[-2.5221138e-07,  1.1231288e-07, -3.5861308e-07, -1.3398730e-07,\n",
       "           1.1939402e-07]], dtype=float32),\n",
       " matrix([[-1.5745227e-06, -2.1281659e-07, -2.8482219e-07, -1.3121023e-07,\n",
       "           1.8321428e-07]], dtype=float32),\n",
       " matrix([[-3.1140385e-07, -2.2382153e-07,  1.8611246e-07, -1.4597056e-08,\n",
       "          -2.7612765e-07]], dtype=float32),\n",
       " matrix([[ 6.4556417e-07, -7.3359563e-09,  1.2700374e-07,  8.6197488e-08,\n",
       "           8.6197488e-08]], dtype=float32),\n",
       " matrix([[ 7.7220591e-08,  7.3359566e-08, -2.2200920e-08, -1.6698954e-07,\n",
       "          -2.8957723e-09]], dtype=float32),\n",
       " matrix([[1.0640998e-06, 1.3050280e-07, 1.9449936e-07, 3.1245384e-07,\n",
       "          1.7818651e-07]], dtype=float32),\n",
       " matrix([[8.7838424e-07, 3.7645037e-08, 1.4528632e-07, 1.7097122e-07,\n",
       "          7.5290075e-08]], dtype=float32),\n",
       " matrix([[8.6115369e-07, 5.3733140e-07, 1.6191113e-07, 9.7413562e-08,\n",
       "          3.1136756e-07]], dtype=float32),\n",
       " matrix([[-1.4805903e-07, -1.0015758e-07,  1.3499499e-07,  1.9903936e-07,\n",
       "          -2.4957743e-07]], dtype=float32),\n",
       " matrix([[-2.8649475e-07, -1.8445553e-07, -1.6090802e-07, -1.7366291e-07,\n",
       "           9.8114645e-09]], dtype=float32),\n",
       " matrix([[-5.8884586e-07, -1.8561447e-07, -1.7361353e-07,  5.1604022e-08,\n",
       "          -2.0001560e-08]], dtype=float32),\n",
       " matrix([[ 3.8532295e-07, -1.9266148e-08, -3.8532296e-08,  2.3119378e-07,\n",
       "           1.0475968e-07]], dtype=float32),\n",
       " matrix([[ 1.0644886e-06,  9.5367432e-07,  7.3036681e-08,  3.2740580e-08,\n",
       "          -5.2049128e-08]], dtype=float32),\n",
       " matrix([[ 3.0711547e-07, -9.4963333e-08,  8.3513854e-08, -1.2122978e-08,\n",
       "           8.4187349e-08]], dtype=float32),\n",
       " matrix([[-3.8146972e-08,  9.5367430e-09, -9.1393787e-08,  1.6540289e-07,\n",
       "          -6.3578291e-08]], dtype=float32),\n",
       " matrix([[-2.9550472e-07, -9.5913109e-08, -2.4681361e-07,  3.5426987e-07,\n",
       "           6.7160162e-09]], dtype=float32),\n",
       " matrix([[ 3.7703404e-07, -7.2080034e-08,  5.5446183e-08, -2.7723091e-08,\n",
       "          -1.1851621e-07]], dtype=float32),\n",
       " matrix([[ 5.2981907e-08,  7.9472862e-08,  2.5497542e-07, -1.3411045e-07,\n",
       "           1.9081764e-07]], dtype=float32),\n",
       " matrix([[ 6.5251402e-07, -1.7881393e-07, -9.4112593e-09,  8.0779976e-08,\n",
       "           2.3057586e-07]], dtype=float32),\n",
       " matrix([[ 1.9426699e-07,  1.6612036e-07,  1.8764425e-07, -1.4349267e-08,\n",
       "           2.2627690e-08]], dtype=float32),\n",
       " matrix([[ 9.2477512e-07,  9.3922473e-08,  3.3505034e-07, -1.4449611e-08,\n",
       "          -2.2803292e-08]], dtype=float32),\n",
       " matrix([[-1.3449253e-06, -2.2924863e-07, -2.8732495e-07, -1.5588907e-07,\n",
       "          -4.9097416e-08]], dtype=float32),\n",
       " matrix([[-4.4504802e-07, -6.3578291e-08,  7.7486035e-08, -2.8014182e-07,\n",
       "          -1.8725792e-07]], dtype=float32),\n",
       " matrix([[-2.18876067e-07, -2.05847741e-07,  8.07756919e-08,\n",
       "          -1.09438034e-07,  2.89880511e-08]], dtype=float32),\n",
       " matrix([[1.78676908e-06, 5.20684239e-07, 1.53464839e-07, 2.44584584e-07,\n",
       "          1.18181624e-07]], dtype=float32),\n",
       " matrix([[3.7398994e-08, 1.7764522e-07, 1.0109415e-07, 2.9451706e-07,\n",
       "          1.2972775e-07]], dtype=float32),\n",
       " matrix([[-2.8207268e-07, -1.8206700e-07, -2.6864065e-08,  2.9382571e-08,\n",
       "           1.6790041e-08]], dtype=float32),\n",
       " matrix([[ 5.8174135e-07,  4.7683717e-08,  2.8610231e-07,  4.4107438e-08,\n",
       "          -2.8610229e-08]], dtype=float32),\n",
       " matrix([[-6.7268098e-07, -7.9827650e-08, -4.6832220e-08,  2.9270138e-08,\n",
       "          -2.1925995e-07]], dtype=float32),\n",
       " matrix([[ 1.0652745e-06, -2.6378225e-07, -2.0449466e-08, -1.0145472e-07,\n",
       "           1.2265717e-07]], dtype=float32),\n",
       " matrix([[ 7.7850967e-07,  8.4338545e-08, -3.4059799e-08,  2.4166238e-07,\n",
       "           1.9097814e-07]], dtype=float32),\n",
       " matrix([[-5.2756451e-07, -3.9567340e-07, -2.1812764e-07, -1.8261849e-07,\n",
       "          -7.8627401e-08]], dtype=float32),\n",
       " matrix([[-1.3602086e-07,  8.5586159e-08, -2.3326048e-07,  9.1699455e-08,\n",
       "           1.0392605e-07]], dtype=float32),\n",
       " matrix([[-4.6004712e-07,  1.4103634e-07, -2.8543070e-08,  7.7863817e-08,\n",
       "           7.1567548e-08]], dtype=float32),\n",
       " matrix([[-6.8989203e-07,  9.1309246e-08, -2.1643672e-07, -1.1498201e-07,\n",
       "          -4.6838261e-07]], dtype=float32),\n",
       " matrix([[-1.0868690e-06, -1.0122800e-07, -1.5700330e-07,  1.4984408e-07,\n",
       "          -6.6514119e-08]], dtype=float32),\n",
       " matrix([[-1.21116636e-06, -1.14440915e-07, -8.58306919e-08,\n",
       "           8.10623177e-08, -5.37931903e-08]], dtype=float32),\n",
       " matrix([[-6.1307634e-07, -1.7516467e-07, -2.1895584e-08, -3.0653817e-07,\n",
       "           5.8388224e-08]], dtype=float32),\n",
       " matrix([[5.0028814e-07, 1.6806555e-07, 1.7832537e-07, 1.7114960e-08,\n",
       "          1.5145442e-08]], dtype=float32),\n",
       " matrix([[ 5.32778927e-07, -2.83704793e-07,  1.14547476e-07,\n",
       "           7.72529489e-08,  5.11967286e-08]], dtype=float32),\n",
       " matrix([[-3.3824901e-07,  1.3154128e-07,  2.2315039e-08,  9.3958059e-09,\n",
       "           6.6357877e-08]], dtype=float32),\n",
       " matrix([[ 4.1439421e-07, -2.9329270e-08,  1.3955055e-07,  2.7626280e-07,\n",
       "          -4.5413064e-08]], dtype=float32),\n",
       " matrix([[9.83949704e-08, 6.81195971e-08, 1.51376884e-08, 1.13532657e-07,\n",
       "          1.03125494e-07]], dtype=float32),\n",
       " matrix([[-3.0003238e-07, -1.7278650e-07, -2.5047345e-07, -1.5269505e-07,\n",
       "           9.6313407e-08]], dtype=float32),\n",
       " matrix([[-1.1270696e-06,  4.3792173e-07,  8.6697668e-08,  4.1193704e-08,\n",
       "          -2.9900843e-07]], dtype=float32),\n",
       " matrix([[-4.9146405e-07, -2.0569088e-07, -1.6089598e-07, -1.6089597e-08,\n",
       "          -7.1489005e-08]], dtype=float32),\n",
       " matrix([[-4.3934995e-07, -1.1096211e-06,  6.5977468e-07, -1.0076559e-06,\n",
       "          -5.6980542e-07]], dtype=float32),\n",
       " matrix([[-2.2980105e-07, -2.2980103e-08,  0.0000000e+00,  9.3356675e-08,\n",
       "           9.4792931e-08]], dtype=float32),\n",
       " matrix([[ 1.0234554e-06, -3.2564489e-07,  2.6361730e-07,  9.7887302e-08,\n",
       "          -3.4405934e-07]], dtype=float32),\n",
       " matrix([[-7.9842499e-07, -3.7703404e-07, -1.6264214e-07, -1.8482061e-07,\n",
       "          -2.8647193e-08]], dtype=float32),\n",
       " matrix([[1.6442661e-07, 1.2057951e-07, 2.7404434e-08, 9.3175075e-08,\n",
       "          5.4808869e-09]], dtype=float32),\n",
       " matrix([[ 5.9604645e-07,  4.0729842e-07, -7.4505806e-08,  1.9868216e-08,\n",
       "           7.5437129e-08]], dtype=float32),\n",
       " matrix([[ 2.2706532e-08, -3.6898115e-08,  2.2706531e-07,  2.7354275e-07,\n",
       "          -8.0182438e-08]], dtype=float32),\n",
       " matrix([[1.0982621e-06, 1.0468066e-06, 2.7008355e-08, 9.9185854e-08,\n",
       "          7.6368451e-08]], dtype=float32),\n",
       " matrix([[ 2.2587024e-07,  8.7838423e-08,  2.0077354e-07, -1.7253976e-07,\n",
       "          -2.1959606e-08]], dtype=float32),\n",
       " matrix([[-3.5321271e-08,  2.4724889e-07,  1.4128508e-07, -3.8264709e-08,\n",
       "           1.3834165e-07]], dtype=float32),\n",
       " matrix([[ 1.9491154e-07, -1.7402815e-08, -9.6096173e-08,  8.2445844e-08,\n",
       "          -7.4723339e-08]], dtype=float32),\n",
       " matrix([[-8.1603059e-07, -4.5225792e-07, -2.6545572e-07, -1.3641476e-07,\n",
       "           1.2904098e-07]], dtype=float32),\n",
       " matrix([[-9.7585280e-07, -8.7604968e-07,  8.3169276e-09, -3.7133780e-08,\n",
       "          -5.5446183e-08]], dtype=float32),\n",
       " matrix([[ 1.3411045e-07, -4.9670536e-08, -4.5324366e-08, -2.9802322e-08,\n",
       "           6.2088169e-08]], dtype=float32),\n",
       " matrix([[-8.4310341e-07,  1.4512435e-07, -3.0234241e-07,  1.7276708e-08,\n",
       "          -1.9004380e-08]], dtype=float32),\n",
       " matrix([[-1.0149195e-06, -2.4060591e-07, -1.5092552e-07, -2.8653977e-07,\n",
       "          -2.0779601e-07]], dtype=float32),\n",
       " matrix([[-3.4877232e-07,  1.9209726e-07, -1.8256051e-07,  1.1989049e-07,\n",
       "          -1.7438616e-07]], dtype=float32),\n",
       " matrix([[ 5.2495835e-08,  9.6242360e-08, -4.3746528e-08,  5.6870487e-08,\n",
       "          -6.3432466e-08]], dtype=float32),\n",
       " matrix([[-1.4086954e-06, -3.7710652e-07, -9.3497485e-09, -4.7216227e-07,\n",
       "           2.0024044e-07]], dtype=float32),\n",
       " matrix([[-8.7420148e-07, -2.2075795e-09, -6.6227386e-08, -3.1789145e-07,\n",
       "          -8.7268376e-08]], dtype=float32),\n",
       " matrix([[ 6.8425067e-08, -4.2765667e-09, -5.7733647e-08, -1.0156845e-07,\n",
       "           7.8448267e-08]], dtype=float32),\n",
       " matrix([[ 2.6876276e-07,  3.4679065e-08, -8.6697662e-09, -1.9940462e-07,\n",
       "          -6.7190690e-08]], dtype=float32),\n",
       " matrix([[ 5.5101185e-07,  1.3642841e-07,  1.9735761e-07, -1.6821755e-07,\n",
       "          -1.2185839e-07]], dtype=float32),\n",
       " matrix([[-2.2114187e-07, -1.6132127e-07,  3.1098075e-08, -7.0402585e-08,\n",
       "           2.2459721e-08]], dtype=float32),\n",
       " matrix([[-4.8155835e-07, -4.3434673e-07,  2.3133684e-07, -1.1094726e-07,\n",
       "          -8.9702041e-08]], dtype=float32),\n",
       " matrix([[-3.2660080e-07,  6.5320158e-08, -5.2256127e-08,  8.8998718e-08,\n",
       "          -2.5005374e-08]], dtype=float32),\n",
       " matrix([[6.7318190e-08, 5.6098490e-09, 9.5367433e-08, 1.1570314e-08,\n",
       "          2.5244320e-08]], dtype=float32),\n",
       " matrix([[ 2.2125244e-07,  2.2888184e-08,  8.5830692e-08,  1.6939640e-07,\n",
       "          -7.3432922e-08]], dtype=float32),\n",
       " matrix([[ 4.7039342e-07,  6.4437451e-08,  3.0124511e-07, -1.3249951e-07,\n",
       "          -4.8328088e-09]], dtype=float32),\n",
       " matrix([[-5.4836274e-08, -2.6702881e-07, -3.5285950e-07, -1.3828277e-07,\n",
       "          -7.6293944e-08]], dtype=float32),\n",
       " matrix([[ 2.0154089e-07,  1.6466319e-07,  3.4712201e-07,  1.1149070e-07,\n",
       "          -5.8747023e-08]], dtype=float32),\n",
       " matrix([[ 2.0385419e-06,  3.2546029e-07,  4.4498495e-07,  4.2133232e-07,\n",
       "          -7.5057699e-08]], dtype=float32),\n",
       " matrix([[ 2.2942166e-07,  2.7890476e-07, -2.2492319e-09, -1.4395084e-07,\n",
       "          -2.6990783e-08]], dtype=float32),\n",
       " matrix([[5.4041544e-07, 2.8014182e-07, 2.3345153e-07, 1.5695890e-07,\n",
       "          2.9057265e-08]], dtype=float32),\n",
       " matrix([[-3.1972897e-07, -8.1654917e-08,  6.8562571e-08,  8.5444810e-08,\n",
       "          -9.0957379e-08]], dtype=float32),\n",
       " matrix([[ 9.8826355e-08, -2.7177247e-08,  1.3588624e-07,  1.2723893e-07,\n",
       "          -1.1426797e-08]], dtype=float32),\n",
       " matrix([[-2.18876067e-07, -1.65012040e-07,  1.78813934e-07,\n",
       "          -5.32533306e-08, -1.10415165e-07]], dtype=float32),\n",
       " matrix([[-4.6083591e-07, -1.3121023e-07,  5.7604488e-08,  3.9303064e-08,\n",
       "          -6.0804737e-08]], dtype=float32),\n",
       " matrix([[-4.8008093e-07, -3.9736431e-08, -1.2143940e-07, -3.7303586e-08,\n",
       "           4.6743523e-08]], dtype=float32),\n",
       " matrix([[-1.2466332e-07, -2.2751054e-07, -5.6098489e-08, -1.9634471e-07,\n",
       "          -2.0101959e-07]], dtype=float32),\n",
       " matrix([[-9.0101747e-07, -1.7625423e-07,  7.0209154e-08,  3.3641886e-08,\n",
       "          -2.4865741e-08]], dtype=float32),\n",
       " matrix([[-2.1409015e-07,  7.1768859e-08,  8.2716653e-08, -2.8038511e-07,\n",
       "           1.7638110e-08]], dtype=float32),\n",
       " matrix([[-9.74557679e-08, -2.26236612e-08,  1.84469855e-07,\n",
       "           6.30852099e-08,  1.12248166e-07]], dtype=float32),\n",
       " matrix([[ 2.4151493e-07, -4.6445177e-08,  6.9667763e-08,  6.6184377e-08,\n",
       "          -3.1350496e-08]], dtype=float32),\n",
       " matrix([[-3.8442687e-07, -2.9571297e-08, -2.5690065e-07, -6.6535421e-08,\n",
       "           7.2773112e-09]], dtype=float32),\n",
       " matrix([[ 5.1606912e-07,  1.0652002e-07,  1.5578553e-07, -2.3122993e-07,\n",
       "           9.1851689e-08]], dtype=float32),\n",
       " matrix([[ 6.0343109e-07, -2.5318787e-08, -2.1520970e-07,  1.2342909e-07,\n",
       "           1.4241817e-07]], dtype=float32),\n",
       " matrix([[ 5.7070275e-07,  5.6319351e-08,  1.2601454e-07,  1.6426478e-07,\n",
       "          -5.8665988e-09]], dtype=float32),\n",
       " matrix([[-7.3737705e-09, -7.8653549e-08,  1.8188634e-07,  6.2677046e-08,\n",
       "          -1.7159378e-07]], dtype=float32),\n",
       " matrix([[ 5.7001222e-07, -3.1789145e-07,  9.4545300e-08,  1.2606040e-07,\n",
       "           1.3702217e-08]], dtype=float32),\n",
       " matrix([[ 7.5688440e-08, -3.1032260e-07, -1.1826318e-07, -2.6490953e-08,\n",
       "           1.9300552e-07]], dtype=float32),\n",
       " matrix([[-3.0670932e-07, -5.4153367e-07,  1.1741216e-07, -1.0183708e-07,\n",
       "          -1.2699684e-07]], dtype=float32),\n",
       " matrix([[-2.0861626e-07, -5.6810677e-08, -1.3411045e-07, -1.1548400e-07,\n",
       "           8.2887709e-08]], dtype=float32),\n",
       " matrix([[ 1.6585641e-07,  1.6585641e-07,  1.3734983e-07,  1.7832802e-07,\n",
       "          -1.5549038e-07]], dtype=float32),\n",
       " matrix([[-7.5636240e-07, -4.1791761e-08, -6.7277887e-07,  2.6034213e-08,\n",
       "          -1.4764139e-07]], dtype=float32),\n",
       " matrix([[-3.4863095e-07, -3.0589553e-07, -2.2492319e-09,  4.0486174e-08,\n",
       "           2.0243087e-08]], dtype=float32),\n",
       " matrix([[ 1.3821366e-07,  2.7642734e-08,  1.9954598e-07, -8.6383540e-09,\n",
       "          -3.1098075e-08]], dtype=float32),\n",
       " matrix([[ 2.8545352e-07, -1.2975161e-07,  1.1353266e-07, -7.7850963e-08,\n",
       "           5.8388224e-08]], dtype=float32),\n",
       " matrix([[ 1.25122074e-06,  1.14440915e-07,  7.58171055e-08,\n",
       "           3.48091135e-07, -8.22544095e-08]], dtype=float32),\n",
       " matrix([[ 4.6548388e-07, -2.0719710e-07,  1.4475414e-07,  6.8119597e-08,\n",
       "           1.2240240e-07]], dtype=float32),\n",
       " matrix([[-2.7939677e-07, -8.9406967e-08,  0.0000000e+00, -2.9802322e-08,\n",
       "           8.8475645e-08]], dtype=float32),\n",
       " matrix([[ 5.5285466e-07,  6.9106836e-09, -1.1057094e-07, -1.3907750e-07,\n",
       "          -2.0300132e-07]], dtype=float32),\n",
       " matrix([[-1.2558951e-06,  1.3599933e-07,  2.9382571e-08,  1.6790040e-09,\n",
       "          -8.3215639e-08]], dtype=float32),\n",
       " matrix([[-1.07490405e-06, -4.84919155e-07, -5.41493023e-07,\n",
       "          -1.17378214e-07, -1.47496237e-07]], dtype=float32),\n",
       " matrix([[-1.3351440e-07,  0.0000000e+00, -1.0299683e-07, -1.3351441e-08,\n",
       "          -4.5776368e-08]], dtype=float32),\n",
       " matrix([[-1.3432032e-08, -6.7160162e-09,  3.3580083e-08,  6.0444144e-08,\n",
       "           6.0758957e-08]], dtype=float32),\n",
       " matrix([[-7.4330501e-07, -1.4024623e-07, -8.5900808e-08,  8.5900808e-08,\n",
       "           2.2790012e-08]], dtype=float32),\n",
       " matrix([[-8.4771051e-07, -4.1138892e-07, -3.8957286e-09, -4.5190450e-08,\n",
       "          -5.2981907e-08]], dtype=float32),\n",
       " matrix([[ 9.3212236e-07,  3.8793530e-07, -1.0102482e-08, -1.5086373e-07,\n",
       "           2.3168359e-07]], dtype=float32),\n",
       " matrix([[1.73874326e-07, 1.15916215e-07, 8.69371632e-08, 7.90337840e-09,\n",
       "          2.48627117e-07]], dtype=float32),\n",
       " matrix([[-2.0492175e-07, -6.3052845e-08, -8.4727262e-08, -1.2684460e-07,\n",
       "          -9.5564474e-08]], dtype=float32),\n",
       " matrix([[ 8.6697668e-07,  3.3956584e-07,  2.2396897e-07, -3.2511625e-07,\n",
       "           3.3956584e-07]], dtype=float32),\n",
       " matrix([[-8.8713890e-08, -2.7723090e-07, -3.0495400e-08,  5.6832334e-08,\n",
       "           3.6040017e-08]], dtype=float32),\n",
       " matrix([[ 1.6633855e-08,  2.8092731e-07, -1.8482060e-08,  2.4396320e-07,\n",
       "           6.9307724e-08]], dtype=float32),\n",
       " matrix([[ 1.8384083e-07,  0.0000000e+00, -2.5852618e-08, -4.8832721e-08,\n",
       "           1.2459525e-07]], dtype=float32),\n",
       " matrix([[ 1.9277481e-06, -1.0531217e-06,  2.2949381e-08, -8.1597804e-08,\n",
       "           4.0543907e-07]], dtype=float32),\n",
       " matrix([[ 2.0604075e-08, -1.5011540e-07, -1.7513463e-07, -1.4717196e-07,\n",
       "          -6.0156538e-08]], dtype=float32),\n",
       " matrix([[-6.2319310e-07, -1.6760119e-07,  3.5408700e-08, -1.6524060e-08,\n",
       "          -8.6161172e-08]], dtype=float32),\n",
       " matrix([[-5.2452089e-07, -4.7683717e-08,  1.1473894e-07,  1.4454126e-07,\n",
       "           8.6054207e-08]], dtype=float32),\n",
       " matrix([[-6.3578290e-07, -1.5440442e-07, -2.2025336e-07, -1.5326908e-07,\n",
       "           1.4759245e-08]], dtype=float32),\n",
       " matrix([[ 5.3738790e-07, -1.5705351e-07,  1.7029899e-08,  5.8658539e-08,\n",
       "          -1.3529308e-07]], dtype=float32),\n",
       " matrix([[ 4.87158331e-07,  1.13532657e-07, -1.03211505e-07,\n",
       "          -1.03211506e-09,  1.38819473e-07]], dtype=float32),\n",
       " matrix([[-8.8576564e-07, -6.4956147e-08, -2.7680176e-07, -1.8047474e-07,\n",
       "          -1.7530779e-08]], dtype=float32),\n",
       " matrix([[ 3.0275376e-07, -5.6766329e-09, -5.6766329e-08,  7.0957911e-09,\n",
       "           1.3600266e-08]], dtype=float32),\n",
       " matrix([[2.8257017e-07, 8.4771051e-07, 4.7297388e-07, 1.5453055e-07,\n",
       "          1.8322909e-07]], dtype=float32),\n",
       " matrix([[1.1460822e-06, 6.1068619e-07, 2.6769806e-07, 1.8613380e-07,\n",
       "          2.7083513e-07]], dtype=float32),\n",
       " matrix([[ 2.8207268e-07, -2.2834456e-07, -9.4024230e-08, -8.3950205e-08,\n",
       "          -8.2271200e-08]], dtype=float32),\n",
       " matrix([[-2.6661863e-07, -2.4610949e-07, -7.6268307e-08, -1.3587295e-07,\n",
       "          -1.6771818e-07]], dtype=float32),\n",
       " matrix([[-8.9128440e-07,  3.3200345e-07, -1.2700802e-07, -2.0778067e-07,\n",
       "           4.4564219e-09]], dtype=float32),\n",
       " matrix([[-1.3563368e-07, -7.2055393e-08, -4.7683717e-08, -2.7550593e-07,\n",
       "          -2.6702881e-07]], dtype=float32),\n",
       " matrix([[-5.1549961e-07, -2.2553108e-07, -1.0551633e-07, -5.7993709e-08,\n",
       "          -4.1239971e-07]], dtype=float32),\n",
       " matrix([[ 9.81723588e-07,  5.49297710e-08, -2.36081135e-07,\n",
       "           2.28484467e-07, -1.04673354e-07]], dtype=float32),\n",
       " matrix([[-1.5641855e-06, -3.9902690e-09, -2.8879572e-07,  3.2420935e-08,\n",
       "          -1.9103413e-07]], dtype=float32),\n",
       " matrix([[ 1.00183968e-06, -1.30046502e-07,  1.05963814e-07,\n",
       "           9.69328084e-08,  1.54129182e-07]], dtype=float32),\n",
       " matrix([[-3.9013949e-07, -5.4186042e-08,  1.0385658e-07, -1.8965114e-08,\n",
       "           5.6895342e-08]], dtype=float32),\n",
       " matrix([[-1.9073486e-06,  6.1988828e-07, -2.1934510e-07, -1.1786818e-07,\n",
       "          -2.2629276e-07]], dtype=float32),\n",
       " matrix([[-1.14440915e-07, -2.70605085e-07, -5.90085989e-08,\n",
       "           9.65595248e-08,  1.04606151e-07]], dtype=float32),\n",
       " matrix([[-5.5770425e-07, -5.5770428e-08, -2.2587024e-07, -2.1785323e-07,\n",
       "          -1.2095211e-07]], dtype=float32),\n",
       " matrix([[-6.8233601e-07, -1.4364969e-07, -1.1571780e-07,  1.3267645e-07,\n",
       "           2.5188573e-08]], dtype=float32),\n",
       " matrix([[ 2.3072765e-07,  1.3459113e-07,  4.2300069e-08, -4.4658421e-08,\n",
       "           8.1475704e-08]], dtype=float32),\n",
       " matrix([[-6.3578291e-08, -1.9073487e-07,  1.4702479e-07, -2.9802322e-08,\n",
       "          -2.5331975e-08]], dtype=float32),\n",
       " matrix([[-3.8875896e-07, -1.1541282e-07, -1.0630128e-07,  3.4168266e-08,\n",
       "          -6.0553766e-08]], dtype=float32),\n",
       " matrix([[ 4.4878792e-07,  1.8432361e-07,  2.8550124e-08, -8.0140703e-09,\n",
       "           2.5294408e-08]], dtype=float32),\n",
       " matrix([[ 1.9771296e-07,  1.2211683e-07,  1.3374701e-07, -3.5617411e-08,\n",
       "           4.8519635e-08]], dtype=float32),\n",
       " matrix([[ 4.5776366e-07,  5.9405963e-08, -2.9404958e-07, -9.8546344e-08,\n",
       "           1.1603038e-07]], dtype=float32),\n",
       " matrix([[ 5.6573901e-07,  1.0102482e-06, -2.2225461e-08,  3.3540240e-07,\n",
       "           6.6676385e-08]], dtype=float32),\n",
       " matrix([[ 4.0266249e-07,  9.0069243e-08,  3.9363901e-08, -6.4902835e-08,\n",
       "           1.6490618e-07]], dtype=float32),\n",
       " matrix([[-4.9212929e-07, -4.9015263e-08,  1.6682350e-07, -1.9184702e-07,\n",
       "          -4.4347246e-07]], dtype=float32),\n",
       " matrix([[-6.4777879e-07,  7.6473881e-08,  1.2520724e-07, -1.1995904e-07,\n",
       "          -8.0972349e-08]], dtype=float32),\n",
       " matrix([[-7.4635381e-07, -1.1402628e-07, -1.4857969e-07,  2.3107597e-07,\n",
       "           9.9772990e-08]], dtype=float32),\n",
       " matrix([[-8.3257282e-07, -4.9449778e-07, -1.4885393e-07, -2.0068524e-07,\n",
       "           3.1852217e-08]], dtype=float32),\n",
       " matrix([[-2.06629437e-07, -3.70873352e-07,  4.83459885e-08,\n",
       "          -1.37752963e-07,  1.11262004e-07]], dtype=float32),\n",
       " matrix([[ 4.1106651e-07,  1.7264793e-07,  1.0584963e-07, -1.1385820e-07,\n",
       "          -8.8379302e-08]], dtype=float32),\n",
       " matrix([[ 7.5470632e-07,  1.3721933e-07,  2.4913885e-07,  6.6894422e-08,\n",
       "          -1.2521264e-07]], dtype=float32),\n",
       " matrix([[-1.6391277e-07, -2.9802322e-08,  1.5832484e-08, -1.1874363e-07,\n",
       "          -9.7323209e-08]], dtype=float32),\n",
       " matrix([[-1.3067172e-06, -1.6139104e-06,  5.0205449e-07, -4.9746956e-07,\n",
       "          -2.3232916e-07]], dtype=float32),\n",
       " matrix([[ 1.3268512e-07, -3.3171279e-08, -4.1464099e-09,  1.0521516e-07,\n",
       "          -3.1098075e-09]], dtype=float32),\n",
       " matrix([[ 7.2294665e-07,  4.2300069e-08,  1.4324343e-07, -1.6343209e-08,\n",
       "           7.7269732e-08]], dtype=float32),\n",
       " matrix([[ 6.2995002e-07,  2.0123403e-07,  4.1340471e-07,  2.6685382e-07,\n",
       "          -8.9680384e-08]], dtype=float32),\n",
       " matrix([[ 9.3497482e-07, -7.7062374e-08,  5.1423615e-07, -9.3205301e-08,\n",
       "           7.1584012e-08]], dtype=float32),\n",
       " matrix([[-1.0933846e-07,  2.3082563e-07,  3.0371794e-09,  5.4669229e-08,\n",
       "           4.8594870e-08]], dtype=float32),\n",
       " matrix([[-3.7831708e-07,  1.6551373e-07,  7.0934455e-08, -7.5860456e-08,\n",
       "          -1.7438053e-07]], dtype=float32),\n",
       " matrix([[ 7.6439545e-07,  2.3295861e-07,  1.8927888e-07, -4.3679741e-08,\n",
       "           2.5479849e-07]], dtype=float32),\n",
       " matrix([[-5.0108309e-07, -1.7780368e-07, -3.1267183e-07, -4.5713733e-08,\n",
       "           1.8184467e-08]], dtype=float32),\n",
       " matrix([[ 6.4247536e-07,  6.1251612e-08, -5.0193387e-09,  1.3803181e-07,\n",
       "          -5.2703054e-08]], dtype=float32),\n",
       " matrix([[-7.4582221e-07,  1.2837924e-07,  2.1090874e-07, -2.4911685e-07,\n",
       "           1.8951221e-07]], dtype=float32),\n",
       " matrix([[5.80012454e-07, 8.36556424e-08, 1.14329374e-07, 5.57704283e-09,\n",
       "          1.51277291e-07]], dtype=float32),\n",
       " matrix([[-4.09843494e-07, -4.41369934e-07, -2.36448177e-08,\n",
       "          -1.37928104e-08, -4.60088756e-07]], dtype=float32),\n",
       " matrix([[ 4.9273171e-07,  1.9073487e-07, -1.5894573e-08,  9.1393787e-08,\n",
       "          -1.2467305e-07]], dtype=float32),\n",
       " matrix([[ 2.4165504e-07, -3.0206881e-08, -2.0605407e-07,  1.7692601e-07,\n",
       "          -2.0807684e-07]], dtype=float32),\n",
       " matrix([[ 3.2648310e-07, -1.2887490e-07,  1.1598742e-07, -1.6216759e-07,\n",
       "           1.7398112e-07]], dtype=float32),\n",
       " matrix([[ 4.6624078e-07,  2.9669869e-07,  5.5796569e-08, -1.1920929e-07,\n",
       "          -5.5299864e-08]], dtype=float32),\n",
       " matrix([[ 6.1926904e-08, -2.1674417e-08, -1.1379068e-07,  1.2385381e-08,\n",
       "           6.9667763e-08]], dtype=float32),\n",
       " matrix([[ 1.2500866e-06,  8.0224629e-07, -3.1413259e-07,  1.2887490e-07,\n",
       "          -1.6109363e-08]], dtype=float32),\n",
       " matrix([[-2.66141683e-07,  1.12740565e-07, -1.14588772e-07,\n",
       "          -1.58945724e-07, -1.25678014e-07]], dtype=float32),\n",
       " matrix([[ 4.2130191e-07, -6.1280275e-08, -9.1920413e-08,  1.8192582e-08,\n",
       "          -1.3093872e-07]], dtype=float32),\n",
       " matrix([[ 2.9764357e-07, -4.5557691e-09,  2.3082563e-07,  1.4578461e-07,\n",
       "           1.3363589e-07]], dtype=float32),\n",
       " matrix([[ 8.4486584e-07,  2.2721771e-07, -3.2002493e-08,  1.7761384e-07,\n",
       "          -1.9201496e-08]], dtype=float32),\n",
       " matrix([[ 4.1018250e-08, -1.5381843e-08, -5.2554633e-08, -2.2752310e-08,\n",
       "           2.3713676e-08]], dtype=float32),\n",
       " matrix([[-2.1923547e-07,  2.6856347e-07, -1.1235818e-07, -1.8086926e-07,\n",
       "          -3.3912986e-08]], dtype=float32),\n",
       " matrix([[-1.3623919e-06,  7.5514158e-08,  1.6850636e-07, -2.5634478e-07,\n",
       "           6.1397266e-08]], dtype=float32),\n",
       " matrix([[-1.8458212e-07, -1.5381843e-07, -1.8169803e-07, -3.6531880e-08,\n",
       "           1.0815359e-07]], dtype=float32),\n",
       " matrix([[ 6.6283746e-07, -6.0872829e-08,  1.3907750e-07,  1.3009453e-07,\n",
       "           1.4964570e-07]], dtype=float32),\n",
       " matrix([[-1.0309993e-07, -1.5464988e-07, -2.0942172e-08, -1.2565303e-07,\n",
       "           6.5645658e-08]], dtype=float32),\n",
       " matrix([[-5.8507629e-07, -1.2871678e-07, -2.4500068e-07, -3.0533666e-08,\n",
       "           2.1026179e-09]], dtype=float32),\n",
       " matrix([[ 9.84046096e-07, -3.64461528e-08,  4.03755024e-07,\n",
       "           3.55349982e-07,  1.05162336e-07]], dtype=float32),\n",
       " matrix([[-5.2113353e-07, -5.6673269e-08, -3.6479346e-08, -1.0878662e-07,\n",
       "          -1.5975999e-07]], dtype=float32),\n",
       " matrix([[-8.9303609e-07,  2.7011583e-07,  3.3316584e-07, -3.1146010e-07,\n",
       "          -2.0051968e-07]], dtype=float32),\n",
       " matrix([[4.9756920e-07, 2.8506570e-08, 2.1509503e-07, 1.0366025e-07,\n",
       "          1.9792630e-07]], dtype=float32),\n",
       " matrix([[7.8376684e-07, 4.8231806e-07, 9.0434632e-08, 2.2745681e-07,\n",
       "          9.8655967e-08]], dtype=float32),\n",
       " matrix([[8.8303178e-09, 2.0309731e-07, 6.6227384e-09, 5.2981907e-08,\n",
       "          6.2916016e-08]], dtype=float32),\n",
       " matrix([[ 3.9608247e-07, -4.9990991e-08,  3.8454610e-07, -8.4600138e-08,\n",
       "           9.8059253e-08]], dtype=float32),\n",
       " matrix([[ 2.0435878e-07,  2.2564616e-07,  2.8383165e-09,  7.3796230e-08,\n",
       "          -1.3934360e-07]], dtype=float32),\n",
       " matrix([[-3.4890525e-07, -1.6645687e-07,  5.5243330e-08, -6.9781045e-08,\n",
       "          -3.1636574e-07]], dtype=float32),\n",
       " matrix([[-1.8352686e-06,  2.8762706e-08,  3.1751600e-08, -7.1148713e-07,\n",
       "           4.9139180e-07]], dtype=float32),\n",
       " matrix([[ 2.9724913e-07, -1.2695016e-07,  3.1215029e-07,  1.2849833e-07,\n",
       "           2.1287374e-08]], dtype=float32),\n",
       " matrix([[-5.9758133e-07, -3.0288368e-07, -3.8560751e-07, -1.1665115e-07,\n",
       "           1.3506975e-07]], dtype=float32),\n",
       " matrix([[ 1.1126200e-06, -2.0861626e-07, -4.2219956e-08,  2.2475918e-07,\n",
       "           2.1358331e-07]], dtype=float32),\n",
       " matrix([[ 2.1908734e-07,  8.2479943e-07,  1.4433989e-07, -1.0567742e-07,\n",
       "           1.4176240e-07]], dtype=float32),\n",
       " matrix([[ 1.7271267e-07, -3.7546233e-09,  2.0181101e-07, -2.7221018e-08,\n",
       "          -3.7546233e-08]], dtype=float32),\n",
       " matrix([[ 2.8984221e-07, -2.8516732e-07,  4.1489507e-08,  8.1810299e-08,\n",
       "           1.0503858e-07]], dtype=float32),\n",
       " matrix([[ 8.6697668e-08, -5.7798445e-08, -9.6631773e-08,  1.3004650e-07,\n",
       "           1.2756297e-07]], dtype=float32),\n",
       " matrix([[-8.3545024e-07, -3.9408028e-09,  1.0443128e-07, -1.5212115e-07,\n",
       "          -4.9260035e-10]], dtype=float32),\n",
       " matrix([[ 5.2399690e-07, -1.5719907e-07,  5.3273016e-08, -2.9201908e-08,\n",
       "           7.5979550e-08]], dtype=float32),\n",
       " matrix([[-3.7252903e-08, -1.7881393e-07, -1.5832484e-08, -2.6077032e-07,\n",
       "          -7.2759576e-08]], dtype=float32),\n",
       " matrix([[ 4.9541523e-08,  0.0000000e+00,  9.4825573e-08,  2.6318935e-08,\n",
       "          -4.6058133e-08]], dtype=float32),\n",
       " matrix([[ 6.9472961e-08,  1.7684027e-07,  9.1577995e-08, -8.2104414e-08,\n",
       "           5.4473119e-08]], dtype=float32),\n",
       " matrix([[-4.8972464e-07, -5.7993709e-08, -2.7385918e-08, -1.1528263e-07,\n",
       "          -1.0753000e-07]], dtype=float32),\n",
       " matrix([[-1.3601584e-06, -2.6056675e-08,  2.0193923e-07,  9.1198366e-08,\n",
       "          -1.6431991e-07]], dtype=float32),\n",
       " matrix([[ 2.87778676e-07,  1.35973096e-07,  2.98023224e-08,\n",
       "          -1.03376806e-07, -4.14438546e-08]], dtype=float32),\n",
       " matrix([[ 1.2185839e-06, -1.3686993e-07,  1.4473443e-07,  1.9205942e-07,\n",
       "           1.1976118e-07]], dtype=float32),\n",
       " matrix([[ 4.8828127e-07, -1.9073487e-09, -1.4305115e-09,  1.8119812e-07,\n",
       "           1.3732910e-07]], dtype=float32),\n",
       " matrix([[6.1575821e-07, 2.2903203e-07, 1.2014794e-07, 2.6282363e-08,\n",
       "          5.3034054e-08]], dtype=float32),\n",
       " matrix([[-1.40246229e-07,  5.76324339e-08,  9.02835069e-08,\n",
       "           5.12775244e-08, -1.35863525e-08]], dtype=float32),\n",
       " matrix([[ 4.1464099e-07,  4.9238619e-08, -5.9604645e-08, -1.4253285e-08,\n",
       "           5.6689199e-08]], dtype=float32),\n",
       " matrix([[ 1.0028327e-06, -1.4092095e-07,  2.7528742e-07,  5.2620044e-07,\n",
       "           7.4864253e-08]], dtype=float32),\n",
       " matrix([[-1.5464989e-06,  4.4676634e-07, -3.3829664e-07, -1.2887490e-07,\n",
       "           7.9472862e-08]], dtype=float32),\n",
       " matrix([[ 6.6342562e-07,  2.2546105e-07,  3.4467033e-07, -1.8140543e-08,\n",
       "           3.1130469e-07]], dtype=float32),\n",
       " matrix([[-5.2018601e-07, -1.8423253e-07,  1.4268991e-07, -1.6978292e-07,\n",
       "           1.0295348e-07]], dtype=float32),\n",
       " matrix([[-1.6495989e-07, -3.8146973e-07,  2.8352479e-08,  4.8972463e-08,\n",
       "          -8.3768690e-08]], dtype=float32),\n",
       " matrix([[ 3.96728524e-07, -2.17437744e-07, -7.10487384e-08,\n",
       "           2.52246849e-07, -1.09910964e-07]], dtype=float32),\n",
       " matrix([[-8.9009603e-08,  2.5431316e-08, -1.8278757e-07, -4.3710074e-08,\n",
       "           2.8610229e-08]], dtype=float32),\n",
       " matrix([[ 9.0307117e-07,  1.0509880e-07,  1.7759751e-07, -1.0412567e-07,\n",
       "           2.0922447e-07]], dtype=float32),\n",
       " matrix([[ 1.9073486e-08, -1.5497207e-07,  1.2874604e-07,  4.6491621e-08,\n",
       "          -2.5041402e-07]], dtype=float32),\n",
       " matrix([[-9.7274778e-07, -2.9981138e-07, -1.5027821e-07, -1.3232231e-07,\n",
       "          -1.7881393e-07]], dtype=float32),\n",
       " matrix([[-9.2589737e-08, -1.9212371e-07,  9.4904486e-08,  7.7543909e-08,\n",
       "           5.5553844e-08]], dtype=float32),\n",
       " matrix([[-7.1363382e-07, -1.8165225e-07, -2.0435878e-07,  7.1363381e-08,\n",
       "           7.5823593e-08]], dtype=float32),\n",
       " matrix([[-5.1468140e-07,  4.1628642e-08, -4.1628642e-08, -1.8117920e-07,\n",
       "          -5.6766329e-08]], dtype=float32),\n",
       " matrix([[-3.7216557e-07, -4.6520697e-08, -1.7445261e-08, -9.8856482e-08,\n",
       "           5.8150874e-08]], dtype=float32),\n",
       " matrix([[-1.1490052e-07,  2.6427119e-07, -6.6067798e-08, -3.8778925e-08,\n",
       "           6.2477156e-08]], dtype=float32),\n",
       " matrix([[ 5.4808869e-09,  9.5230412e-08,  9.5915517e-08,  5.4808869e-09,\n",
       "          -5.5665257e-08]], dtype=float32),\n",
       " matrix([[ 3.0215423e-07,  1.5786378e-08, -8.0259717e-08,  1.9002668e-07,\n",
       "           9.3242910e-08]], dtype=float32),\n",
       " matrix([[ 2.5357815e-07, -3.3075409e-08,  4.6856830e-08, -2.8940983e-08,\n",
       "           1.4677214e-07]], dtype=float32),\n",
       " matrix([[-1.1089236e-08, -3.0218169e-07,  7.2080034e-08, -1.3861546e-08,\n",
       "           5.1287717e-08]], dtype=float32),\n",
       " matrix([[ 6.11791052e-07,  4.04861737e-07,  1.55197000e-07,\n",
       "           1.23707755e-08, -7.08508026e-08]], dtype=float32),\n",
       " matrix([[ 6.8119596e-07,  1.9949310e-07, -7.2985280e-09, -1.7212362e-07,\n",
       "          -1.3015708e-07]], dtype=float32),\n",
       " matrix([[ 8.3526510e-07, -8.9606985e-08,  4.2883343e-07,  4.8003741e-08,\n",
       "           4.1603241e-07]], dtype=float32),\n",
       " matrix([[ 5.6098492e-07, -2.6646782e-07,  1.7029899e-07,  1.9233768e-07,\n",
       "           1.1119522e-07]], dtype=float32),\n",
       " matrix([[ 1.5894572e-07, -2.2990363e-07,  8.5149496e-09,  9.6502760e-08,\n",
       "          -2.9092742e-08]], dtype=float32),\n",
       " matrix([[-1.4992260e-07,  1.6241616e-07, -8.9537110e-08, -1.2441494e-07,\n",
       "           1.1608590e-07]], dtype=float32),\n",
       " matrix([[ 2.2178473e-07, -2.9571297e-08,  7.0231827e-08, -1.0742698e-07,\n",
       "           1.3283982e-07]], dtype=float32),\n",
       " matrix([[1.0638009e-06, 1.0127113e-06, 1.9584384e-08, 7.4477424e-07,\n",
       "          1.5894572e-07]], dtype=float32),\n",
       " matrix([[ 7.5718867e-07, -3.5942499e-08,  4.9121414e-08,  5.3913748e-08,\n",
       "           3.3246812e-07]], dtype=float32),\n",
       " matrix([[-1.4834934e-07, -7.2055394e-07, -4.2385526e-08, -2.2517310e-07,\n",
       "          -7.4174672e-08]], dtype=float32),\n",
       " matrix([[ 1.0058284e-07,  2.6449561e-07,  2.0675361e-07,  1.4901161e-07,\n",
       "          -5.5275450e-08]], dtype=float32),\n",
       " matrix([[ 1.2174566e-07, -2.4856405e-07,  2.1326626e-07, -5.4109179e-08,\n",
       "          -7.1018299e-08]], dtype=float32),\n",
       " matrix([[ 2.2007869e-07, -1.8339891e-07,  6.4189621e-08,  5.5019672e-08,\n",
       "           2.1033563e-07]], dtype=float32),\n",
       " matrix([[ 6.5208503e-08,  8.5586159e-08, -4.4830845e-08, -6.3170738e-08,\n",
       "           2.7382476e-09]], dtype=float32),\n",
       " matrix([[ 4.0323141e-07,  1.7281347e-07,  1.6961322e-07, -2.0251578e-07,\n",
       "           6.7205235e-08]], dtype=float32),\n",
       " matrix([[-5.1724709e-07, -1.9497790e-07, -2.3134685e-07, -3.5406043e-08,\n",
       "          -5.5816216e-08]], dtype=float32),\n",
       " matrix([[ 6.15273734e-08, -1.03827446e-07, -2.69182259e-08,\n",
       "          -6.54930048e-08, -9.19305521e-09]], dtype=float32),\n",
       " matrix([[ 1.3004650e-07, -1.9601211e-07,  9.8006055e-08, -1.3570069e-07,\n",
       "           8.4812932e-08]], dtype=float32),\n",
       " matrix([[-1.3172297e-06,  3.4511419e-07, -3.1350066e-07, -2.1734290e-07,\n",
       "          -4.0537745e-07]], dtype=float32),\n",
       " matrix([[ 1.5411377e-06,  7.4386598e-08, -5.6584675e-08,  1.3287863e-07,\n",
       "           1.3065338e-07]], dtype=float32),\n",
       " matrix([[-1.2439230e-07, -1.2093696e-07, -7.6017521e-08,  5.4421633e-08,\n",
       "           1.4253285e-08]], dtype=float32),\n",
       " matrix([[7.7905787e-07, 1.3432032e-08, 2.5185061e-08, 1.8607562e-07,\n",
       "          2.7502088e-07]], dtype=float32),\n",
       " matrix([[-2.9394071e-08, -8.1650198e-09, -3.5272885e-07, -1.8616245e-07,\n",
       "          -7.5934686e-08]], dtype=float32),\n",
       " matrix([[-7.6293944e-08, -7.1525577e-08,  9.0599059e-08, -1.3649463e-07,\n",
       "           5.7220458e-08]], dtype=float32),\n",
       " matrix([[-6.2099724e-07, -4.4356945e-08, -5.2673872e-08,  2.0099241e-08,\n",
       "          -7.3466190e-08]], dtype=float32),\n",
       " matrix([[-9.8232545e-07,  5.9348832e-08,  2.2409300e-07, -1.7088371e-07,\n",
       "          -2.4634880e-07]], dtype=float32),\n",
       " matrix([[ 3.2372432e-07,  1.8811008e-07, -1.4162939e-07, -5.9057815e-08,\n",
       "          -1.7772027e-08]], dtype=float32),\n",
       " matrix([[ 4.8287308e-07, -1.8107739e-08,  1.4486191e-07, -3.0179568e-09,\n",
       "          -2.6708918e-07]], dtype=float32),\n",
       " matrix([[-7.5180168e-07,  4.1766757e-08, -8.7014079e-08, -2.7844505e-08,\n",
       "           1.5662534e-08]], dtype=float32),\n",
       " matrix([[ 3.2285848e-07,  1.0430813e-07,  1.6298145e-08,  9.9341072e-08,\n",
       "          -5.8362883e-08]], dtype=float32),\n",
       " matrix([[ 5.0862631e-08, -6.9936114e-08,  9.5764797e-08,  1.3033549e-07,\n",
       "           1.2278556e-07]], dtype=float32),\n",
       " matrix([[ 2.8500611e-07,  1.7812882e-08,  1.0071130e-07,  1.1920929e-07,\n",
       "          -4.7572385e-08]], dtype=float32),\n",
       " matrix([[ 2.2057773e-07,  7.7040019e-09, -3.7303586e-08, -8.2716653e-08,\n",
       "          -1.0010134e-08]], dtype=float32),\n",
       " matrix([[ 2.0217895e-07, -4.1961670e-08,  1.7166138e-07, -1.0871887e-07,\n",
       "           4.0054321e-08]], dtype=float32),\n",
       " matrix([[ 2.4056649e-07,  1.5464988e-07,  1.1061763e-07, -7.6519477e-08,\n",
       "           2.0512590e-07]], dtype=float32),\n",
       " matrix([[-1.4671913e-07, -3.4845792e-07, -5.2154064e-08,  3.7826023e-08,\n",
       "          -1.5818156e-07]], dtype=float32),\n",
       " matrix([[-3.5135369e-07, -1.1293512e-07,  6.9015904e-08,  6.8231635e-08,\n",
       "          -1.0607274e-07]], dtype=float32),\n",
       " matrix([[2.3841858e-07, 1.4901161e-07, 7.4505806e-09, 1.3317913e-07,\n",
       "          2.4121255e-07]], dtype=float32),\n",
       " matrix([[ 8.1163769e-08, -9.1309246e-08,  2.5363678e-09, -1.1160019e-07,\n",
       "          -9.2577430e-08]], dtype=float32),\n",
       " matrix([[ 1.4901161e-07,  3.5390258e-08,  8.9406967e-08, -9.4529241e-08,\n",
       "           3.5390258e-08]], dtype=float32),\n",
       " matrix([[-7.7952507e-07,  1.4512435e-08,  3.3171279e-08, -1.3683153e-07,\n",
       "          -3.1098075e-08]], dtype=float32),\n",
       " matrix([[-8.45711213e-07,  2.11427803e-07,  1.03464664e-07,\n",
       "          -1.41982767e-07, -2.87901685e-07]], dtype=float32),\n",
       " matrix([[-1.3463638e-07,  2.3911980e-07,  8.9757584e-08, -3.0854171e-08,\n",
       "          -1.2271545e-08]], dtype=float32),\n",
       " matrix([[ 8.4147736e-08,  1.0693775e-07, -1.4725853e-07, -1.9152375e-07,\n",
       "          -1.1745621e-07]], dtype=float32),\n",
       " matrix([[7.2660903e-08, 8.1743515e-08, 2.6772420e-07, 7.0390250e-08,\n",
       "          1.9231368e-07]], dtype=float32),\n",
       " matrix([[-3.15264231e-07,  3.54672274e-08,  1.02460874e-07,\n",
       "           6.60084467e-08,  1.58617325e-07]], dtype=float32),\n",
       " matrix([[ 3.3659094e-07, -9.5834920e-08, -8.1810301e-09,  4.2073868e-08,\n",
       "          -8.5754721e-08]], dtype=float32),\n",
       " matrix([[ 1.2557277e-06, -7.9755679e-08,  2.3810040e-07,  2.0363153e-08,\n",
       "          -1.3236050e-07]], dtype=float32),\n",
       " matrix([[ 5.0193387e-07, -3.3462257e-08,  1.1502651e-07, -3.5815070e-08,\n",
       "           4.5553112e-08]], dtype=float32),\n",
       " matrix([[-1.2214548e-07,  1.8791612e-08, -2.5838466e-07,  6.8119597e-08,\n",
       "          -1.1157520e-07]], dtype=float32),\n",
       " matrix([[ 3.6941779e-07,  3.6679783e-08,  1.5195910e-07, -5.7639657e-08,\n",
       "           5.2399688e-08]], dtype=float32),\n",
       " matrix([[ 7.0209154e-07,  1.6820943e-08,  3.2618001e-07,  2.2306033e-07,\n",
       "          -3.3641885e-07]], dtype=float32),\n",
       " matrix([[ 3.0697672e-07,  1.3097673e-07,  5.4744181e-08, -1.6218603e-07,\n",
       "          -3.0697670e-08]], dtype=float32),\n",
       " matrix([[-4.9449778e-07,  1.3422083e-07, -1.2362444e-08, -6.8876481e-08,\n",
       "          -1.2472823e-07]], dtype=float32),\n",
       " matrix([[-1.34129675e-06, -4.12233419e-07,  1.03827446e-07,\n",
       "           3.73009712e-08,  3.24556908e-07]], dtype=float32),\n",
       " matrix([[-7.3598778e-07,  1.2568806e-07, -5.6624413e-07, -2.3582707e-07,\n",
       "          -3.1616378e-07]], dtype=float32),\n",
       " matrix([[-7.4505806e-08, -4.4703484e-08, -1.4714897e-07,  5.3783879e-08,\n",
       "          -9.5926225e-08]], dtype=float32),\n",
       " matrix([[-3.2744182e-07, -2.6604649e-08,  1.0232557e-08, -1.0232557e-08,\n",
       "           2.8139533e-09]], dtype=float32),\n",
       " matrix([[-1.4901161e-07, -2.0116568e-07, -3.1839591e-08,  8.3819032e-09,\n",
       "          -1.3969839e-09]], dtype=float32),\n",
       " matrix([[-3.5408701e-07, -1.6996177e-07, -1.7586321e-07,  7.3177979e-08,\n",
       "           2.3605800e-09]], dtype=float32),\n",
       " matrix([[-8.8809213e-07, -1.0008115e-07,  1.7317797e-07, -8.0884701e-07,\n",
       "          -4.4677864e-07]], dtype=float32),\n",
       " matrix([[4.2276284e-07, 1.1920929e-07, 9.0943168e-08, 8.7870767e-08,\n",
       "          4.3013659e-09]], dtype=float32),\n",
       " matrix([[-1.6867709e-06, -3.3086661e-07, -3.6817019e-07, -1.7840846e-07,\n",
       "          -1.9138362e-07]], dtype=float32),\n",
       " matrix([[-2.6490954e-07, -1.4128508e-07, -2.7594742e-08,  9.1200626e-08,\n",
       "           9.3822123e-08]], dtype=float32),\n",
       " matrix([[ 2.6822090e-07,  3.7252903e-09, -1.1175871e-07,  6.7055225e-08,\n",
       "          -1.0104850e-07]], dtype=float32),\n",
       " matrix([[ 2.8487515e-08,  8.4147736e-08,  9.1160047e-08,  1.1219698e-07,\n",
       "          -1.2622161e-07]], dtype=float32),\n",
       " matrix([[-3.4438239e-07, -2.9669869e-07,  2.2517311e-08,  6.0929196e-08,\n",
       "          -2.4504132e-08]], dtype=float32),\n",
       " matrix([[-8.8201091e-08, -4.9613114e-08, -1.2403278e-07, -2.8940983e-08,\n",
       "           1.3988142e-07]], dtype=float32),\n",
       " matrix([[ 2.1674417e-07,  8.6697668e-08,  3.2511625e-08, -1.5894572e-07,\n",
       "          -1.4449611e-08]], dtype=float32),\n",
       " matrix([[ 2.2587024e-07,  2.3841858e-07, -3.1370867e-08,  8.3132797e-08,\n",
       "           3.1370866e-09]], dtype=float32),\n",
       " matrix([[ 5.6578841e-07,  3.4049381e-07, -1.6404948e-07,  6.9265333e-08,\n",
       "          -1.5037870e-07]], dtype=float32),\n",
       " matrix([[-1.2692788e-06, -4.6654571e-07, -1.0737413e-06, -2.4699477e-07,\n",
       "          -2.0068326e-07]], dtype=float32),\n",
       " matrix([[-8.0553076e-07, -5.5553844e-08, -4.1665382e-07,  1.9067700e-07,\n",
       "          -2.1990063e-07]], dtype=float32),\n",
       " matrix([[ 8.8526730e-07,  1.6095768e-08, -1.0261053e-07,  1.7981992e-07,\n",
       "           1.2323324e-07]], dtype=float32),\n",
       " matrix([[ 2.2149855e-07, -1.0613472e-07,  3.0763687e-08,  5.0760086e-08,\n",
       "          -5.5374638e-08]], dtype=float32),\n",
       " matrix([[-7.37139558e-08,  4.13201278e-08, -5.64372478e-08,\n",
       "          -2.90824591e-08, -1.23816415e-08]], dtype=float32),\n",
       " matrix([[-1.8353733e-06, -1.1995903e-08, -6.9163882e-08,  3.7112326e-08,\n",
       "           1.7244110e-07]], dtype=float32),\n",
       " matrix([[ 5.9193576e-07,  3.3707454e-07, -2.0553326e-09,  7.2964305e-08,\n",
       "           3.3193621e-07]], dtype=float32),\n",
       " matrix([[-2.3496324e-07, -1.6585641e-07,  2.2805256e-07, -2.7642733e-07,\n",
       "          -9.3294226e-08]], dtype=float32),\n",
       " matrix([[ 1.7029899e-08, -3.0653817e-07, -1.1920929e-07,  7.4505806e-08,\n",
       "          -2.0223004e-08]], dtype=float32),\n",
       " matrix([[ 8.4032780e-07,  2.2669307e-07,  4.6315739e-07, -5.6062564e-08,\n",
       "           2.3451008e-08]], dtype=float32),\n",
       " matrix([[ 4.12081505e-07, -1.34294410e-07, -2.50192329e-08,\n",
       "           5.88687854e-08,  1.03204336e-07]], dtype=float32),\n",
       " matrix([[6.8263006e-07, 1.5308983e-07, 1.6752043e-07, 1.1669962e-07,\n",
       "          1.6563817e-07]], dtype=float32),\n",
       " matrix([[-3.4455331e-07, -4.3069164e-08, -1.6150936e-07,  1.5151116e-07,\n",
       "          -1.7227666e-07]], dtype=float32),\n",
       " matrix([[ 6.1338596e-07, -2.7363951e-08,  2.6009300e-08, -9.9702312e-08,\n",
       "          -1.3004650e-08]], dtype=float32),\n",
       " matrix([[-7.5688440e-08,  8.5386020e-08,  8.3257284e-08,  1.5137688e-08,\n",
       "          -8.0182438e-08]], dtype=float32),\n",
       " matrix([[-1.6232754e-07, -9.1309246e-08,  1.0145471e-08, -9.5113792e-09,\n",
       "           1.5598663e-07]], dtype=float32),\n",
       " matrix([[-1.0899136e-06, -2.9867823e-07, -2.9998822e-07,  6.5008365e-08,\n",
       "          -7.4997054e-08]], dtype=float32),\n",
       " matrix([[-1.7136335e-07, -1.0430813e-07, -3.9115548e-08, -2.6449561e-07,\n",
       "           3.7194695e-08]], dtype=float32),\n",
       " matrix([[ 5.7220461e-07,  4.8535210e-08,  1.9754683e-07, -6.7693847e-08,\n",
       "          -2.9802322e-08]], dtype=float32),\n",
       " matrix([[ 6.5565109e-07,  3.4272671e-07,  3.0547380e-07, -1.8812716e-07,\n",
       "           2.9802322e-08]], dtype=float32),\n",
       " matrix([[ 6.2442962e-07,  4.3993904e-07, -2.8383164e-08,  2.0893779e-07,\n",
       "           1.6178403e-07]], dtype=float32),\n",
       " matrix([[ 3.9586482e-07,  4.6334176e-07, -1.1312055e-08, -4.2735405e-08,\n",
       "           5.1732332e-08]], dtype=float32),\n",
       " matrix([[ 6.3578290e-07,  2.3496324e-07, -1.4814778e-07,  1.4166901e-07,\n",
       "           1.1775157e-07]], dtype=float32),\n",
       " matrix([[ 1.0355850e-06,  9.1783839e-08, -3.7737419e-07, -2.7462016e-07,\n",
       "          -3.0533666e-08]], dtype=float32),\n",
       " matrix([[-2.7673585e-07,  2.1287373e-07,  9.3664440e-08,  5.9604645e-08,\n",
       "           7.2377070e-08]], dtype=float32),\n",
       " matrix([[-3.5170967e-07, -2.4518222e-08,  8.1903542e-09,  1.4541843e-07,\n",
       "          -1.6909119e-09]], dtype=float32),\n",
       " matrix([[1.0977546e-07, 4.8026766e-07, 1.7495464e-07, 4.8884385e-08,\n",
       "          3.6020072e-08]], dtype=float32),\n",
       " matrix([[3.3060709e-07, 2.2888183e-07, 1.1044244e-07, 1.3351440e-07,\n",
       "          3.4650168e-07]], dtype=float32),\n",
       " matrix([[1.2882093e-06, 6.1414630e-07, 7.2961080e-07, 4.1442391e-07,\n",
       "          3.9320341e-08]], dtype=float32),\n",
       " matrix([[ 3.3826910e-07, -1.4264360e-07, -3.1381592e-07, -8.1510629e-09,\n",
       "           6.5717941e-08]], dtype=float32),\n",
       " matrix([[ 8.0917822e-08, -8.6697668e-08,  8.3085261e-08, -1.5822324e-07,\n",
       "           2.6248622e-07]], dtype=float32),\n",
       " matrix([[-5.9604645e-07, -3.3527613e-07, -1.7974526e-07, -2.9802322e-08,\n",
       "          -3.7252903e-09]], dtype=float32),\n",
       " matrix([[7.1916423e-07, 5.7064119e-07, 3.3808536e-07, 5.7650393e-08,\n",
       "          1.5780574e-07]], dtype=float32),\n",
       " matrix([[ 2.1534581e-07,  9.2291060e-08, -1.9996396e-07, -1.7400711e-07,\n",
       "           4.0377341e-08]], dtype=float32),\n",
       " matrix([[-3.57973391e-07,  1.25774434e-07, -6.91068323e-08,\n",
       "           1.09534334e-07, -1.38213672e-08]], dtype=float32),\n",
       " matrix([[ 6.6811083e-07, -9.8667577e-08, -4.7144915e-09,  2.2898959e-07,\n",
       "          -1.2897502e-07]], dtype=float32),\n",
       " matrix([[ 1.0097729e-06,  1.2341668e-07,  2.3000381e-07, -4.4878792e-08,\n",
       "           6.4513266e-08]], dtype=float32),\n",
       " matrix([[-4.7969246e-07, -5.4821999e-07, -2.1129311e-07, -1.3991030e-07,\n",
       "          -1.1492632e-07]], dtype=float32),\n",
       " matrix([[ 9.9055671e-07,  4.3732027e-07, -8.3644089e-08,  5.2491606e-07,\n",
       "           3.7080017e-07]], dtype=float32),\n",
       " matrix([[-1.6303173e-07, -7.1096544e-08,  1.6180593e-07, -4.5661142e-08,\n",
       "           5.9451420e-08]], dtype=float32),\n",
       " matrix([[-2.1390825e-07,  1.3369267e-07,  2.3396217e-08, -1.0249771e-07,\n",
       "           7.2416860e-08]], dtype=float32),\n",
       " matrix([[-1.0066562e-06, -5.9604645e-07, -4.2716661e-07,  7.6161491e-08,\n",
       "          -2.4255780e-07]], dtype=float32),\n",
       " matrix([[-9.5367432e-07, -1.5524931e-07, -2.1953223e-07,  2.6336936e-08,\n",
       "           1.6911085e-07]], dtype=float32),\n",
       " matrix([[-5.3752552e-07, -1.8423253e-07, -4.7683717e-08,  5.6353482e-08,\n",
       "           7.6944175e-08]], dtype=float32),\n",
       " matrix([[-3.8146973e-07,  7.2660903e-08,  1.8732888e-07, -1.2829190e-07,\n",
       "          -1.9584384e-07]], dtype=float32),\n",
       " matrix([[ 4.5413063e-07,  2.9329269e-07,  2.8950828e-07,  1.8922110e-08,\n",
       "          -3.3409350e-08]], dtype=float32),\n",
       " matrix([[-1.0421595e-06, -6.3906009e-07,  1.5177677e-07, -8.2954919e-08,\n",
       "           1.3211339e-07]], dtype=float32),\n",
       " matrix([[-3.8767249e-07, -1.3956209e-07,  3.7313477e-08, -7.7534494e-08,\n",
       "          -8.3925038e-08]], dtype=float32),\n",
       " matrix([[-6.7512588e-07, -2.0773103e-07,  1.1802900e-07, -6.1375083e-08,\n",
       "          -8.4980883e-08]], dtype=float32),\n",
       " matrix([[1.4240386e-06, 7.4438383e-08, 2.6431019e-07, 1.3215509e-07,\n",
       "          5.6887376e-07]], dtype=float32),\n",
       " matrix([[-4.63949675e-07, -2.31974838e-07,  9.66561799e-08,\n",
       "          -1.17598354e-07, -1.61093638e-07]], dtype=float32),\n",
       " matrix([[ 0.0000000e+00,  2.6551160e-07, -8.1279063e-09, -1.4562498e-07,\n",
       "           3.1495635e-08]], dtype=float32),\n",
       " matrix([[ 4.2087035e-07,  2.1155451e-07,  2.3226224e-07,  1.0857560e-07,\n",
       "          -1.4565360e-07]], dtype=float32),\n",
       " matrix([[ 2.19464795e-07, -1.19708075e-08,  3.95286044e-08,\n",
       "           1.65596163e-07,  9.52676729e-08]], dtype=float32),\n",
       " matrix([[-1.6736668e-07,  1.0105158e-07,  0.0000000e+00, -9.4735860e-08,\n",
       "          -4.7367930e-08]], dtype=float32),\n",
       " matrix([[ 5.4495676e-08,  2.0435879e-08,  6.6416604e-08, -1.0217939e-07,\n",
       "          -1.0430813e-08]], dtype=float32),\n",
       " matrix([[-1.9462742e-07,  2.4328426e-07,  1.6786615e-07, -9.8530130e-08,\n",
       "          -5.0177380e-08]], dtype=float32),\n",
       " matrix([[ 1.3443361e-06, -3.4470156e-07,  4.3949450e-07, -2.7989049e-07,\n",
       "           1.2567244e-09]], dtype=float32),\n",
       " matrix([[ 3.0901180e-07,  1.5983369e-08, -3.3964659e-07,  8.0333074e-09,\n",
       "           1.4851213e-07]], dtype=float32),\n",
       " matrix([[-1.1219698e-07,  2.3140626e-07, -1.3936969e-07,  1.7530778e-09,\n",
       "          -1.4725853e-07]], dtype=float32),\n",
       " matrix([[ 1.93967651e-07, -1.33352771e-07,  1.34363006e-07,\n",
       "          -6.06148909e-09,  1.14915736e-07]], dtype=float32),\n",
       " matrix([[-9.5367432e-07,  3.9408029e-08,  1.4580971e-07, -1.4975052e-07,\n",
       "          -9.4579271e-08]], dtype=float32),\n",
       " matrix([[ 8.1510628e-08,  1.6098349e-07, -1.5283243e-08,  1.2736035e-07,\n",
       "           1.5537964e-08]], dtype=float32),\n",
       " matrix([[ 9.8655967e-08,  8.2213305e-08,  4.5217316e-08,  1.3051361e-07,\n",
       "          -1.0276663e-08]], dtype=float32),\n",
       " matrix([[ 1.0699761e-06,  1.0757911e-07, -5.5243330e-08,  3.5472033e-07,\n",
       "           3.4018259e-07]], dtype=float32),\n",
       " matrix([[-6.8530363e-07,  6.2300330e-08, -1.1980833e-07, -4.3130999e-08,\n",
       "          -4.4688508e-07]], dtype=float32),\n",
       " matrix([[ 5.1172771e-07,  1.1533256e-07, -1.5506899e-07,  2.0352806e-08,\n",
       "           1.7445262e-07]], dtype=float32),\n",
       " matrix([[-1.1444092e-08, -3.3569336e-07,  3.8146972e-08,  1.6212464e-08,\n",
       "           5.7220458e-08]], dtype=float32),\n",
       " matrix([[-4.88136607e-07, -6.77967504e-09, -5.52614132e-09,\n",
       "          -1.11864644e-07, -2.82486461e-08]], dtype=float32),\n",
       " matrix([[5.2904562e-07, 1.4966422e-07, 3.5284211e-07, 1.8446985e-07,\n",
       "          2.6104225e-08]], dtype=float32),\n",
       " matrix([[ 1.3351440e-07,  2.8610229e-08, -1.1205673e-07,  1.5616416e-07,\n",
       "           3.8146972e-08]], dtype=float32),\n",
       " matrix([[ 6.6173322e-07,  3.9330956e-08, -4.7034959e-08,  9.4069918e-08,\n",
       "          -9.0826127e-08]], dtype=float32),\n",
       " matrix([[-5.7353839e-07, -3.7346686e-07, -4.7183536e-07, -1.5588907e-07,\n",
       "          -5.8354196e-08]], dtype=float32),\n",
       " matrix([[-5.7549311e-08,  1.6442661e-07, -1.2331995e-07, -9.8655967e-08,\n",
       "          -5.8576980e-08]], dtype=float32),\n",
       " matrix([[-4.0999083e-07, -5.3477063e-08,  6.1275802e-09, -4.4564219e-09,\n",
       "          -1.4566929e-07]], dtype=float32),\n",
       " matrix([[-5.3405762e-07, -2.8882707e-07, -7.4250359e-08,  2.4523054e-08,\n",
       "          -1.1989049e-07]], dtype=float32),\n",
       " matrix([[-4.8047713e-07,  1.0919935e-07, -5.0959695e-08,  9.0999457e-08,\n",
       "          -4.5499728e-08]], dtype=float32),\n",
       " matrix([[ 3.0453467e-07,  1.2021106e-07, -6.6116080e-08, -2.5544848e-08,\n",
       "          -4.2073868e-08]], dtype=float32),\n",
       " matrix([[-5.1208968e-07, -2.5604484e-07, -4.8240334e-08,  8.3492884e-09,\n",
       "          -2.2543080e-07]], dtype=float32),\n",
       " matrix([[2.0435878e-07, 5.1089696e-08, 2.9802322e-08, 1.0856560e-07,\n",
       "          5.9604645e-08]], dtype=float32),\n",
       " matrix([[-7.3693013e-07,  9.1032547e-08,  1.7339532e-08,  3.2511625e-09,\n",
       "          -4.1614879e-07]], dtype=float32),\n",
       " matrix([[ 1.2964985e-06,  1.7297035e-07,  0.0000000e+00,  2.0569446e-07,\n",
       "          -1.9089069e-07]], dtype=float32),\n",
       " matrix([[1.1626988e-06, 6.8912766e-07, 6.6749038e-08, 5.5277184e-07,\n",
       "          3.2905029e-07]], dtype=float32),\n",
       " matrix([[ 1.2362445e-07, -7.0642542e-08,  6.6227386e-08,  1.1037897e-08,\n",
       "           4.4151587e-08]], dtype=float32),\n",
       " matrix([[-4.0154708e-07,  1.1842502e-07, -1.3332618e-07, -1.3411045e-07,\n",
       "           1.4116890e-08]], dtype=float32),\n",
       " matrix([[-1.5137688e-07, -4.1628642e-08, -1.3387393e-07, -1.4901161e-08,\n",
       "          -3.5952009e-08]], dtype=float32),\n",
       " matrix([[-2.7350660e-07, -7.7373578e-08,  7.0176036e-08, -5.2182180e-08,\n",
       "           6.2078797e-08]], dtype=float32),\n",
       " matrix([[ 6.52514018e-07, -6.77610714e-08, -1.13562535e-07,\n",
       "          -4.39192114e-08,  2.25870238e-08]], dtype=float32),\n",
       " matrix([[-6.5051955e-07,  7.4209758e-08,  1.2631448e-08,  6.8683498e-08,\n",
       "          -1.6420883e-07]], dtype=float32),\n",
       " matrix([[ 5.0603126e-07,  1.6421689e-07, -1.3137350e-07,  1.2164213e-07,\n",
       "          -2.5544848e-08]], dtype=float32),\n",
       " matrix([[ 5.1272815e-07,  9.7418344e-08, -1.5125480e-07,  2.7430954e-07,\n",
       "           4.9670536e-08]], dtype=float32),\n",
       " matrix([[ 1.1630174e-08,  1.0176403e-07, -2.3551104e-07,  1.8899033e-08,\n",
       "          -1.8317525e-07]], dtype=float32),\n",
       " matrix([[-1.1402628e-07,  2.7383584e-07,  0.0000000e+00,  7.6017521e-08,\n",
       "          -9.3294226e-08]], dtype=float32),\n",
       " matrix([[6.61274157e-07, 4.40849448e-07, 1.07963132e-07, 1.67427203e-07,\n",
       "          1.00653125e-07]], dtype=float32),\n",
       " matrix([[-6.8940309e-08,  9.1920413e-08, -9.4792931e-08,  1.3500811e-07,\n",
       "           8.3302879e-08]], dtype=float32),\n",
       " matrix([[ 1.0451225e-06,  1.4370436e-07,  4.3642032e-07, -1.2553718e-08,\n",
       "           7.2668676e-08]], dtype=float32),\n",
       " matrix([[ 4.1919751e-08, -1.5195910e-07,  2.9474825e-07, -1.5163160e-07,\n",
       "           1.2575926e-07]], dtype=float32),\n",
       " matrix([[-7.0892605e-07, -2.3208888e-07, -8.8615757e-08, -2.4131969e-08,\n",
       "          -1.7617656e-07]], dtype=float32),\n",
       " matrix([[ 3.8793530e-07,  3.3136141e-07, -3.7177134e-07,  2.0204965e-08,\n",
       "           5.9099520e-08]], dtype=float32),\n",
       " matrix([[ 1.4975052e-07, -1.2807610e-07,  5.3200839e-08, -2.0984776e-07,\n",
       "          -1.4285411e-07]], dtype=float32),\n",
       " matrix([[-1.5777700e-07, -4.2073868e-08, -3.3659094e-07, -2.5594935e-07,\n",
       "          -1.7092509e-08]], dtype=float32),\n",
       " matrix([[-7.7259693e-07,  5.0928019e-08,  2.1125697e-08, -1.2977213e-07,\n",
       "          -5.2814244e-08]], dtype=float32),\n",
       " matrix([[-3.24878073e-07, -1.07419361e-07, -1.83398910e-07,\n",
       "          -7.27045659e-08, -1.10203096e-07]], dtype=float32),\n",
       " matrix([[ 3.0763687e-07,  1.7304575e-07,  1.2497748e-07,  0.0000000e+00,\n",
       "          -6.2969420e-08]], dtype=float32),\n",
       " matrix([[-1.5206051e-06, -2.6808357e-07,  3.6476945e-07,  3.3180834e-07,\n",
       "           1.2257407e-08]], dtype=float32),\n",
       " matrix([[-5.5057484e-07, -1.8557323e-07, -2.4579235e-08, -1.3764371e-07,\n",
       "          -1.3242062e-07]], dtype=float32),\n",
       " matrix([[-8.9545580e-07, -4.4356946e-07, -3.9089556e-07,  1.1588333e-07,\n",
       "           1.2648660e-08]], dtype=float32),\n",
       " matrix([[ 1.5894573e-08, -1.1920929e-07, -2.2947788e-07, -4.4703485e-09,\n",
       "          -5.7121117e-08]], dtype=float32),\n",
       " matrix([[-2.5234681e-07,  3.9654500e-07,  5.3582733e-07, -4.0965393e-08,\n",
       "          -2.1711658e-08]], dtype=float32),\n",
       " matrix([[ 2.9045918e-08, -4.8409863e-08,  6.4143066e-08,  1.0196327e-07,\n",
       "          -1.7064477e-07]], dtype=float32),\n",
       " matrix([[-1.09438034e-07, -5.47190169e-08, -7.62157768e-08,\n",
       "          -9.77125314e-09, -9.28269017e-09]], dtype=float32),\n",
       " matrix([[ 4.2737273e-07, -1.1871465e-08,  3.0173307e-08,  7.7411840e-08,\n",
       "          -2.5412353e-08]], dtype=float32),\n",
       " matrix([[-2.6786009e-07, -3.0018805e-07, -8.7169987e-08, -7.2737869e-08,\n",
       "           2.4029475e-08]], dtype=float32),\n",
       " matrix([[7.4488173e-07, 4.6272956e-07, 5.6430434e-08, 1.4883527e-07,\n",
       "          2.3982935e-08]], dtype=float32),\n",
       " matrix([[-1.8567111e-07,  1.5191273e-07,  6.3296966e-08, -3.7978182e-08,\n",
       "           4.2197978e-09]], dtype=float32),\n",
       " matrix([[7.35363301e-07, 1.60860722e-07, 2.32673557e-07, 1.17773034e-07,\n",
       "          1.71991715e-07]], dtype=float32),\n",
       " matrix([[-4.6669169e-07, -2.3334584e-07, -3.5001875e-07,  1.5218207e-08,\n",
       "          -1.6470538e-07]], dtype=float32),\n",
       " matrix([[-4.9476336e-07, -1.9360306e-07, -1.2010560e-07, -2.5007063e-07,\n",
       "           6.2741734e-08]], dtype=float32),\n",
       " matrix([[ 1.3821367e-08, -1.1057094e-07,  0.0000000e+00,  2.5396761e-07,\n",
       "           4.1464101e-08]], dtype=float32),\n",
       " matrix([[-7.3145895e-07, -1.9443846e-07,  1.3425512e-07, -2.3147434e-08,\n",
       "          -1.5045832e-07]], dtype=float32),\n",
       " matrix([[-2.7033289e-07, -8.4479026e-08,  6.1951283e-08,  1.0325214e-07,\n",
       "           3.0740978e-07]], dtype=float32),\n",
       " matrix([[ 9.2330254e-07,  1.9741665e-07, -1.6248910e-07,  2.1715833e-07,\n",
       "          -1.8716618e-07]], dtype=float32),\n",
       " matrix([[ 1.2557925e-06,  6.4791612e-07,  2.5343348e-07, -2.7299838e-09,\n",
       "          -4.8229712e-08]], dtype=float32),\n",
       " matrix([[-1.5633016e-06,  5.6813036e-07, -3.5083747e-08, -4.6778329e-08,\n",
       "           1.2524521e-07]], dtype=float32),\n",
       " matrix([[2.8128034e-07, 4.6344286e-07, 4.7549772e-08, 2.1162998e-07,\n",
       "          5.1233204e-08]], dtype=float32),\n",
       " matrix([[ 1.9210705e-07, -1.7666989e-07,  1.2349739e-07,  7.5041822e-09,\n",
       "           7.0968120e-08]], dtype=float32),\n",
       " matrix([[-1.7425943e-08,  1.9960625e-07, -8.8713890e-08,  1.5208096e-07,\n",
       "          -1.8079416e-07]], dtype=float32),\n",
       " matrix([[ 2.3972140e-07, -1.3288904e-07,  2.6056675e-08,  2.2083033e-07,\n",
       "           1.5992285e-07]], dtype=float32),\n",
       " matrix([[ 2.03697425e-07, -1.08792946e-07, -6.94423052e-09,\n",
       "          -5.26604147e-08, -1.06622871e-07]], dtype=float32),\n",
       " matrix([[ 1.03827446e-07, -1.96118506e-07,  1.53818434e-08,\n",
       "          -6.34501092e-08,  5.29952580e-08]], dtype=float32),\n",
       " matrix([[-3.0611767e-07,  3.5358065e-07, -5.5925344e-08, -6.7699105e-08,\n",
       "           6.6227386e-08]], dtype=float32),\n",
       " matrix([[ 0.0000000e+00, -5.8687650e-08, -7.3359566e-08,  5.1351694e-08,\n",
       "          -4.5849728e-09]], dtype=float32),\n",
       " matrix([[ 7.0390246e-07,  1.0217939e-07,  3.8884934e-07, -1.2488593e-07,\n",
       "          -1.6746067e-07]], dtype=float32),\n",
       " matrix([[1.51243498e-07, 0.00000000e+00, 1.82883852e-07, 1.07130816e-07,\n",
       "          6.30181276e-08]], dtype=float32),\n",
       " matrix([[ 1.17005425e-06,  2.08365819e-07,  4.97874112e-07,\n",
       "          -1.08189944e-07,  9.21618053e-08]], dtype=float32),\n",
       " matrix([[ 4.8165367e-07,  3.5160718e-07, -1.3245477e-08,  1.3727130e-07,\n",
       "           3.8532296e-08]], dtype=float32),\n",
       " matrix([[ 1.2945384e-07,  9.6857548e-08, -5.9953891e-08,  5.6810677e-08,\n",
       "          -1.3969839e-07]], dtype=float32),\n",
       " matrix([[-3.5321270e-07, -2.9434393e-08,  1.6924776e-07, -2.9728736e-07,\n",
       "           8.0944581e-08]], dtype=float32),\n",
       " matrix([[-5.7081235e-07, -4.3507040e-08,  6.9611261e-08, -2.4755505e-07,\n",
       "          -1.3530689e-07]], dtype=float32),\n",
       " matrix([[-1.7166138e-07,  4.2915346e-08, -5.0067900e-08, -4.1723252e-09,\n",
       "           4.4405461e-08]], dtype=float32),\n",
       " matrix([[ 3.24878073e-07,  1.04799376e-07, -1.67679005e-07,\n",
       "           6.81195971e-08,  1.10039345e-07]], dtype=float32),\n",
       " matrix([[ 9.5367432e-07,  1.7759751e-07,  3.4303082e-07,  4.7927000e-07,\n",
       "          -6.2037486e-08]], dtype=float32),\n",
       " matrix([[ 1.1786986e-07, -2.1430884e-08, -6.9650369e-08,  6.4962364e-08,\n",
       "          -9.2085827e-08]], dtype=float32),\n",
       " matrix([[-2.5045992e-07, -3.1307490e-08, -2.1915243e-07, -2.0470281e-07,\n",
       "           1.0235141e-07]], dtype=float32),\n",
       " matrix([[ 2.1375459e-07,  6.9752851e-08,  1.5414994e-08, -5.1897146e-08,\n",
       "           9.5059129e-08]], dtype=float32),\n",
       " matrix([[-8.1383263e-07, -4.3786488e-07,  4.3499929e-07, -2.3669921e-07,\n",
       "          -1.7537521e-07]], dtype=float32),\n",
       " matrix([[1.0331472e-06, 1.7660636e-08, 3.9736429e-07, 6.1812223e-08,\n",
       "          9.9617019e-08]], dtype=float32),\n",
       " matrix([[ 6.4074993e-07, -2.5611371e-08, -1.7136335e-07,  3.3527613e-08,\n",
       "           5.4715201e-08]], dtype=float32),\n",
       " matrix([[ 3.8146973e-07, -3.6784581e-07,  2.9291425e-07, -2.0435879e-08,\n",
       "          -8.4297994e-08]], dtype=float32),\n",
       " matrix([[-4.2162443e-07, -1.3552214e-07,  1.5618770e-07, -8.7838421e-09,\n",
       "          -4.6428880e-08]], dtype=float32),\n",
       " matrix([[-3.6964121e-07, -1.0349954e-07, -2.1346780e-07,  1.1089236e-08,\n",
       "           1.2937442e-08]], dtype=float32),\n",
       " matrix([[-9.3804033e-08,  2.2669307e-07, -2.6382384e-08,  1.4168317e-08,\n",
       "           1.7588256e-08]], dtype=float32),\n",
       " matrix([[ 1.8804846e-07,  1.6790041e-07, -3.0222072e-08,  9.9061239e-08,\n",
       "           9.5703236e-08]], dtype=float32),\n",
       " matrix([[-1.3847873e-06, -5.5032234e-07, -5.9604645e-07, -1.3472282e-07,\n",
       "          -4.1559952e-07]], dtype=float32),\n",
       " matrix([[-2.2007869e-07, -3.0566486e-07, -2.0479544e-07,  2.2084285e-07,\n",
       "           4.9670539e-09]], dtype=float32),\n",
       " matrix([[-6.7636478e-08,  8.4545597e-08, -1.3527295e-08,  2.4433677e-07,\n",
       "          -5.0727356e-09]], dtype=float32),\n",
       " matrix([[ 1.7801921e-07, -2.7974446e-07,  2.0980835e-07, -1.9073486e-08,\n",
       "           1.2715658e-07]], dtype=float32),\n",
       " matrix([[-9.9513841e-07,  8.5001403e-08, -1.9073487e-07, -4.9756920e-08,\n",
       "           6.6342558e-08]], dtype=float32),\n",
       " matrix([[-2.7876635e-07,  8.8031477e-08,  1.3938318e-07,  4.9976201e-08,\n",
       "          -3.2094810e-08]], dtype=float32),\n",
       " matrix([[-1.8289644e-07,  4.5724111e-08,  4.7357116e-08, -1.2614956e-07,\n",
       "          -2.0157392e-08]], dtype=float32),\n",
       " matrix([[-3.3302913e-07, -1.8922110e-07, -3.7844221e-09, -4.6201485e-08,\n",
       "          -6.9381070e-09]], dtype=float32),\n",
       " matrix([[ 1.6617052e-07, -2.8899223e-08,  4.6961237e-08,  1.4990060e-07,\n",
       "           6.6829450e-08]], dtype=float32),\n",
       " matrix([[ 1.0288603e-06,  1.6817908e-07, -5.9357324e-09, -1.4245758e-07,\n",
       "           3.0074378e-07]], dtype=float32),\n",
       " matrix([[ 2.0662944e-07,  2.3841858e-07, -9.3380613e-08,  6.4571701e-08,\n",
       "           6.2088170e-09]], dtype=float32),\n",
       " matrix([[ 3.2885321e-08, -6.1659975e-08, -1.2075078e-07, -5.1383315e-09,\n",
       "          -5.1383314e-08]], dtype=float32),\n",
       " matrix([[ 1.5258789e-07,  5.4041546e-08,  2.4159749e-07, -6.3578289e-09,\n",
       "           5.0862631e-08]], dtype=float32),\n",
       " matrix([[ 7.9472864e-09,  1.2715658e-07,  1.4305115e-07,  1.3584892e-07,\n",
       "          -7.8479452e-08]], dtype=float32),\n",
       " matrix([[-8.2104413e-07, -8.2735983e-07, -3.5052267e-07, -1.0894624e-07,\n",
       "          -7.1051893e-08]], dtype=float32),\n",
       " matrix([[ 1.4093710e-06,  5.4025886e-08,  2.0553325e-07,  1.9731193e-07,\n",
       "          -1.8732888e-07]], dtype=float32),\n",
       " matrix([[-1.8994671e-06, -1.1113065e-06, -5.0109770e-07,  1.3201689e-07,\n",
       "          -2.9950104e-07]], dtype=float32),\n",
       " matrix([[-4.0581885e-08,  1.8430940e-07,  1.3527295e-08,  1.6909119e-09,\n",
       "          -8.4017188e-08]], dtype=float32),\n",
       " matrix([[ 6.4052756e-08, -9.9637617e-08,  3.7008257e-07, -2.1350918e-07,\n",
       "          -9.7413562e-08]], dtype=float32),\n",
       " matrix([[-9.1360397e-07, -6.2509747e-07, -2.5945550e-07, -3.2056281e-08,\n",
       "           1.7230251e-07]], dtype=float32),\n",
       " matrix([[-5.3688331e-07, -2.7992107e-07,  2.0133125e-07, -1.3422083e-07,\n",
       "          -8.8303178e-09]], dtype=float32),\n",
       " matrix([[ 4.3710074e-07, -1.4404456e-07,  1.6142925e-08,  4.6566129e-08,\n",
       "           7.8851976e-08]], dtype=float32),\n",
       " matrix([[5.4868934e-07, 2.3188656e-07, 2.5964763e-07, 9.8796740e-08,\n",
       "          2.7597767e-07]], dtype=float32),\n",
       " matrix([[-9.8145119e-07, -4.5658317e-07, -9.0274995e-08, -4.5137497e-07,\n",
       "          -2.4304807e-08]], dtype=float32),\n",
       " matrix([[2.1430884e-08, 9.6438974e-08, 2.7458320e-08, 1.8484137e-07,\n",
       "          1.7077735e-07]], dtype=float32),\n",
       " matrix([[-3.3378601e-07, -7.1525577e-08, -1.0579824e-07,  1.2367964e-07,\n",
       "           7.4505806e-08]], dtype=float32),\n",
       " matrix([[-1.4458933e-06, -6.6526474e-07,  3.6676084e-07, -5.0247354e-07,\n",
       "          -1.2690022e-07]], dtype=float32),\n",
       " matrix([[-1.9927523e-07,  1.7080734e-07,  7.2504157e-08,  1.7792431e-09,\n",
       "           2.0461297e-08]], dtype=float32),\n",
       " matrix([[ 7.3892443e-07,  3.1866117e-07, -2.3784129e-07,  6.0037607e-08,\n",
       "           5.8305755e-08]], dtype=float32),\n",
       " matrix([[-5.2881467e-07, -4.1130031e-07, -1.7175178e-07, -1.4011329e-07,\n",
       "          -1.7471788e-07]], dtype=float32),\n",
       " matrix([[-2.5471672e-07, -2.2910535e-07, -1.4342368e-07,  1.9557774e-08,\n",
       "          -1.8626451e-07]], dtype=float32),\n",
       " matrix([[ 6.3578290e-07,  1.5330895e-07, -5.7149023e-08,  1.6742878e-07,\n",
       "           1.0626147e-07]], dtype=float32),\n",
       " matrix([[ 2.1108112e-07,  1.5775063e-07, -6.0052798e-08,  1.8643257e-07,\n",
       "          -3.7645037e-08]], dtype=float32),\n",
       " matrix([[-1.1656019e-06,  1.2068101e-07, -2.6638125e-07,  3.0170252e-08,\n",
       "          -1.0541192e-07]], dtype=float32),\n",
       " matrix([[ 1.6061884e-07,  2.3590891e-07, -1.7442201e-07, -1.5042330e-07,\n",
       "           2.1857650e-07]], dtype=float32),\n",
       " matrix([[ 2.2423755e-07, -3.0577848e-08,  3.1907319e-07,  5.3178866e-08,\n",
       "           1.7604420e-07]], dtype=float32),\n",
       " matrix([[4.1060977e-07, 1.4238887e-07, 5.7948959e-08, 5.4637592e-08,\n",
       "          5.2154064e-08]], dtype=float32),\n",
       " matrix([[ 1.5026382e-07,  1.6028140e-07,  5.6098489e-08, -4.4077385e-08,\n",
       "           2.9652060e-07]], dtype=float32),\n",
       " matrix([[-1.0084832e-06, -2.2471636e-07,  3.2405742e-07, -7.1594087e-08,\n",
       "          -3.5283211e-08]], dtype=float32),\n",
       " matrix([[ 6.3996566e-07, -3.7645037e-08,  4.0782126e-08,  2.4586916e-07,\n",
       "          -7.7642895e-08]], dtype=float32),\n",
       " matrix([[ 2.8500611e-07, -2.4663992e-08,  4.5217316e-08, -1.2229229e-07,\n",
       "          -2.5349102e-08]], dtype=float32),\n",
       " matrix([[-9.6905616e-08, -3.0763687e-09, -4.3069164e-08,  2.0919308e-07,\n",
       "          -2.1534581e-07]], dtype=float32),\n",
       " matrix([[1.0299683e-06, 1.2516975e-07, 1.2397766e-07, 1.6212464e-07,\n",
       "          3.5017729e-07]], dtype=float32),\n",
       " matrix([[-6.9936118e-07,  9.5367433e-08,  5.0001674e-08, -1.8874805e-07,\n",
       "           1.0463926e-07]], dtype=float32),\n",
       " matrix([[-1.1299459e-06, -5.3785425e-07, -2.5084799e-07, -2.2598918e-09,\n",
       "          -5.9463403e-08]], dtype=float32),\n",
       " matrix([[ 5.9989191e-07,  4.6722351e-07, -3.4609148e-08,  1.9227304e-09,\n",
       "          -1.7304574e-08]], dtype=float32),\n",
       " matrix([[-1.0899135e-07, -1.9073487e-07, -1.4532181e-07,  4.9812453e-08,\n",
       "          -1.7370496e-07]], dtype=float32),\n",
       " matrix([[ 2.6822090e-07,  6.9538750e-08,  1.3286869e-07,  5.5879354e-08,\n",
       "          -5.9604645e-08]], dtype=float32),\n",
       " matrix([[ 5.57809528e-07, -3.28387841e-07, -1.03464664e-07,\n",
       "           1.61944698e-07,  2.74406290e-07]], dtype=float32),\n",
       " matrix([[-1.7438616e-06, -6.2670028e-07, -2.0163399e-07, -4.8637389e-07,\n",
       "          -3.0926296e-07]], dtype=float32),\n",
       " matrix([[ 3.9719521e-07,  8.5982869e-08, -8.2431953e-08, -2.8407321e-08,\n",
       "           3.6472969e-07]], dtype=float32),\n",
       " matrix([[ 9.4432454e-07,  3.3659094e-07,  1.5646219e-07,  6.8954392e-08,\n",
       "          -1.9868214e-07]], dtype=float32),\n",
       " matrix([[ 3.3181968e-07, -4.0309945e-07, -1.8434426e-07, -2.7037157e-07,\n",
       "          -1.1736585e-07]], dtype=float32),\n",
       " matrix([[-4.56105113e-07,  2.93704048e-08, -2.41873916e-08,\n",
       "           1.07115596e-07, -3.02342400e-08]], dtype=float32),\n",
       " matrix([[ 2.5142322e-07,  5.2018599e-08, -7.3693016e-08,  4.0097671e-08,\n",
       "           3.1725926e-07]], dtype=float32),\n",
       " matrix([[4.05311596e-07, 1.49011614e-09, 1.13248824e-07, 2.38418579e-07,\n",
       "          1.28149992e-07]], dtype=float32),\n",
       " matrix([[-6.6425076e-07,  1.6606269e-07, -4.5074160e-07, -8.5403670e-08,\n",
       "          -1.3759480e-07]], dtype=float32),\n",
       " matrix([[-3.9951220e-07, -2.5774980e-07, -4.8972464e-07, -1.9331235e-08,\n",
       "           1.3290225e-08]], dtype=float32),\n",
       " matrix([[ 2.7454260e-07,  2.0229456e-07,  8.3085261e-08,  3.6124028e-08,\n",
       "          -1.4088370e-07]], dtype=float32),\n",
       " matrix([[-8.1296827e-07,  0.0000000e+00,  2.3451008e-07, -2.1692182e-07,\n",
       "          -6.6200244e-08]], dtype=float32),\n",
       " matrix([[7.6001629e-07, 1.6808053e-07, 2.9779486e-07, 7.3078489e-08,\n",
       "          2.0096586e-07]], dtype=float32),\n",
       " matrix([[ 5.2275482e-07, -2.7903803e-07, -1.2009232e-07, -1.2892264e-07,\n",
       "           3.5321270e-09]], dtype=float32),\n",
       " matrix([[-2.0435878e-07, -3.4059798e-07,  1.3198171e-07,  6.3862117e-08,\n",
       "           8.0892015e-08]], dtype=float32),\n",
       " matrix([[-5.5905048e-07,  1.1098796e-07, -1.9731193e-07, -1.5723295e-07,\n",
       "          -1.0276663e-07]], dtype=float32),\n",
       " matrix([[ 8.6284821e-08,  1.8165226e-08, -7.2660903e-08,  6.0172312e-08,\n",
       "           3.7465778e-08]], dtype=float32),\n",
       " matrix([[ 6.3143671e-07,  2.5890768e-07,  6.4261258e-07, -4.4936314e-08,\n",
       "           3.4179538e-07]], dtype=float32),\n",
       " matrix([[1.2737431e-07, 8.9815217e-08, 2.0167599e-07, 1.8289644e-07,\n",
       "          8.4916209e-08]], dtype=float32),\n",
       " matrix([[ 6.3578290e-07,  2.5857897e-08,  1.6263449e-07,  2.5010576e-07,\n",
       "          -6.8370035e-08]], dtype=float32),\n",
       " matrix([[ 2.1347940e-07,  3.9902691e-08,  4.8880796e-08,  1.2469592e-07,\n",
       "          -6.4841871e-08]], dtype=float32),\n",
       " matrix([[ 1.1711790e-07,  1.5058015e-07, -3.0325172e-08,  3.2416562e-08,\n",
       "          -1.1764074e-09]], dtype=float32),\n",
       " matrix([[-8.2232992e-07,  3.5691404e-08, -4.4542873e-07, -3.2265029e-07,\n",
       "          -2.1985905e-07]], dtype=float32),\n",
       " matrix([[ 5.0193387e-07,  1.8822520e-07, -2.1645897e-07,  1.2548346e-08,\n",
       "           1.5267155e-07]], dtype=float32),\n",
       " matrix([[-6.68810571e-07, -6.19269036e-09, -2.70930212e-08,\n",
       "          -1.11081384e-07,  1.16112941e-08]], dtype=float32),\n",
       " matrix([[-1.6348703e-07,  8.8555474e-08,  2.5885447e-07,  6.1307638e-08,\n",
       "           1.2814999e-07]], dtype=float32),\n",
       " matrix([[ 6.4683996e-07, -2.3219896e-07,  7.4635381e-08, -7.4829742e-08,\n",
       "           1.2957531e-07]], dtype=float32),\n",
       " matrix([[ 5.35874165e-07,  1.81652258e-08, -7.26609031e-08,\n",
       "          -5.67663305e-10,  1.04450045e-07]], dtype=float32),\n",
       " matrix([[-3.5591674e-07,  1.4601711e-07, -1.3917257e-07, -5.9319454e-08,\n",
       "          -4.6200729e-08]], dtype=float32),\n",
       " matrix([[-3.4263749e-07,  3.2407794e-07,  2.9552481e-07,  7.2810465e-08,\n",
       "           4.4257341e-08]], dtype=float32),\n",
       " matrix([[ 1.5361196e-07, -9.6007478e-09,  1.4081097e-07,  1.6801309e-08,\n",
       "          -7.5205861e-08]], dtype=float32),\n",
       " matrix([[-6.8119596e-07, -6.9822585e-07,  8.5149495e-08, -4.3506068e-07,\n",
       "          -1.7029899e-07]], dtype=float32),\n",
       " matrix([[-4.7192131e-07, -1.1798033e-07, -2.9003496e-07, -1.2228169e-07,\n",
       "          -2.9725513e-07]], dtype=float32),\n",
       " matrix([[ 1.4449611e-07,  2.6490954e-07,  1.7098706e-07, -2.8899223e-08,\n",
       "           9.6330737e-08]], dtype=float32),\n",
       " matrix([[-7.2702949e-07, -9.1246619e-08, -1.6704018e-07,  2.0972005e-08,\n",
       "           2.2922033e-07]], dtype=float32),\n",
       " matrix([[ 9.4296411e-09, -1.1101365e-06, -1.5459955e-06, -5.0337985e-07,\n",
       "          -1.5459955e-07]], dtype=float32),\n",
       " matrix([[ 9.67698952e-07,  4.72162270e-07,  1.26221607e-07,\n",
       "          -3.92689429e-07, -1.07522105e-07]], dtype=float32),\n",
       " matrix([[-2.36774312e-07, -1.18387156e-07, -1.54561008e-07,\n",
       "          -7.89247707e-08, -5.09722469e-08]], dtype=float32),\n",
       " matrix([[-5.0401439e-07,  8.4002401e-08, -1.5194551e-07, -1.2693010e-07,\n",
       "          -2.8289043e-07]], dtype=float32),\n",
       " matrix([[-2.2293685e-07, -1.2385381e-08, -1.3159467e-07,  4.2574747e-08,\n",
       "          -1.2520846e-07]], dtype=float32),\n",
       " matrix([[-6.6173322e-07, -3.2437903e-08,  6.4875806e-08, -6.0010116e-08,\n",
       "           3.6898115e-08]], dtype=float32),\n",
       " matrix([[ 3.0517577e-07,  1.4495849e-07,  1.5258789e-07,  6.6757204e-09,\n",
       "          -1.3446808e-07]], dtype=float32),\n",
       " matrix([[ 3.46790671e-07, -1.12706964e-07,  1.14874403e-07,\n",
       "          -2.76348811e-08,  1.53888351e-07]], dtype=float32),\n",
       " matrix([[-9.6381984e-07,  2.9802322e-08,  1.4457297e-07, -5.9921689e-08,\n",
       "           1.8117197e-07]], dtype=float32),\n",
       " matrix([[-5.2018601e-07, -7.1427053e-08, -1.8915854e-07,  3.7591565e-08,\n",
       "           3.5929041e-08]], dtype=float32),\n",
       " matrix([[1.0229356e-06, 5.0613998e-08, 1.5983369e-08, 4.1956341e-08,\n",
       "          1.1821033e-07]], dtype=float32),\n",
       " matrix([[ 1.7498611e-07, -6.9994442e-08, -8.8860136e-10,  8.7493053e-09,\n",
       "           7.2728604e-08]], dtype=float32),\n",
       " matrix([[ 9.5945416e-07,  6.6468209e-07,  1.3510386e-07, -1.6761548e-07,\n",
       "          -1.4449611e-08]], dtype=float32),\n",
       " matrix([[7.5531005e-07, 3.4332277e-07, 4.0817261e-07, 1.2207032e-07,\n",
       "          3.1471252e-08]], dtype=float32),\n",
       " matrix([[ 2.2936472e-07,  2.2936472e-07, -1.0261053e-07,  5.5832199e-08,\n",
       "          -7.5448919e-10]], dtype=float32),\n",
       " matrix([[ 8.2157754e-08,  9.6656176e-09,  2.5774982e-08, -2.4486232e-07,\n",
       "          -1.5464988e-07]], dtype=float32),\n",
       " matrix([[-6.0532619e-07, -1.0279124e-07,  8.8514682e-08, -8.2804057e-08,\n",
       "          -9.7080616e-08]], dtype=float32),\n",
       " matrix([[-6.0550752e-07, -1.0091791e-08, -2.1823500e-07, -4.0367166e-08,\n",
       "          -7.3165488e-08]], dtype=float32),\n",
       " matrix([[ 5.1657361e-07,  2.5828680e-07,  2.5828680e-07, -2.4276474e-07,\n",
       "           2.0861626e-07]], dtype=float32),\n",
       " matrix([[ 1.4395084e-07, -5.8480030e-08, -4.2735405e-08, -4.7796178e-08,\n",
       "          -4.8920793e-08]], dtype=float32),\n",
       " matrix([[-1.6312850e-07,  3.6076496e-08,  4.2350667e-08, -5.0193385e-08,\n",
       "           3.6076496e-08]], dtype=float32),\n",
       " matrix([[ 9.42454619e-07,  2.52443204e-08, -1.65490547e-07,\n",
       "          -2.30705041e-07,  1.02379744e-07]], dtype=float32),\n",
       " matrix([[ 9.4911127e-07,  2.7150060e-07,  6.9015904e-08, -6.1600971e-08,\n",
       "           9.6964492e-08]], dtype=float32),\n",
       " matrix([[ 4.0581887e-07, -4.7345534e-08,  2.1981855e-07, -7.4400127e-08,\n",
       "          -6.2141012e-08]], dtype=float32),\n",
       " matrix([[-3.0179567e-07,  2.1729288e-07, -6.9413005e-08, -1.2071827e-08,\n",
       "           1.1468236e-07]], dtype=float32),\n",
       " matrix([[ 2.2049062e-06,  1.2721866e-06, -1.4295802e-07,  2.3283064e-08,\n",
       "           8.9406967e-07]], dtype=float32),\n",
       " matrix([[ 1.1951417e-07,  0.0000000e+00, -5.6098489e-08,  6.7684049e-08,\n",
       "           1.4664877e-07]], dtype=float32),\n",
       " matrix([[ 8.9528612e-07, -2.4977186e-07,  3.2437902e-07, -2.9031924e-07,\n",
       "          -2.7126197e-07]], dtype=float32),\n",
       " matrix([[ 2.7359508e-07,  2.5796109e-07,  1.7197405e-07,  3.4199386e-09,\n",
       "          -4.8856265e-08]], dtype=float32),\n",
       " matrix([[ 3.9085012e-07,  3.7326188e-07,  2.0715056e-07, -1.8321099e-08,\n",
       "          -1.1725504e-08]], dtype=float32),\n",
       " matrix([[ 2.5675848e-07, -1.4671913e-07,  2.2924864e-08,  1.6047404e-07,\n",
       "           9.1699455e-08]], dtype=float32),\n",
       " matrix([[-1.3854374e-06, -9.7265293e-08,  6.5238915e-08, -2.6273491e-07,\n",
       "           2.1588150e-07]], dtype=float32),\n",
       " matrix([[ 4.0154710e-08,  1.5058015e-08, -6.5251399e-08, -3.2625699e-08,\n",
       "           4.7056300e-08]], dtype=float32),\n",
       " matrix([[-2.1538037e-06, -2.5181288e-07, -6.1783311e-07,  1.5671334e-07,\n",
       "           1.9036652e-07]], dtype=float32),\n",
       " matrix([[ 3.7134222e-07,  2.0255030e-07,  1.7723151e-07, -1.5191273e-07,\n",
       "           2.9538585e-08]], dtype=float32),\n",
       " matrix([[ 1.8699497e-08,  1.6829547e-07,  6.1357724e-08, -4.5580023e-08,\n",
       "          -1.2388416e-07]], dtype=float32),\n",
       " matrix([[-3.0199686e-07,  1.5894573e-08,  6.3578291e-08,  3.0919910e-08,\n",
       "          -6.0101350e-08]], dtype=float32),\n",
       " matrix([[ 1.0427719e-06,  1.6499555e-07, -9.7347382e-08,  1.0312222e-08,\n",
       "           1.0430813e-07]], dtype=float32),\n",
       " matrix([[4.4750050e-07, 7.0803799e-07, 7.6158904e-07, 1.3076933e-06,\n",
       "          1.7759157e-07]], dtype=float32),\n",
       " matrix([[ 7.4317865e-07,  2.0942173e-07,  1.7183321e-07,  8.9138474e-08,\n",
       "          -5.0207515e-08]], dtype=float32),\n",
       " matrix([[-2.22524008e-07, -2.78155010e-08, -1.30136812e-07,\n",
       "          -1.13248824e-07,  1.11262004e-07]], dtype=float32),\n",
       " matrix([[-9.6516442e-07,  3.3321152e-07, -2.3590513e-07, -7.8994105e-08,\n",
       "          -2.7001622e-07]], dtype=float32),\n",
       " matrix([[-6.9266872e-07,  4.5174048e-08, -1.3677698e-07, -7.5290075e-08,\n",
       "          -1.3552214e-07]], dtype=float32),\n",
       " matrix([[ 8.6697668e-08,  4.4897003e-08, -8.5149495e-08,  2.1674417e-07,\n",
       "           3.7930228e-08]], dtype=float32),\n",
       " matrix([[-1.0182658e-06,  1.8047622e-07,  3.7615044e-07,  3.0039789e-08,\n",
       "          -8.5132534e-08]], dtype=float32),\n",
       " matrix([[-4.1018250e-08,  1.2818203e-08,  3.1815182e-07, -2.0252762e-07,\n",
       "          -1.1350118e-07]], dtype=float32),\n",
       " matrix([[ 1.8060734e-06,  1.9833050e-07, -2.1626464e-08,  3.3125414e-07,\n",
       "           1.7406666e-08]], dtype=float32),\n",
       " matrix([[ 0.0000000e+00,  5.0727358e-08, -1.1286837e-07, -9.8918349e-08,\n",
       "           4.8190991e-08]], dtype=float32),\n",
       " matrix([[ 2.70545897e-08,  6.08728286e-08,  2.87455020e-08,\n",
       "           3.93137007e-08, -1.14136554e-07]], dtype=float32),\n",
       " matrix([[ 1.9972236e-07, -4.2441005e-08,  1.9254485e-07, -1.4042979e-08,\n",
       "           6.9902832e-08]], dtype=float32),\n",
       " matrix([[-2.6702881e-07,  1.4781952e-07,  1.6063451e-07,  3.8146972e-08,\n",
       "          -3.9219856e-07]], dtype=float32),\n",
       " matrix([[ 4.35009326e-07,  2.00773542e-07, -5.85589497e-08,\n",
       "           1.06660941e-07, -1.18686444e-07]], dtype=float32),\n",
       " matrix([[-5.6499192e-07,  4.0070351e-09, -1.5376996e-07, -6.2509747e-07,\n",
       "          -1.6028140e-07]], dtype=float32),\n",
       " matrix([[ 8.8424974e-07, -6.9881310e-08, -2.0827370e-07,  2.9962180e-07,\n",
       "          -1.5392158e-07]], dtype=float32),\n",
       " matrix([[-2.7247838e-08,  8.3446501e-08,  2.4182455e-07,  1.3113022e-07,\n",
       "          -7.0886955e-08]], dtype=float32),\n",
       " matrix([[ 1.3154128e-07, -2.1375459e-07,  1.6442661e-07,  1.3154128e-07,\n",
       "           1.6031593e-07]], dtype=float32),\n",
       " matrix([[ 3.6808481e-07, -1.3384903e-07,  4.6010604e-07, -6.3787425e-08,\n",
       "          -3.7645037e-08]], dtype=float32),\n",
       " matrix([[-2.1311158e-07,  1.4917811e-07, -6.1269581e-08, -1.1188358e-07,\n",
       "           1.0322592e-07]], dtype=float32),\n",
       " matrix([[ 8.3446503e-07,  1.5050173e-07,  2.3841858e-08, -1.7881394e-08,\n",
       "           2.8312206e-07]], dtype=float32),\n",
       " matrix([[-1.1506909e-06, -3.9546075e-07, -6.5672182e-08,  1.5561452e-07,\n",
       "          -5.1110089e-07]], dtype=float32),\n",
       " matrix([[-6.2355628e-07, -1.4366248e-07, -3.1177814e-07, -7.5804883e-07,\n",
       "           1.5283243e-07]], dtype=float32),\n",
       " matrix([[3.4090621e-07, 1.6829547e-07, 3.0206881e-08, 2.1576343e-09,\n",
       "          1.6182257e-08]], dtype=float32),\n",
       " matrix([[1.5207239e-06, 1.9331235e-08, 2.1828187e-07, 2.1727504e-07,\n",
       "          4.2448173e-07]], dtype=float32),\n",
       " matrix([[ 9.1816514e-07,  5.0727358e-08,  1.0621041e-07, -1.2745248e-07,\n",
       "           2.0290943e-07]], dtype=float32),\n",
       " matrix([[ 7.4768064e-07,  2.4795531e-07, -3.8146974e-09,  1.9359588e-07,\n",
       "           7.7128412e-08]], dtype=float32),\n",
       " matrix([[-2.7528742e-07, -1.2781202e-07,  1.4747541e-08, -1.8434426e-08,\n",
       "           2.7037158e-08]], dtype=float32),\n",
       " matrix([[-1.83398910e-07, -1.83398914e-08,  1.10039345e-07,\n",
       "           4.58497285e-09,  2.98739629e-08]], dtype=float32),\n",
       " matrix([[-1.6348703e-07, -2.8865679e-07, -3.7040028e-08,  4.2574747e-08,\n",
       "           8.0040522e-08]], dtype=float32),\n",
       " matrix([[-1.76970488e-07,  1.08148633e-07, -1.03232786e-07,\n",
       "           8.11114731e-08, -1.40101633e-07]], dtype=float32),\n",
       " matrix([[ 1.7579251e-07, -1.0767290e-07, -4.8342937e-08, -2.5709653e-07,\n",
       "          -1.1914062e-07]], dtype=float32),\n",
       " matrix([[-9.6502754e-07, -4.7116052e-07, -4.8960959e-07,  1.5153948e-07,\n",
       "          -1.3960968e-07]], dtype=float32),\n",
       " matrix([[ 1.8289644e-07,  3.9192095e-08,  3.2660079e-09, -2.4821659e-07,\n",
       "          -9.4714231e-08]], dtype=float32),\n",
       " matrix([[-5.1770894e-07, -1.8392291e-07,  5.8114530e-08, -2.0265580e-07,\n",
       "          -4.8109463e-08]], dtype=float32),\n",
       " matrix([[ 9.3149583e-07, -5.6370283e-08,  8.3169269e-08,  2.4119089e-07,\n",
       "          -1.3491903e-07]], dtype=float32),\n",
       " matrix([[1.3258399e-06, 3.0238454e-07, 4.8846732e-07, 2.8145021e-07,\n",
       "          1.6631149e-07]], dtype=float32),\n",
       " matrix([[-7.7934675e-07,  3.5314150e-07,  2.1534581e-07, -5.2554633e-08,\n",
       "          -2.5892771e-07]], dtype=float32),\n",
       " matrix([[-5.6624413e-07, -2.9802322e-08, -2.6077032e-08, -1.1920929e-07,\n",
       "           2.5052577e-07]], dtype=float32),\n",
       " matrix([[ 4.1181391e-07,  2.7634880e-07,  2.6009300e-07, -2.4383718e-08,\n",
       "          -2.0861626e-07]], dtype=float32),\n",
       " matrix([[-4.1239971e-08, -1.7333674e-07, -2.3197483e-08, -1.6238238e-07,\n",
       "           2.0458891e-08]], dtype=float32),\n",
       " matrix([[ 6.5878815e-08, -3.5135369e-07,  2.1332188e-07,  5.0193385e-08,\n",
       "           6.5878815e-08]], dtype=float32),\n",
       " matrix([[-2.6822090e-07,  2.2351742e-07, -3.3527613e-08, -2.0721927e-07,\n",
       "          -3.2596290e-08]], dtype=float32),\n",
       " matrix([[-1.6412069e-06, -3.7333763e-07, -3.9311919e-07, -2.5747821e-07,\n",
       "          -1.9918751e-08]], dtype=float32),\n",
       " matrix([[-3.74448803e-07, -1.17015254e-07, -7.53285718e-08,\n",
       "           5.30225357e-08, -2.12090150e-08]], dtype=float32),\n",
       " matrix([[ 7.4400127e-08,  1.3527296e-07,  1.0483654e-07, -1.3527295e-08,\n",
       "           4.8613717e-08]], dtype=float32),\n",
       " matrix([[-4.0154708e-07,  9.6801529e-08, -3.2939408e-08,  5.3778626e-09,\n",
       "           8.9631044e-08]], dtype=float32),\n",
       " matrix([[ 1.8658845e-07,  1.7622243e-07, -2.3453131e-07,  3.7900779e-08,\n",
       "          -1.1920929e-07]], dtype=float32),\n",
       " matrix([[ 5.0108309e-07,  2.4650058e-07,  1.5961922e-07, -2.7781826e-09,\n",
       "           1.1617854e-08]], dtype=float32),\n",
       " matrix([[-2.1192763e-07, -1.4570024e-07,  3.7844221e-09, -3.0275376e-07,\n",
       "          -6.2916016e-08]], dtype=float32),\n",
       " matrix([[ 4.4356945e-08, -1.5524931e-07,  3.6964121e-09,  3.1419503e-08,\n",
       "           4.9901562e-08]], dtype=float32),\n",
       " matrix([[ 1.1235068e-06,  1.7636442e-07,  4.8990119e-09,  2.2606899e-07,\n",
       "          -7.6342936e-08]], dtype=float32),\n",
       " matrix([[-5.8572124e-07, -1.5769417e-07,  3.1914297e-08, -2.4405052e-08,\n",
       "          -1.2624920e-07]], dtype=float32),\n",
       " matrix([[ 5.239969e-07, -8.121952e-08,  6.156964e-08,  7.597955e-08,\n",
       "           9.743067e-08]], dtype=float32),\n",
       " matrix([[-4.7683716e-07, -1.2874604e-07, -1.2397766e-07, -5.8412553e-08,\n",
       "          -8.0466272e-08]], dtype=float32),\n",
       " matrix([[ 6.8664548e-08,  1.1253357e-07,  4.3869019e-08, -4.2438508e-08,\n",
       "          -9.8228455e-08]], dtype=float32),\n",
       " matrix([[ 2.6009300e-07, -8.2362781e-08,  5.2018599e-08, -1.1595813e-07,\n",
       "           1.4955347e-07]], dtype=float32),\n",
       " matrix([[-3.2885321e-08, -9.0434632e-08, -7.3991970e-08,  1.0276663e-08,\n",
       "           4.1106651e-09]], dtype=float32),\n",
       " matrix([[-1.1704185e-06, -2.0373952e-07,  8.0195342e-08,  8.6697662e-09,\n",
       "           5.7979065e-08]], dtype=float32),\n",
       " matrix([[-3.7715932e-08, -5.9267894e-08, -3.5021937e-08,  2.9633947e-08,\n",
       "          -6.7349881e-10]], dtype=float32),\n",
       " matrix([[2.62078430e-07, 2.18398696e-07, 1.05559373e-07, 9.50944354e-08,\n",
       "          1.08289356e-07]], dtype=float32),\n",
       " matrix([[ 1.2715658e-06,  3.2243275e-07,  5.1770894e-07, -2.2706531e-07,\n",
       "           4.1297503e-07]], dtype=float32),\n",
       " matrix([[-1.1032051e-06, -1.8774425e-07, -1.6282245e-07, -1.8940570e-07,\n",
       "          -5.6904781e-08]], dtype=float32),\n",
       " matrix([[-1.2925257e-07, -1.1178600e-07,  1.6898899e-07,  7.8599534e-08,\n",
       "          -3.5806455e-08]], dtype=float32),\n",
       " matrix([[-2.5431316e-07, -1.2516975e-07, -2.4139882e-07, -7.3512396e-08,\n",
       "          -5.8114530e-08]], dtype=float32),\n",
       " matrix([[ 1.3830037e-06,  4.5044396e-07, -4.9267307e-08, -2.4721632e-07,\n",
       "          -2.1334504e-08]], dtype=float32),\n",
       " matrix([[ 3.8552793e-07,  3.0816869e-07,  2.7519590e-07,  1.9561737e-07,\n",
       "          -5.6434185e-08]], dtype=float32),\n",
       " matrix([[-1.5600568e-06, -5.8433221e-07, -3.8295124e-07,  5.2093770e-07,\n",
       "           9.5780877e-08]], dtype=float32),\n",
       " matrix([[ 3.2011445e-07, -2.7093021e-08,  1.7339534e-07, -1.6672628e-08,\n",
       "           1.6839354e-07]], dtype=float32),\n",
       " matrix([[-1.4059005e-06, -2.1996037e-07, -1.6612391e-07, -8.6753602e-07,\n",
       "          -7.7582172e-08]], dtype=float32),\n",
       " matrix([[-1.7100368e-07, -9.3723166e-08, -7.8924771e-08,  3.8640252e-08,\n",
       "           1.5003927e-08]], dtype=float32),\n",
       " matrix([[-2.4573202e-07, -2.3110512e-07,  6.6186750e-08, -6.1433006e-08,\n",
       "           5.7044936e-08]], dtype=float32),\n",
       " matrix([[ 2.9669869e-07,  1.2715658e-07,  5.6955550e-08, -1.5894573e-08,\n",
       "           3.2451418e-08]], dtype=float32),\n",
       " matrix([[-9.4190057e-08, -1.7071947e-07, -5.8868785e-08,  2.9434393e-08,\n",
       "          -1.8543668e-07]], dtype=float32),\n",
       " matrix([[ 1.0775981e-08,  8.3513854e-08, -8.0819859e-08,  1.8453868e-07,\n",
       "           8.6207848e-08]], dtype=float32),\n",
       " matrix([[-1.3398731e-06, -1.2425845e-07,  3.9408029e-08, -3.2954964e-07,\n",
       "          -3.2511625e-08]], dtype=float32),\n",
       " matrix([[1.2223149e-06, 3.7609692e-07, 3.0222072e-08, 1.9938174e-08,\n",
       "          3.0389972e-07]], dtype=float32),\n",
       " matrix([[ 9.8546343e-07,  2.2384856e-07,  1.8013849e-07, -5.8559493e-08,\n",
       "           4.2716660e-08]], dtype=float32),\n",
       " matrix([[ 1.6348703e-07,  4.0871758e-08, -6.8119594e-09,  2.1798270e-07,\n",
       "          -2.1117074e-07]], dtype=float32),\n",
       " matrix([[ 4.0871757e-07, -3.4059799e-08,  1.0217939e-07,  2.9802322e-08,\n",
       "           1.4901161e-08]], dtype=float32),\n",
       " matrix([[ 4.8618693e-07,  4.3826944e-08, -1.4024623e-07,  1.5738743e-07,\n",
       "           1.9011155e-07]], dtype=float32),\n",
       " matrix([[ 9.3236315e-07,  3.0901180e-07,  2.5839779e-07, -1.5483889e-07,\n",
       "           8.8740997e-08]], dtype=float32),\n",
       " matrix([[-1.5570193e-06, -2.1084637e-07, -3.5681690e-08, -3.0005060e-07,\n",
       "          -5.5833738e-07]], dtype=float32),\n",
       " matrix([[ 4.5684996e-07,  7.4951949e-08, -1.3277203e-07, -5.7106245e-08,\n",
       "           1.1278484e-07]], dtype=float32),\n",
       " matrix([[ 1.0940264e-06,  3.2388940e-08, -2.9150044e-07, -6.8376650e-08,\n",
       "           1.8938532e-07]], dtype=float32),\n",
       " matrix([[-2.3119378e-07,  5.2018599e-08, -1.5894573e-08,  1.1848681e-07,\n",
       "           1.0403720e-07]], dtype=float32),\n",
       " matrix([[-3.2002495e-07,  3.6871622e-08, -8.4006544e-08, -1.9639030e-08,\n",
       "          -8.5406654e-08]], dtype=float32),\n",
       " matrix([[ 1.0234554e-07, -4.7102208e-08,  8.6063295e-08,  1.6805602e-07,\n",
       "          -1.6049641e-07]], dtype=float32),\n",
       " matrix([[ 1.2858530e-07,  8.7062965e-08,  1.1117271e-07, -1.7123779e-07,\n",
       "          -5.0228635e-09]], dtype=float32),\n",
       " matrix([[ 1.08382665e-07, -2.40281224e-07,  4.09781933e-07,\n",
       "           2.02562660e-07,  1.82539225e-07]], dtype=float32),\n",
       " matrix([[7.5290075e-08, 8.1564252e-08, 1.2862056e-07, 1.9998927e-07,\n",
       "          3.2155139e-08]], dtype=float32),\n",
       " matrix([[ 2.9903347e-07,  5.0647111e-07,  1.1314780e-07, -1.8049768e-07,\n",
       "          -2.1551962e-08]], dtype=float32),\n",
       " matrix([[-2.6207843e-07,  2.5206850e-07, -6.1424636e-08,  7.2799566e-09,\n",
       "          -1.0191939e-07]], dtype=float32),\n",
       " matrix([[-5.6653920e-07, -1.0386552e-07, -9.3242910e-08, -1.1802900e-07,\n",
       "          -1.8648582e-07]], dtype=float32),\n",
       " matrix([[ 0.0000000e+00,  5.8218490e-08, -9.3911972e-08, -6.9307724e-08,\n",
       "          -6.2550221e-08]], dtype=float32),\n",
       " matrix([[-1.4512435e-07, -1.1726566e-07,  1.2957531e-08,  4.7942866e-08,\n",
       "          -3.0450199e-08]], dtype=float32),\n",
       " matrix([[ 3.6215479e-07, -3.0179567e-07,  4.7344194e-08, -1.5391579e-07,\n",
       "           6.3377094e-08]], dtype=float32),\n",
       " matrix([[2.5796109e-07, 1.0162103e-07, 2.0519632e-07, 2.9313760e-09,\n",
       "          8.1101405e-08]], dtype=float32),\n",
       " matrix([[-2.89880518e-07, -7.40009568e-07, -1.78488222e-07,\n",
       "           1.14649374e-07, -2.34510082e-07]], dtype=float32),\n",
       " matrix([[-4.7923333e-08,  1.4174823e-07,  2.8754000e-08, -1.0483229e-07,\n",
       "           1.7492016e-07]], dtype=float32),\n",
       " matrix([[ 2.8141210e-07,  3.1268009e-08, -3.9085011e-09,  2.9313760e-09,\n",
       "           2.3451008e-08]], dtype=float32),\n",
       " matrix([[8.0841266e-07, 9.4735860e-08, 1.6262989e-07, 6.3946707e-08,\n",
       "          8.4867544e-08]], dtype=float32),\n",
       " matrix([[-4.7202062e-07,  1.2041342e-08, -1.2041342e-07, -2.9862528e-07,\n",
       "           1.0957621e-07]], dtype=float32),\n",
       " matrix([[ 5.2756451e-07,  1.2681839e-07, -1.7754575e-08, -2.7900047e-08,\n",
       "           5.1995542e-08]], dtype=float32),\n",
       " matrix([[-1.5915214e-06, -4.3348834e-07, -3.5298336e-07,  1.0295348e-07,\n",
       "          -1.4746344e-07]], dtype=float32),\n",
       " matrix([[-4.6428880e-07,  9.4112593e-09, -1.5058015e-07, -4.1566398e-08,\n",
       "           5.7643966e-08]], dtype=float32),\n",
       " matrix([[-2.0980835e-07, -1.6212464e-07, -2.7716160e-07, -1.6689301e-08,\n",
       "           3.2484532e-08]], dtype=float32),\n",
       " matrix([[-9.7980241e-08, -3.9192096e-07, -2.7761068e-08, -7.6751185e-08,\n",
       "           7.0219173e-08]], dtype=float32),\n",
       " matrix([[-1.50184931e-08, -1.48307620e-07,  4.36474963e-08,\n",
       "           1.07241426e-07,  7.41538102e-08]], dtype=float32),\n",
       " matrix([[ 6.86645535e-07,  2.73386632e-07, -6.35782893e-09,\n",
       "          -1.13248824e-07, -4.86771246e-09]], dtype=float32),\n",
       " matrix([[ 5.6704960e-07,  2.5774980e-07, -1.1276555e-08, -7.5177027e-08,\n",
       "           2.5238002e-08]], dtype=float32),\n",
       " matrix([[ 1.4395084e-08, -5.0382795e-08, -3.8686789e-08, -2.0468010e-08,\n",
       "          -2.9240015e-08]], dtype=float32),\n",
       " matrix([[ 1.0049471e-06,  5.2554633e-08, -5.8963735e-08,  3.1773121e-07,\n",
       "           1.2561839e-07]], dtype=float32),\n",
       " matrix([[-6.2951898e-07, -7.0468545e-08, -2.4076753e-08,  6.0925927e-08,\n",
       "          -1.8409908e-07]], dtype=float32),\n",
       " matrix([[ 1.0732157e-06,  3.6659347e-07,  3.9780704e-07, -1.6944364e-07,\n",
       "           3.7970980e-07]], dtype=float32),\n",
       " matrix([[ 4.6624078e-07,  3.7087335e-07, -3.7087336e-08,  4.3875641e-08,\n",
       "          -9.6691977e-08]], dtype=float32),\n",
       " matrix([[ 5.8248372e-07, -2.1414843e-07,  2.7982060e-07,  2.8196209e-07,\n",
       "          -4.8718768e-08]], dtype=float32),\n",
       " matrix([[ 8.3164014e-07,  6.4632906e-07, -5.8757184e-08,  1.3559351e-07,\n",
       "          -6.2500128e-08]], dtype=float32),\n",
       " matrix([[-1.1219698e-07, -6.1107286e-08,  2.0235527e-07, -6.2109045e-08,\n",
       "          -8.0140701e-08]], dtype=float32),\n",
       " matrix([[-2.5902264e-07, -1.2362445e-07,  4.4151587e-08, -2.1339934e-08,\n",
       "          -3.6792990e-08]], dtype=float32),\n",
       " matrix([[-1.1080263e-06, -6.3945794e-07, -8.9579238e-08, -4.1929974e-07,\n",
       "          -2.2050273e-08]], dtype=float32),\n",
       " matrix([[ 7.4797987e-07, -1.0284723e-07,  4.2073868e-08,  1.2768250e-07,\n",
       "          -4.7917460e-08]], dtype=float32),\n",
       " matrix([[1.0103793e-06, 2.5259482e-07, 1.3660740e-07, 1.8783518e-07,\n",
       "          8.6990561e-08]], dtype=float32),\n",
       " matrix([[ 4.9793613e-07,  3.4602343e-07,  4.3041939e-07, -1.0444000e-07,\n",
       "          -2.6901212e-08]], dtype=float32),\n",
       " matrix([[-1.3987223e-07, -1.7007191e-07, -3.1789146e-08, -3.6358834e-08,\n",
       "           6.0399373e-08]], dtype=float32),\n",
       " matrix([[ 2.6053988e-07,  7.3737702e-08, -2.9495082e-08,  3.1953004e-08,\n",
       "          -1.7973566e-08]], dtype=float32),\n",
       " matrix([[-5.7757740e-07, -8.2271200e-08, -1.0929267e-07, -5.0370122e-08,\n",
       "          -1.7965344e-07]], dtype=float32),\n",
       " matrix([[-2.47518528e-07, -5.82396531e-08,  2.41148570e-07,\n",
       "           4.00397617e-08, -1.08289356e-07]], dtype=float32),\n",
       " matrix([[-3.5321271e-08, -1.3245477e-07, -7.7265279e-09,  1.6073939e-08,\n",
       "          -1.1976118e-07]], dtype=float32),\n",
       " matrix([[8.7193081e-07, 4.3596540e-07, 2.0499741e-07, 1.5241760e-07,\n",
       "          4.3851987e-08]], dtype=float32),\n",
       " matrix([[ 3.63304508e-07,  1.01044066e-07,  1.13532659e-08,\n",
       "           1.36239189e-08, -1.36239189e-08]], dtype=float32),\n",
       " matrix([[-3.1590463e-07, -9.5367433e-08,  1.8775464e-07, -2.3618341e-07,\n",
       "           1.2516975e-07]], dtype=float32),\n",
       " matrix([[-2.4523055e-07,  4.0871758e-08,  1.0217939e-08, -1.5433345e-08,\n",
       "           1.8307141e-07]], dtype=float32),\n",
       " matrix([[ 4.80591780e-07,  2.52498410e-07, -1.31411815e-08,\n",
       "          -2.62823630e-08,  5.96046448e-08]], dtype=float32),\n",
       " matrix([[-1.24561541e-06,  1.61784030e-07,  1.17688764e-07,\n",
       "          -2.95590382e-07, -2.32944686e-07]], dtype=float32),\n",
       " matrix([[-1.0561351e-06, -2.7585621e-08, -2.4432978e-07, -7.6845659e-08,\n",
       "          -2.6616175e-07]], dtype=float32),\n",
       " matrix([[ 4.9221899e-07, -2.9738231e-07,  1.4869116e-07, -1.3659398e-08,\n",
       "           3.8835150e-08]], dtype=float32),\n",
       " matrix([[ 3.4570695e-07,  4.9173831e-08,  2.9802322e-07, -9.3877318e-08,\n",
       "           6.1467289e-09]], dtype=float32),\n",
       " matrix([[-2.9550472e-07,  8.0592194e-08, -4.1975103e-08, -9.7382234e-08,\n",
       "           1.5593750e-07]], dtype=float32),\n",
       " matrix([[-2.1430884e-08,  1.5537391e-07, -3.9848050e-08, -1.9229195e-07,\n",
       "          -9.5936691e-08]], dtype=float32),\n",
       " matrix([[ 3.1268009e-08, -7.8170025e-08, -2.1985320e-08,  2.7359508e-08,\n",
       "           1.4950018e-07]], dtype=float32),\n",
       " matrix([[ 1.4901161e-07,  1.2665987e-07,  2.0395964e-07,  2.3283064e-08,\n",
       "          -6.1467290e-08]], dtype=float32),\n",
       " matrix([[ 7.0445628e-07, -2.8410855e-07,  1.5534590e-07,  1.0176403e-07,\n",
       "           2.0986235e-07]], dtype=float32),\n",
       " matrix([[-1.5283243e-07, -8.2529510e-08,  7.9472862e-08, -1.0469021e-07,\n",
       "          -1.5283243e-08]], dtype=float32),\n",
       " matrix([[-9.3944038e-07,  5.7825403e-08,  1.5079085e-07, -2.0806024e-07,\n",
       "          -1.2187816e-07]], dtype=float32),\n",
       " matrix([[-1.8517948e-06,  1.6203204e-07,  5.4396475e-07, -3.8728552e-07,\n",
       "          -3.1075430e-07]], dtype=float32),\n",
       " matrix([[1.1309058e-06, 3.6975979e-07, 2.1098990e-07, 2.6795718e-07,\n",
       "          4.2197978e-09]], dtype=float32),\n",
       " matrix([[ 2.8049246e-07, -3.0854170e-07, -1.2885121e-07, -7.1876187e-08,\n",
       "          -1.1219698e-07]], dtype=float32),\n",
       " matrix([[-3.4355969e-07, -2.1620566e-07,  1.1846886e-08,  8.4409059e-08,\n",
       "          -3.8872594e-09]], dtype=float32),\n",
       " matrix([[-2.19634089e-07, -2.36973619e-07,  1.10900764e-07,\n",
       "          -8.66976677e-08, -6.03271246e-08]], dtype=float32),\n",
       " matrix([[ 3.3775964e-07, -4.9670539e-09, -2.9802322e-08, -1.3411045e-07,\n",
       "          -3.1044085e-08]], dtype=float32),\n",
       " matrix([[ 1.5894572e-07,  4.7683716e-07,  1.4106432e-07, -6.0598055e-08,\n",
       "           2.6822089e-08]], dtype=float32),\n",
       " matrix([[-1.9073487e-07, -7.1525577e-08, -2.3841858e-08, -3.4059797e-09,\n",
       "          -6.8971090e-08]], dtype=float32),\n",
       " matrix([[-4.5654622e-07, -2.3334584e-07,  1.1920929e-07, -6.6024825e-08,\n",
       "           1.3950023e-08]], dtype=float32),\n",
       " matrix([[ 1.2588501e-06, -5.3942202e-08,  2.6240946e-07,  2.8371812e-07,\n",
       "          -2.6226044e-08]], dtype=float32),\n",
       " matrix([[3.3395816e-07, 3.4428675e-07, 7.5743088e-08, 4.2691559e-07,\n",
       "          9.3387783e-08]], dtype=float32),\n",
       " matrix([[-6.1527373e-08,  3.6531878e-07, -4.0377341e-08, -1.7208438e-07,\n",
       "           3.5570515e-08]], dtype=float32),\n",
       " matrix([[ 1.2341668e-07, -1.1219698e-08, -6.7318190e-08, -1.6829548e-08,\n",
       "          -1.9283856e-07]], dtype=float32),\n",
       " matrix([[-6.4437455e-07, -1.3531866e-07, -2.3761311e-07,  8.6185096e-08,\n",
       "          -1.3209679e-07]], dtype=float32),\n",
       " matrix([[-1.5874062e-06,  9.9981982e-08, -2.6610590e-07, -1.8294780e-07,\n",
       "          -6.2296465e-08]], dtype=float32),\n",
       " matrix([[-2.1107992e-06,  2.8186375e-07,  8.9009603e-08,  7.0412955e-07,\n",
       "           3.3809080e-08]], dtype=float32),\n",
       " matrix([[-1.6282245e-07,  1.2502437e-07,  3.0529208e-08, -7.0144488e-08,\n",
       "          -7.7776789e-08]], dtype=float32),\n",
       " matrix([[-1.6163972e-07, -1.3739376e-07,  2.8286950e-08, -6.3645636e-08,\n",
       "           7.6021180e-08]], dtype=float32),\n",
       " matrix([[-4.4803491e-07,  2.3201808e-08,  6.4004988e-09,  4.8803802e-08,\n",
       "          -1.3441047e-07]], dtype=float32),\n",
       " matrix([[-4.9569513e-07, -1.6163972e-07, -1.5355774e-07, -1.4951674e-07,\n",
       "          -5.7247398e-09]], dtype=float32),\n",
       " matrix([[-4.4627066e-07, -1.1768096e-07,  1.1768096e-07, -1.3754918e-07,\n",
       "          -1.1691680e-07]], dtype=float32),\n",
       " matrix([[ 1.8232009e-07, -7.7135425e-08,  4.3826944e-08, -3.5061557e-08,\n",
       "           1.9174289e-10]], dtype=float32),\n",
       " matrix([[ 1.5053095e-06, -1.6829547e-07,  5.0488643e-07,  1.0518467e-07,\n",
       "           3.3483786e-07]], dtype=float32),\n",
       " matrix([[ 5.5019672e-08,  1.4213416e-07, -1.9142261e-07, -2.1090874e-07,\n",
       "          -1.5818156e-07]], dtype=float32),\n",
       " matrix([[-5.5770425e-07, -3.3462257e-08,  1.2408920e-07,  1.1851216e-08,\n",
       "           2.1262476e-08]], dtype=float32),\n",
       " matrix([[-3.8146973e-07,  2.7857328e-07, -2.4312422e-07, -5.3016763e-08,\n",
       "           7.5917498e-08]], dtype=float32),\n",
       " matrix([[-5.9838391e-07, -8.4147736e-08, -2.8049245e-08, -6.9830932e-08,\n",
       "          -1.0942127e-07]], dtype=float32),\n",
       " matrix([[ 1.0360906e-06,  2.7668329e-07, -8.0944581e-08,  3.6792991e-09,\n",
       "           3.0685354e-07]], dtype=float32),\n",
       " matrix([[ 3.1370865e-07,  4.0782126e-08,  1.2548346e-08, -8.1564252e-08,\n",
       "          -7.6858619e-08]], dtype=float32),\n",
       " matrix([[ 3.3801115e-07, -4.5269348e-09, -1.1468236e-07, -3.4329258e-08,\n",
       "           9.7706348e-08]], dtype=float32),\n",
       " matrix([[-1.2362445e-07,  6.1812223e-08, -1.5011540e-07,  3.5321271e-08,\n",
       "           5.7397067e-08]], dtype=float32),\n",
       " matrix([[ 2.2649765e-07, -1.2144446e-07, -1.1920929e-08,  1.9371509e-08,\n",
       "          -6.8545340e-08]], dtype=float32),\n",
       " matrix([[-2.1192763e-07, -3.8853398e-07, -1.6336088e-07, -5.8765306e-08,\n",
       "           5.1510187e-09]], dtype=float32),\n",
       " matrix([[-6.3148707e-07, -2.4486232e-07,  9.6656180e-08, -1.5679781e-07,\n",
       "          -2.7922896e-08]], dtype=float32),\n",
       " matrix([[ 1.93967651e-07, -1.16809948e-08,  3.05094972e-07,\n",
       "           9.39530835e-08,  1.17693915e-07]], dtype=float32),\n",
       " matrix([[-1.2818203e-06, -3.0250959e-07, -7.0500117e-09,  1.9227305e-07,\n",
       "           1.5510025e-07]], dtype=float32),\n",
       " matrix([[-4.3679739e-07,  8.0079523e-08,  3.6399783e-08, -2.0201880e-07,\n",
       "           3.4124795e-08]], dtype=float32),\n",
       " matrix([[ 1.7660635e-07, -4.7095028e-08, -7.8001143e-08,  7.0642542e-08,\n",
       "           2.0751247e-07]], dtype=float32),\n",
       " matrix([[3.1789145e-07, 1.5610740e-07, 2.4125690e-08, 3.4059798e-07,\n",
       "          1.1353266e-07]], dtype=float32),\n",
       " matrix([[ 1.1336128e-06,  5.7580337e-07,  1.5744624e-07,  2.4629088e-07,\n",
       "          -1.8781085e-07]], dtype=float32),\n",
       " matrix([[-7.3958415e-07, -1.3928025e-07,  1.2002023e-07,  8.9204226e-09,\n",
       "          -1.0876834e-07]], dtype=float32),\n",
       " matrix([[-3.6784581e-07, -2.5885447e-07, -4.0871758e-08, -2.1287373e-07,\n",
       "          -3.6614281e-08]], dtype=float32),\n",
       " matrix([[-9.7440636e-07,  1.3475832e-07, -2.0732051e-08, -3.1292439e-07,\n",
       "          -1.0106874e-07]], dtype=float32),\n",
       " matrix([[-7.9111618e-07,  1.9168311e-07, -1.5984882e-07, -9.8974191e-08,\n",
       "          -2.2351742e-07]], dtype=float32),\n",
       " matrix([[5.0727357e-07, 3.3289829e-09, 1.7754575e-08, 7.2920578e-08,\n",
       "          2.5458792e-07]], dtype=float32),\n",
       " matrix([[-2.7743252e-07,  2.8176741e-08, -3.3866275e-08,  1.7339532e-08,\n",
       "           2.6009300e-08]], dtype=float32),\n",
       " matrix([[-4.5413064e-08,  4.3993904e-08, -1.7739478e-07, -5.3218432e-08,\n",
       "          -8.5149496e-09]], dtype=float32),\n",
       " matrix([[ 4.5473212e-07,  1.3578807e-07, -1.4526165e-07,  8.4078074e-08,\n",
       "           1.8157706e-08]], dtype=float32),\n",
       " matrix([[-6.7551929e-07, -2.0662944e-07,  1.8477439e-07, -3.9736432e-09,\n",
       "          -1.0033448e-07]], dtype=float32),\n",
       " matrix([[ 2.7148394e-07,  3.2717293e-07,  1.0175209e-07, -7.2874293e-09,\n",
       "           1.6793717e-07]], dtype=float32),\n",
       " matrix([[ 2.8049246e-07,  3.5061557e-08, -8.2394656e-08, -1.6654239e-07,\n",
       "           6.3110804e-08]], dtype=float32),\n",
       " matrix([[ 5.8342431e-07, -4.7122731e-07,  1.6081567e-07,  3.1321658e-08,\n",
       "           1.4492110e-07]], dtype=float32),\n",
       " matrix([[ 6.2482110e-07, -1.7675860e-07, -2.6102722e-07,  1.5894572e-07,\n",
       "           9.2489969e-08]], dtype=float32),\n",
       " matrix([[-2.4453189e-07, -2.3841858e-07, -1.9562550e-07,  1.0851102e-07,\n",
       "          -9.5138184e-08]], dtype=float32),\n",
       " matrix([[-7.5963669e-07, -3.2305201e-07, -9.7018813e-08, -1.4088370e-07,\n",
       "           1.9661792e-07]], dtype=float32),\n",
       " matrix([[ 1.4561479e-06,  5.1272814e-08,  1.6279118e-07,  2.5636407e-08,\n",
       "          -2.2816401e-07]], dtype=float32),\n",
       " matrix([[-1.5119227e-07, -1.0757911e-07, -3.1871107e-07, -1.7445261e-08,\n",
       "          -1.4246964e-07]], dtype=float32),\n",
       " matrix([[-1.5435191e-07, -7.7175955e-08,  3.3075409e-08,  2.0672131e-07,\n",
       "          -1.7088962e-07]], dtype=float32),\n",
       " matrix([[-4.6748741e-07, -8.4147736e-08, -5.0254897e-08, -6.6616956e-08,\n",
       "           7.2168369e-08]], dtype=float32),\n",
       " matrix([[ 9.3078614e-07,  2.5939943e-07, -2.2315979e-07,  2.4437904e-07,\n",
       "           3.3473970e-07]], dtype=float32),\n",
       " matrix([[ 3.5321270e-07, -1.4901161e-07,  5.9604645e-08, -7.1263422e-08,\n",
       "          -3.5376459e-07]], dtype=float32),\n",
       " matrix([[-4.6811454e-07, -3.6053541e-07, -1.3083947e-07, -1.4537719e-08,\n",
       "          -8.1411223e-08]], dtype=float32),\n",
       " matrix([[ 1.1951627e-06,  5.6893015e-07,  1.2279068e-07, -1.6218603e-07,\n",
       "           6.6511618e-08]], dtype=float32),\n",
       " matrix([[ 7.2660902e-07,  2.5828680e-07,  3.7607691e-08, -1.9158636e-08,\n",
       "          -8.5149496e-09]], dtype=float32),\n",
       " matrix([[ 1.3746657e-07,  4.0219712e-07, -8.5916604e-08,  8.1083797e-08,\n",
       "           9.1554881e-08]], dtype=float32),\n",
       " matrix([[-2.3231687e-06,  1.2743671e-07,  3.0734529e-07, -1.0192111e-06,\n",
       "          -6.7796755e-08]], dtype=float32),\n",
       " matrix([[6.0232060e-07, 5.0695320e-07, 5.0193385e-08, 2.4092824e-07,\n",
       "          2.3214440e-08]], dtype=float32),\n",
       " matrix([[-1.2327985e-06, -8.5772541e-08, -1.8680969e-07, -1.8790001e-07,\n",
       "           2.1897438e-07]], dtype=float32),\n",
       " matrix([[-2.6247918e-08, -4.8121180e-08,  1.2249028e-07, -2.0615552e-07,\n",
       "           2.6247918e-08]], dtype=float32),\n",
       " matrix([[-3.2056280e-07,  5.6975029e-08,  6.6116080e-08,  3.0052764e-08,\n",
       "          -1.5226733e-07]], dtype=float32),\n",
       " matrix([[ 1.3070362e-06, -6.0371923e-07, -6.8823812e-07,  1.1281038e-07,\n",
       "          -1.1363987e-07]], dtype=float32),\n",
       " matrix([[ 3.79571873e-07,  1.28105512e-07,  3.49917819e-08,\n",
       "           4.74464841e-08, -1.05568425e-07]], dtype=float32),\n",
       " matrix([[-2.8861197e-07, -1.7920607e-07, -1.5528579e-07,  6.4285764e-08,\n",
       "          -8.5877744e-08]], dtype=float32),\n",
       " matrix([[-1.8384083e-07, -4.5960209e-07, -1.5619289e-08, -1.3563647e-07,\n",
       "           6.7324521e-08]], dtype=float32),\n",
       " matrix([[-1.2170701e-06, -3.4059799e-08, -3.6898115e-07,  2.2649765e-07,\n",
       "           8.1743515e-08]], dtype=float32),\n",
       " matrix([[-3.5422190e-07, -5.3133283e-07, -9.8773413e-08, -2.0095280e-07,\n",
       "          -1.3283321e-07]], dtype=float32),\n",
       " matrix([[-1.12196979e-07, -1.18430144e-07,  1.18430144e-07,\n",
       "           6.23316581e-08, -5.60984894e-08]], dtype=float32),\n",
       " matrix([[8.0532499e-07, 6.7110413e-08, 1.2980567e-07, 1.6777604e-07,\n",
       "          1.5651739e-07]], dtype=float32),\n",
       " matrix([[-1.9868214e-07,  3.9736431e-08, -9.9341072e-08, -6.7676105e-08,\n",
       "          -1.4901161e-08]], dtype=float32),\n",
       " matrix([[ 1.5307384e-06, -5.4061792e-07,  1.1845000e-07,  1.5375720e-07,\n",
       "           1.5489614e-07]], dtype=float32),\n",
       " matrix([[ 9.5763153e-07,  2.0493734e-07,  3.9571550e-09, -4.5754605e-09,\n",
       "           1.7807197e-07]], dtype=float32),\n",
       " matrix([[ 1.3494167e-06,  4.3791168e-08,  1.7070445e-07, -1.5408004e-08,\n",
       "           1.7526604e-07]], dtype=float32),\n",
       " matrix([[-7.15255737e-07, -1.09275184e-07, -1.22934580e-07,\n",
       "          -2.53319740e-07, -2.95462087e-07]], dtype=float32),\n",
       " matrix([[ 2.0807440e-07,  8.6697662e-09, -2.2107905e-07, -1.4088370e-07,\n",
       "           2.0157208e-07]], dtype=float32),\n",
       " matrix([[ 1.9836426e-07, -6.8664548e-08,  2.5177002e-07, -4.8160555e-08,\n",
       "          -7.1763992e-08]], dtype=float32),\n",
       " matrix([[ 3.5110398e-07, -7.1169723e-08,  2.6451414e-07,  1.0675459e-08,\n",
       "           1.7792431e-07]], dtype=float32),\n",
       " matrix([[-6.0187443e-07, -3.0517577e-07, -1.4570024e-07, -2.0133124e-08,\n",
       "          -2.6649900e-07]], dtype=float32),\n",
       " matrix([[-2.3355290e-07,  7.7850963e-08, -3.7709061e-08, -1.4353772e-07,\n",
       "           2.5164717e-08]], dtype=float32),\n",
       " matrix([[3.6413019e-07, 8.6697668e-08, 1.0010871e-07, 1.1487440e-07,\n",
       "          6.2720339e-08]], dtype=float32),\n",
       " matrix([[ 7.9472858e-07,  3.9736431e-08,  1.3464263e-07, -2.2706532e-08,\n",
       "          -8.6568647e-08]], dtype=float32),\n",
       " matrix([[ 1.6829547e-07,  1.4024623e-07, -5.9604645e-08, -7.7135425e-08,\n",
       "           1.3148083e-07]], dtype=float32),\n",
       " matrix([[3.9268943e-07, 1.6362060e-07, 1.4258366e-07, 3.7398993e-07,\n",
       "          5.6098489e-08]], dtype=float32),\n",
       " matrix([[-4.5413064e-08,  1.8922110e-07, -5.2981907e-08,  9.8394970e-08,\n",
       "           8.9880018e-08]], dtype=float32),\n",
       " matrix([[9.0715361e-07, 1.9189788e-07, 2.9802322e-07, 3.4890522e-08,\n",
       "          4.3613156e-08]], dtype=float32),\n",
       " matrix([[-8.4548435e-07, -1.6028140e-07, -2.5444672e-07,  1.2722336e-07,\n",
       "           1.2722336e-07]], dtype=float32),\n",
       " matrix([[ 3.6979208e-07, -8.0283804e-08,  1.5570193e-07, -1.3745561e-07,\n",
       "           2.7977691e-08]], dtype=float32),\n",
       " matrix([[-1.0706896e-06, -3.0423965e-07,  1.9819458e-07,  1.0238835e-07,\n",
       "           2.0111997e-07]], dtype=float32),\n",
       " matrix([[-1.2488593e-07,  1.6867709e-07, -5.5144433e-08,  1.0136844e-07,\n",
       "          -1.2650781e-07]], dtype=float32),\n",
       " matrix([[-4.3166312e-07, -2.6100560e-07, -3.0116030e-07, -2.1583156e-07,\n",
       "           2.1285132e-07]], dtype=float32),\n",
       " matrix([[ 6.2584877e-07,  7.9472862e-08, -1.3907750e-07,  1.5646219e-07,\n",
       "           1.3286869e-07]], dtype=float32),\n",
       " matrix([[ 1.3623919e-07,  1.9981748e-07,  1.4418647e-07, -4.2574747e-08,\n",
       "           1.2375060e-07]], dtype=float32),\n",
       " matrix([[ 6.1101213e-07,  3.0550606e-07,  7.7731164e-09, -2.8899223e-08,\n",
       "           1.6307418e-07]], dtype=float32),\n",
       " matrix([[1.58309933e-06, 2.61068351e-07, 3.21865095e-08, 5.00679000e-08,\n",
       "          1.14813446e-07]], dtype=float32),\n",
       " matrix([[ 7.3304818e-07,  2.6332799e-07,  6.4764453e-07, -2.4731480e-07,\n",
       "          -5.6046158e-08]], dtype=float32),\n",
       " matrix([[ 5.9193576e-07,  6.2482108e-08, -5.3438647e-08,  6.4331907e-08,\n",
       "           2.8851732e-08]], dtype=float32),\n",
       " matrix([[-2.88320138e-07, -2.43963200e-07,  1.30645063e-07,\n",
       "          -4.99015620e-08,  1.10892366e-07]], dtype=float32),\n",
       " matrix([[-1.9239824e-06, -6.3208648e-07, -6.4594803e-07, -1.4171265e-07,\n",
       "           7.9703888e-09]], dtype=float32),\n",
       " matrix([[-3.42007354e-07,  1.64426606e-09,  1.47983945e-08,\n",
       "           1.31541285e-07, -1.09343695e-07]], dtype=float32),\n",
       " matrix([[-2.4610949e-07, -1.3330931e-07, -1.0735245e-07,  3.7172789e-08,\n",
       "           4.2300069e-08]], dtype=float32),\n",
       " matrix([[6.2027596e-07, 3.4115178e-07, 5.8150874e-08, 6.4935143e-08,\n",
       "          6.2027596e-08]], dtype=float32),\n",
       " matrix([[ 3.0275377e-08, -1.4759246e-07, -5.0143591e-08, -8.7041705e-08,\n",
       "          -3.8790326e-08]], dtype=float32),\n",
       " matrix([[ 5.20186006e-07,  3.65755767e-07, -1.92360446e-07,\n",
       "           2.03874976e-07, -1.08372085e-08]], dtype=float32),\n",
       " matrix([[ 1.02223919e-06,  1.00534145e-07, -1.38687938e-07,\n",
       "           3.03866813e-07,  1.34792202e-07]], dtype=float32),\n",
       " matrix([[ 3.0517577e-07, -7.4931556e-08, -9.6048630e-08,  8.1743515e-08,\n",
       "          -7.7826634e-08]], dtype=float32),\n",
       " matrix([[2.0345053e-07, 3.8146972e-08, 5.5631002e-08, 8.2651773e-08,\n",
       "          3.2027563e-07]], dtype=float32),\n",
       " matrix([[6.1223534e-07, 8.8303175e-08, 1.7660636e-08, 3.5321271e-08,\n",
       "          8.3888018e-08]], dtype=float32),\n",
       " matrix([[-4.9565966e-07,  4.8101995e-08, -5.9754030e-10,  2.8846259e-07,\n",
       "          -1.3444656e-09]], dtype=float32),\n",
       " matrix([[-1.6702771e-07, -3.3405541e-07,  3.2327943e-08,  6.0614894e-08,\n",
       "          -2.1636149e-08]], dtype=float32),\n",
       " matrix([[-7.4286208e-07,  5.0193385e-08, -7.4035242e-08, -1.9073487e-07,\n",
       "           1.3301248e-07]], dtype=float32),\n",
       " matrix([[-4.1804901e-07, -1.2410830e-07, -9.3081226e-08,  8.2466698e-08,\n",
       "          -3.3476582e-08]], dtype=float32),\n",
       " matrix([[-1.2962563e-07,  2.0369743e-07, -1.5393044e-07, -5.3239098e-08,\n",
       "          -1.3309775e-08]], dtype=float32),\n",
       " matrix([[ 4.94830999e-07,  4.13858658e-07, -1.34953915e-08,\n",
       "          -1.94558552e-07,  4.61092533e-08]], dtype=float32),\n",
       " matrix([[3.5762787e-07, 1.0679165e-07, 9.3132257e-08, 2.9802322e-08,\n",
       "          6.3329935e-08]], dtype=float32),\n",
       " matrix([[ 7.4174670e-07,  4.9449778e-07, -1.5894572e-07,  8.8303175e-08,\n",
       "          -7.2850121e-08]], dtype=float32),\n",
       " matrix([[ 2.7550593e-07,  2.2517310e-07, -4.2385526e-08,  1.7649597e-07,\n",
       "           5.2981908e-09]], dtype=float32),\n",
       " matrix([[-2.4286115e-07, -3.8206207e-07, -2.3397600e-07, -2.5174631e-07,\n",
       "           5.4791848e-08]], dtype=float32),\n",
       " matrix([[-2.3841858e-08,  8.3446501e-08,  1.3113022e-07,  1.1920929e-07,\n",
       "           8.9779498e-08]], dtype=float32),\n",
       " matrix([[ 2.6822090e-07,  3.1664968e-08, -1.0244548e-07,  2.1560118e-07,\n",
       "           2.0489097e-08]], dtype=float32),\n",
       " matrix([[ 9.6360839e-07, -1.3659398e-08, -2.4276474e-07,  1.7912437e-07,\n",
       "           4.3399632e-07]], dtype=float32),\n",
       " matrix([[-8.8031477e-08, -7.3359566e-08,  7.8861532e-08,  4.9517705e-08,\n",
       "          -1.3388120e-07]], dtype=float32),\n",
       " matrix([[3.67122425e-07, 2.49759296e-07, 3.12265030e-07, 1.47692925e-08,\n",
       "          1.18154340e-07]], dtype=float32),\n",
       " matrix([[ 4.2537991e-07, -6.8609665e-09,  6.8609666e-08,  1.7409702e-07,\n",
       "          -5.0170815e-08]], dtype=float32),\n",
       " matrix([[-5.3268298e-07, -1.4605823e-07, -1.1598742e-07, -7.5714006e-08,\n",
       "           2.5238003e-07]], dtype=float32),\n",
       " matrix([[ 2.2888183e-07,  9.5367433e-08,  4.7683717e-08, -1.1324882e-08,\n",
       "           1.3828277e-07]], dtype=float32),\n",
       " matrix([[-3.4438239e-07, -2.7815500e-07,  4.8014854e-08, -2.8808913e-07,\n",
       "          -1.4901161e-07]], dtype=float32),\n",
       " matrix([[ 3.9462387e-07,  2.5486125e-07,  2.8774656e-07,  2.1169926e-07,\n",
       "          -6.1659975e-08]], dtype=float32),\n",
       " matrix([[1.6920028e-07, 3.8454608e-08, 2.7687318e-07, 2.6918227e-07,\n",
       "          1.9227304e-08]], dtype=float32),\n",
       " matrix([[-6.4304896e-07,  8.1743515e-08, -2.2888183e-07, -2.6055744e-07,\n",
       "          -2.6566642e-08]], dtype=float32),\n",
       " matrix([[-6.0183328e-07,  4.0276538e-07, -1.2036666e-06, -2.4304808e-07,\n",
       "          -1.0416346e-08]], dtype=float32),\n",
       " matrix([[1.4695155e-07, 1.9337175e-07, 6.3669847e-07, 1.8458212e-07,\n",
       "          1.6260806e-07]], dtype=float32),\n",
       " matrix([[-1.9073487e-07, -2.9802322e-07,  7.4505806e-09,  5.9604645e-08,\n",
       "          -8.3446501e-08]], dtype=float32),\n",
       " matrix([[-1.2030662e-06, -8.0204410e-07, -6.6712310e-08, -3.6311448e-07,\n",
       "           7.4817548e-09]], dtype=float32),\n",
       " matrix([[-1.7339534e-07, -1.0003577e-08, -6.6690511e-09,  1.0337029e-07,\n",
       "          -7.0650259e-08]], dtype=float32),\n",
       " matrix([[-3.9268944e-08, -1.2902653e-07,  7.8537887e-08, -4.4037313e-07,\n",
       "          -1.3884376e-07]], dtype=float32),\n",
       " matrix([[ 9.9374472e-07, -3.3659094e-07,  3.8467536e-07,  2.8049245e-08,\n",
       "           1.1820753e-07]], dtype=float32),\n",
       " matrix([[ 5.4868934e-07,  8.4916209e-08, -4.8990120e-08, -1.3676409e-07,\n",
       "          -4.8990120e-08]], dtype=float32),\n",
       " matrix([[-7.0642542e-08, -1.9426698e-08, -5.0332812e-08,  5.1215842e-08,\n",
       "           8.6537113e-08]], dtype=float32),\n",
       " matrix([[ 3.5762787e-07,  8.8179313e-08,  3.1563368e-07, -1.3072382e-07,\n",
       "           5.0122086e-08]], dtype=float32),\n",
       " matrix([[ 1.7937193e-06, -4.8901171e-07,  4.1799342e-07, -2.8133076e-07,\n",
       "          -2.1051854e-07]], dtype=float32),\n",
       " matrix([[ 1.46719131e-07, -1.10039345e-07, -5.73121568e-08,\n",
       "          -4.87153358e-08, -7.10670776e-08]], dtype=float32),\n",
       " matrix([[-6.2453006e-07, -3.4813333e-08, -1.6879191e-07, -1.6417651e-08,\n",
       "          -1.2237413e-07]], dtype=float32),\n",
       " matrix([[ 3.8146973e-07, -5.0012023e-08,  2.7045607e-07, -1.8626451e-07,\n",
       "           8.2701447e-08]], dtype=float32),\n",
       " matrix([[-1.3779325e-07, -7.6148901e-08, -8.8613753e-08, -5.4392071e-08,\n",
       "          -1.6136315e-07]], dtype=float32),\n",
       " matrix([[-2.9024869e-07,  5.1830127e-09, -1.7411683e-07,  2.5267186e-08,\n",
       "           2.9154446e-08]], dtype=float32),\n",
       " matrix([[ 2.1855037e-07, -5.4637592e-08, -2.2103389e-07, -1.7260511e-07,\n",
       "          -7.7299774e-08]], dtype=float32),\n",
       " matrix([[ 6.0110381e-07, -2.3119378e-07,  1.9362479e-07,  1.2887247e-07,\n",
       "          -1.2896278e-07]], dtype=float32),\n",
       " matrix([[-3.4829844e-07,  7.6708588e-08, -3.1098075e-08, -8.5519709e-08,\n",
       "          -4.5092211e-08]], dtype=float32),\n",
       " matrix([[-1.2690022e-07, -4.3069161e-07,  4.5184166e-08, -1.5574116e-07,\n",
       "          -2.0465062e-07]], dtype=float32),\n",
       " matrix([[-2.9550472e-07,  1.3432032e-08,  1.3767833e-07,  3.7497756e-08,\n",
       "           4.5752863e-08]], dtype=float32),\n",
       " matrix([[ 8.2556880e-07,  2.5087328e-07, -3.5584862e-09,  2.2418463e-07,\n",
       "          -6.5720791e-08]], dtype=float32),\n",
       " matrix([[ 5.6259921e-07, -1.7152416e-08,  3.2589590e-08,  1.5522936e-07,\n",
       "           1.9124944e-07]], dtype=float32),\n",
       " matrix([[-3.2356806e-07, -3.4059799e-08, -1.4475414e-07,  2.2990363e-07,\n",
       "          -6.7853499e-08]], dtype=float32),\n",
       " matrix([[ 1.6086072e-07,  4.0215181e-08,  1.8384083e-07, -2.0107591e-07,\n",
       "           1.5798821e-07]], dtype=float32),\n",
       " matrix([[-1.10039345e-07,  3.43872948e-08, -1.73369273e-07,\n",
       "          -1.77094563e-07, -2.04890966e-08]], dtype=float32),\n",
       " matrix([[ 5.8687652e-07,  1.8034225e-07,  8.7114479e-08,  1.8645555e-07,\n",
       "          -4.1264755e-08]], dtype=float32),\n",
       " matrix([[ 6.5468453e-07, -1.2951928e-07, -1.5980488e-07, -3.7373724e-08,\n",
       "           2.0619986e-07]], dtype=float32),\n",
       " matrix([[ 4.7683716e-07, -1.5142801e-07, -3.4635132e-08,  5.6382774e-09,\n",
       "           4.8328088e-09]], dtype=float32),\n",
       " matrix([[ 1.1280018e-06,  1.9547759e-08,  2.5892771e-07, -2.8840956e-08,\n",
       "           6.2809193e-08]], dtype=float32),\n",
       " matrix([[ 1.4356388e-07,  9.5816070e-08,  2.2303674e-07,  2.6277316e-08,\n",
       "          -6.2488738e-08]], dtype=float32),\n",
       " matrix([[-6.4420385e-07, -2.5262895e-07, -1.9736638e-07, -1.1368303e-07,\n",
       "          -5.3683653e-08]], dtype=float32),\n",
       " matrix([[-1.31193289e-07, -4.54130635e-08,  1.00917916e-07,\n",
       "           1.55161302e-07, -4.09979037e-08]], dtype=float32),\n",
       " matrix([[ 1.6530355e-07, -1.2715658e-07,  1.0172526e-07, -3.6875406e-07,\n",
       "           2.7020772e-07]], dtype=float32),\n",
       " matrix([[ 1.6668201e-07,  4.8949653e-07,  7.3424485e-07, -3.1648483e-08,\n",
       "           2.3630868e-07]], dtype=float32),\n",
       " matrix([[ 1.5258789e-07,  1.6348702e-08,  6.2670026e-08,  3.5762786e-09,\n",
       "          -1.6280583e-07]], dtype=float32),\n",
       " matrix([[-6.1360441e-07, -2.8647193e-07,  2.0145445e-07,  1.8666881e-07,\n",
       "          -1.8482060e-08]], dtype=float32),\n",
       " matrix([[ 4.8287308e-08,  2.1729288e-07,  5.2814244e-08,  8.0730345e-08,\n",
       "          -1.9993964e-08]], dtype=float32),\n",
       " matrix([[ 1.8042488e-07,  7.0881200e-08, -7.6519477e-08,  1.2001476e-07,\n",
       "           2.2553110e-08]], dtype=float32),\n",
       " matrix([[ 9.9144359e-07,  2.9743308e-07, -1.4753625e-09,  7.1407541e-08,\n",
       "           3.9716758e-07]], dtype=float32),\n",
       " matrix([[5.0488643e-07, 1.4784290e-07, 2.0803189e-07, 1.5543957e-07,\n",
       "          3.0737297e-07]], dtype=float32),\n",
       " matrix([[ 1.1245639e-06, -2.0051968e-07, -1.5573005e-07, -4.2033335e-08,\n",
       "           5.4884509e-07]], dtype=float32),\n",
       " matrix([[-3.5095215e-07, -1.1086464e-07, -1.2874604e-08, -3.0803682e-07,\n",
       "          -2.7656554e-08]], dtype=float32),\n",
       " matrix([[ 2.9617215e-07,  2.9617215e-08,  2.2398018e-07, -3.7698317e-08,\n",
       "          -2.8136354e-08]], dtype=float32),\n",
       " matrix([[-9.3199992e-07, -4.4703484e-08, -3.0276451e-07,  7.5521797e-08,\n",
       "           1.0498545e-07]], dtype=float32),\n",
       " matrix([[-2.1798270e-07,  1.0081700e-07, -1.9073487e-07,  8.5830692e-08,\n",
       "           1.0626657e-07]], dtype=float32),\n",
       " matrix([[ 1.0056929e-06, -7.3259525e-07,  6.8057665e-07,  7.2500922e-07,\n",
       "           4.1181391e-08]], dtype=float32),\n",
       " matrix([[-4.9046110e-07,  2.3783318e-07,  3.4059797e-09,  2.3841858e-08,\n",
       "          -2.5438410e-08]], dtype=float32),\n",
       " matrix([[ 3.2424927e-07,  2.0027160e-07,  4.3869019e-07, -2.2560359e-07,\n",
       "          -7.1525577e-08]], dtype=float32),\n",
       " matrix([[ 6.4292649e-08,  7.5008096e-08,  1.9555681e-07,  9.1081255e-08,\n",
       "          -1.3461273e-07]], dtype=float32),\n",
       " matrix([[-2.6128063e-07, -2.2535454e-07, -2.4127633e-07, -8.1650198e-09,\n",
       "          -6.8586168e-08]], dtype=float32),\n",
       " matrix([[-1.0451225e-07, -4.5724111e-08, -5.8788142e-08,  8.9457998e-08,\n",
       "          -3.2660079e-09]], dtype=float32),\n",
       " ...]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39933ab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8853c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ffd90c4",
   "metadata": {},
   "source": [
    "### Finnish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb67632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, QuestionAnsweringPipeline, pipeline\n",
    "\n",
    "model_name = \"ilmariky/bert-base-finnish-cased-squad2-fi\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'Mikä tämä on?',\n",
    "    'context': 'Tämä on testi.'\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "train_res = nlp(finn_training)\n",
    "print(res)\n",
    "print(train_res)\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffd03cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69945e87",
   "metadata": {},
   "source": [
    "### Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33556e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForQuestionAnswering,QuestionAnsweringPipeline\n",
    "\n",
    "model_name = \"KoichiYasuoka/deberta-base-japanese-aozora-ud-head\"\n",
    "\n",
    "# a) Get predictions\n",
    "QA_input = {\n",
    "    'question': '国語',\n",
    "    'context': '全学年にわたって小学校の国語の教科書に挿し絵>が用いられている'\n",
    "}\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Option 1:\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "res = nlp(QA_input)\n",
    "train_res = nlp(jap_training)\n",
    "print(res)\n",
    "print(train_res)\n",
    "print(\"----------------------------------------------------------------\")\n",
    "\n",
    "# Option 2:\n",
    "nlp2 = QuestionAnsweringPipeline(model=model, tokenizer=tokenizer, align_to_words=False)\n",
    "res2 = nlp2(QA_input)\n",
    "train_res2 = nlp2(jap_training)\n",
    "print(res)\n",
    "print(train_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98edf578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7bf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578f78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7fedbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39212a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f977f7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
